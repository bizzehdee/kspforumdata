{"TopicId":104912,"ForumId":44,"TopicTitle":"Usefulness of Ackermann Function as Computer Benchmarker?","CreatedByName":"Themohawkninja","CreatedById":9628,"CreatedDateTime":"2015-04-25T07:05:18Z","PageNum":1,"Articles":[{"CreatedByName":"Themohawkninja","CreatedById":9628,"CreatedDateTime":"2015-04-25T07:05:18Z","Content":"Hello,\n\nIn addition to my interests in all manner of computers, I also am quite interested in mathematics, and I recently discovered a highly recursive mathematical function called the [Ackermann function](https://en.wikipedia.org/wiki/Ackermann_function).\n\nAs you can see in the article, there is a brief mention of this function being a useful tool for benchmarking computer performance, however when I looked up Ackermann-based benchmarks, only academic papers about the subject seemed to show up in Google. As a result, I ended up programming my own in C\u002B\u002B. Once it was up-and-running, I tested in on both my computer (i7-2600k w/ GTX 580), and my roommate\u0027s (i7-4790k w/ ASUS Hero VII on-board graphics), and my roommate\u0027s computer scored about 25% higher. I\u0027m not really sure if that accurately displays the difference in performance, because I can\u0027t seem to find consistent information on the GFLOP count of my roommate\u0027s processor.\n\nIs this function an accurate way of measuring either CPU, GPU, or total computer performance?\n\nIn-case anyone wants to try this on their own computer, the .exe application and the source code in .h format are linked below. Ignore the broken \u0022how it works\u0022 function. I have yet to get it to properly display the message that you can read in the source code, so if any programmers want to tell me how to fix it, that would be nice.\n\nApplication (EXE): [https://www.dropbox.com/s/bh5c72j395xz1m7/A44.exe?dl=0](https://www.dropbox.com/s/bh5c72j395xz1m7/A44.exe?dl=0)\n\nSource (H): [https://www.dropbox.com/s/guavn0c364w97hz/Form1.h?dl=0](https://www.dropbox.com/s/guavn0c364w97hz/Form1.h?dl=0)"},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2015-04-25T09:11:29Z","Content":"Lets start with the fact that A(4,4) is far outside the int range. And why, exactly, are you passing 64 bit integers to it as parameters, but return just a 32 bit int? But that\u0027s just minor gripes. Then there is your implementation with forms, which is going to prevent you from running a clean, well optimized code. If you want to write efficient code, write it in C. Finally, the only thing you are really \u0022testing\u0022 with this implementation is the stack.\n\nEdit: All of the references talk about Ackermann as the benchmark of *optimizer*, not benchmark of the computer.\n\n**Edited \u003Ctime datetime=\u00222015-04-25T09:15:58Z\u0022 title=\u002204/25/2015 09:15  AM\u0022 data-short=\u00229 yr\u0022\u003EApril 25, 2015\u003C/time\u003E by K^2**"},{"CreatedByName":"ZetaX","CreatedById":60692,"CreatedDateTime":"2015-04-25T09:43:21Z","Content":"\u003E \n\u003E Is this function an accurate way of measuring either CPU, GPU, or total computer performance?\n\nUnless you do weird things, all you will test is your CPU\u0027s arithmetics and maybe memory and busses. Why would you expect a purely arithmetical thing to test a GPU\u00C3\u201A\u00C2\u00BF"},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2015-04-25T10:49:11Z","Content":"Modern GPUs are just general vector processors. Lots and lots of arithmetic operations are precisely how you test them. What GPUs are really bad at is any sort of branching, which would make Ackermann absolutely the worst thing to use a GPU for."},{"CreatedByName":"Themohawkninja","CreatedById":9628,"CreatedDateTime":"2015-04-25T18:01:44Z","Content":"\u003E \n\u003E Unless you do weird things, all you will test is your CPU\u0027s arithmetics and maybe memory and busses. Why would you expect a purely arithmetical thing to test a GPU\u00C3\u201A\u00C2\u00BF\n\nI don\u0027t. I have a pretty limited knowledge of computer science at the moment, which is why I asked what this would ACTUALLY test.\n\n- - - Updated - - -\n\n\u003E \n\u003E Lets start with the fact that A(4,4) is far outside the int range. And why, exactly, are you passing 64 bit integers to it as parameters, but return just a 32 bit int? But that\u0027s just minor gripes. Then there is your implementation with forms, which is going to prevent you from running a clean, well optimized code. If you want to write efficient code, write it in C. Finally, the only thing you are really \u0022testing\u0022 with this implementation is the stack.\n\u003E Edit: All of the references talk about Ackermann as the benchmark of *optimizer*, not benchmark of the computer.\n\nThe program was meant to do the exact opposite of what it does (run for a given period of time, and count the number of times it called the function), but I was having issues with it either breaking a 64-bit integer, or calculating for such a short period of time that I couldn\u0027t get any real data from it. The code would look nicer if it wasn\u0027t for the fact that this isn\u0027t so much of a serious program that I would put in a portfolio for a job, so much so as it is a little experiment in mathematics and computer science. It gave me quite the eye-opener as to just how fast current processors are when I had to tell the computer to run 100 million iterations to get a decent number of milliseconds to go off of.\n\nAlso, what is the \u0022stack\u0022 with reference to computer science here? Is that the order/speed in which instructions are carried out, or something completely different?"},{"CreatedByName":"andrewas","CreatedById":24662,"CreatedDateTime":"2015-04-25T19:19:14Z","Content":"The stack is an area of memory to which the current contents of the processor registers are pushed every time you do a function call."},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2015-04-26T00:16:03Z","Content":"You don\u0027t usually push all the registers. Just the \u0022relevant\u0022 ones. (TBD by the compiler.) Unoptimized code will almost never push any working registers to the stack. What always goes onto the stack is the return address and almost always a base pointer. But stack is used for a lot more than that. Stack is used to pass variables to a function, it is used for nearly all local variables within a function, and it is used in intermediate operations of complicated algebraic expressions.\n\nFor example. Consider a very simple function.\n\n    int sum(int a, int {\tint c = a \u002B b;\treturn c;}\n\nIf you compile it without optimization and call sum(3,4) from main, the stack will get the following workout.\n\n1. Push 4 to the stack.\n2. Push 3 to the stack.\n3. Push return address in main to the stack. (Followed by jump to address of sum function in memory.)\n4. Push current base pointer (belonging to main) to the stack.\n5. Set base pointer to match stack pointer.\n6. Decrement stack pointer by 4 to create space for c on the stack.\n7. Use base pointer to read values of a and b, compute the sum, and use base pointer again to store it in c.\n8. Copy answer from c to return register. (Usually eax)\n9. Pop base pointer from stack. (Returns it to base of main.)\n10. Pop return address from stack, and return to main function.\n\nNow imagine all of that on top of your A(m,n) function. Basically, all it does is stack operations simply because of the way you\u0027ve set up recursion. Processor does very little of actual algebra. It will spend, maybe, one cycle in a hundred doing math, and the rest of the time will be wasted on branching, function calls, stack operations, and all of the mess associated with it. (Branch predictions, cache predictions, etc.)\n\nWhen you want to test computational capabilities of the CPU, you really want to avoid all of that nonsense. You want to serve mathematical operations in as predictable a manner as possible, making sure that cache remains consistent, and any branches you must have are very well predicted. Then all the CPU is doing is pulling values out of cache, does math, puts them back into cache, and it can do this very, very fast. That\u0027s where you can get tens of billions of operations per second.\n\nGPU is kind of a different story. It\u0027s really bad at general computing. Especially branching. You generally want to pull as much of that out of GPU code as possible and have CPU look after it. If you can reduce your math problem to \u0022Do this set of operations a million times,\u0022 you can get a good GPU give you *trillions* of operations per second. That\u0027s why GPU is so awesome at image processing, numerical integration, and artificial neural networks. And, of course, actual rendering. All of these problems are reduced to, \u0022Here is the math you have to do for each point, now do this lots.\u0022\n\nEdit: If you can read assembly, the sum(a,![B)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_cool.png) compiles to the following on x86. (Again, unoptimized)\n\n    push ebpmov ebp, espsub esp, 4mov eax, [ebp\u002B8]add eax, [ebp\u002B12]mov [ebp-4], eaxmov eax, [ebp-4]mov esp, ebppop ebpret\n\n**Edited \u003Ctime datetime=\u00222015-04-26T00:27:59Z\u0022 title=\u002204/26/2015 12:27  AM\u0022 data-short=\u00229 yr\u0022\u003EApril 26, 2015\u003C/time\u003E by K^2**"},{"CreatedByName":"Camacha","CreatedById":59088,"CreatedDateTime":"2015-04-26T02:39:34Z","Content":"\u003E \n\u003E Is this function an accurate way of measuring either CPU, GPU, or total computer performance?\n\nNo, for the simple reason that computer performance in dependant on so many factors, of which a major one is what you are actually trying to do. So even if you might be measuring a computer\u0027s capability to solve Ackermann Functions to perfection, any other task will be less accurately gauged. Many components are slightly or even very specialised towards their final purpose."}]}