{"TopicId":185611,"ForumId":44,"TopicTitle":"Statistics Help","CreatedByName":"Cunjo Carl","CreatedById":162109,"CreatedDateTime":"2019-06-18T22:41:08Z","PageNum":1,"Articles":[{"CreatedByName":"Cunjo Carl","CreatedById":162109,"CreatedDateTime":"2019-06-18T22:41:08Z","Content":"\n\u003Cp\u003E\nSo an experiment at work went pear shaped today when we discovered the calibration data was completely out of whack. There\u0027s a couple months of experiment data on the line, and I think I can save it by calibrating our data against itself. It would involve multivariate linear regression though, and I have a question about that. My data is a bunch of y values that vary with x\u003Csub\u003E1\u003C/sub\u003E and x\u003Csub\u003E2\u003C/sub\u003E. If we put it together, and draw a best fit line for y (called y\u003Csub\u003Ehat\u003C/sub\u003E) it will take the nice happy linear form of:\n\u003C/p\u003E\n\u003Cp\u003E\ny\u003Csub\u003Ehat\u003C/sub\u003E = B\u003Csub\u003E0\u003C/sub\u003E \u002B B\u003Csub\u003E1\u003C/sub\u003E*x\u003Csub\u003E1\u003C/sub\u003E \u002B B\u003Csub\u003E2\u003C/sub\u003E*x\u003Csub\u003E2\u003C/sub\u003E\u003Cbr\u003E\u003Cbr\u003E\nAnd we can calculate the standard error in our fit line y\u003Csub\u003Ehat\u003C/sub\u003E by:\n\u003C/p\u003E\n\u003Cp\u003E\nSE\u003Csub\u003Eyhat\u003C/sub\u003E = sqrt( sum( (y\u003Csub\u003Ei\u003C/sub\u003E - y\u003Csub\u003Ehat\u003C/sub\u003E)\u003Csup\u003E2\u003C/sup\u003E ) )\u003Cbr\u003E\u003Cbr\u003E\nBut \u003Cstrong\u003Ewhat\u0027s the standard error in the slope B\u003Csub\u003E1\u003C/sub\u003E\u003C/strong\u003E? If this were single variate, it would be:\u003Cbr\u003E\u003Cbr\u003E\nSE\u003Csub\u003EB1\u003C/sub\u003E = (SE\u003Csub\u003Eyhat\u003C/sub\u003E/SE\u003Csub\u003Ex1\u003C/sub\u003E)/sqrt(n-2)\u003Cbr\u003E\u003Cbr\u003E\nDoes the other dependent variable x\u003Csub\u003E2\u003C/sub\u003E change this? Physically I know the degrees of freedom term (n-2) should become (n-3), but are there any other changes? Thanks in advance!\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222019-06-18T22:45:16Z\u0022 title=\u002206/18/2019 10:45  PM\u0022 data-short=\u00225 yr\u0022\u003EJune 18, 2019\u003C/time\u003E by Cunjo Carl\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"mikegarrison","CreatedById":137807,"CreatedDateTime":"2019-06-18T23:01:16Z","Content":"\n\u003Cp\u003E\nDunno.\n\u003C/p\u003E\n\u003Cp\u003E\nBut I suppose you could treat it as two separate problems. Assume there is zero error in x2 and just treat is as a single variable problem. The do the same for the other variable. Then treat it as any other case where you are combining the effects of two sources of error. It seems like that should work, as long as any error in x1 and x2 are independent of each other.\n\u003C/p\u003E\n\u003Cp\u003E\nBut my real answer is \u0022hire a statistician\u0022. I did that once, and it was really useful. (It happens I work for a very large Fortune 500 company, and they have statisticians in the company available to help with problems like this.)\n\u003C/p\u003E\n"},{"CreatedByName":"Cunjo Carl","CreatedById":162109,"CreatedDateTime":"2019-06-19T00:09:11Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00223621344\u0022 data-ipsquote-contentid=\u0022185611\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221560898876\u0022 data-ipsquote-userid=\u0022137807\u0022 data-ipsquote-username=\u0022mikegarrison\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n53 minutes ago, mikegarrison said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nDunno.\n\u003C/p\u003E\n\u003Cp\u003E\nBut I suppose you could treat it as two separate problems. Assume there is zero error in x2 and just treat is as a single variable problem. The do the same for the other variable. Then treat it as any other case where you are combining the effects of two sources of error. It seems like that should work, as long as any error in x1 and x2 are independent of each other.\n\u003C/p\u003E\n\u003Cp\u003E\nBut my real answer is \u0022hire a statistician\u0022. I did that once, and it was really useful. (It happens I work for a very large Fortune 500 company, and they have statisticians in the company available to help with problems like this.)\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nYeah, if the calibration files weren\u0027t hosed I could use them to treat this as two separate problems rather than one combined one. Unfortunately, that was the thing that was lost! I feel like the formula will wind up being more complicated because physically I feel like not all the error in Y should lie with either B1 or B2 individually, and maybe their errors should be added in quadrature to get the standard error in Y or something like that.\n\u003C/p\u003E\n\u003Cp\u003E\nAh, man, I wish I had that kind of budget! I work for one of those small-miracles-on-shoestrings sorts of labs. If no one on the forums happens to know, I\u0027ll just have to grit my teeth and dive head first into a stats textbook! \u003Cimg alt=\u0022:wacko:\u0022 data-emoticon=\u0022\u0022 src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_wacko.png\u0022 title=\u0022:wacko:\u0022\u003E\u003C/p\u003E\n"},{"CreatedByName":"mikegarrison","CreatedById":137807,"CreatedDateTime":"2019-06-19T00:24:15Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00223621368\u0022 data-ipsquote-contentid=\u0022185611\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221560902951\u0022 data-ipsquote-userid=\u0022162109\u0022 data-ipsquote-username=\u0022Cunjo Carl\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n13 minutes ago, Cunjo Carl said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nAh, man, I wish I had that kind of budget! I work for one of those small-miracles-on-shoestrings sorts of labs. If no one on the forums happens to know, I\u0027ll just have to grit my teeth and dive head first into a stats textbook! \u003Cimg alt=\u0022:wacko:\u0022 data-emoticon=\u0022\u0022 src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_wacko.png\u0022 title=\u0022:wacko:\u0022\u003E\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nHow much would it cost to redo all the experiments? Or to get the wrong answer? I\u0027m just sayin\u0027....\n\u003C/p\u003E\n"},{"CreatedByName":"Shpaget","CreatedById":45577,"CreatedDateTime":"2019-06-19T06:58:45Z","Content":"\n\u003Cp\u003E\nWhat\u0027s the nature of the out of wackness of the calibration? Is there a sensor that is out of cal? If so, can you document the offset and adjust the data according to it?\n\u003C/p\u003E\n"},{"CreatedByName":"Cunjo Carl","CreatedById":162109,"CreatedDateTime":"2019-06-21T17:35:31Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00223621503\u0022 data-ipsquote-contentid=\u0022185611\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221560927525\u0022 data-ipsquote-userid=\u002245577\u0022 data-ipsquote-username=\u0022Shpaget\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nOn 6/18/2019 at 11:58 PM, Shpaget said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nWhat\u0027s the nature of the out of wackness of the calibration? Is there a sensor that is out of cal? If so, can you document the offset and adjust the data according to it?\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nThanks for asking! I wound up doing exactly as you suggested and now the question is if we need to incorporate anything else.\n\u003C/p\u003E\n\u003Cp\u003E\nWe\u0027re measuring the thermal conductivities of a few different structural materials (like metals and thermal ceramics). We\u0027re using the unusual technique of just flowing heat through the materials and measuring the temperature difference created across them! It\u0027s less accurate and convenient than other techniques, but has several advantages in the end and provides a nice confirmation point. To make thermal contact to the materials we use liquid metals or thermal paste (like in computers). I did an initial calibration run to measure the thermal resistance of our thermal paste, but I only did two runs! The values came out very close, but 2 points make for terrible statistics. I asked the students to do a battery of calibration runs on the paste so we could make statistics, but they must have forgotten so we had no idea what variability there is in our thermal paste\u0027s thermal contact resistance. Unfortunately we can\u0027t do the paste calibration runs now because we moved the tool and it might be sensitive to its surroundings.\n\u003C/p\u003E\n\u003Cp\u003E\nWe now have quite a few experiments with one of the test structural materials using different numbers of material layers and thicknesses (along with different numbers of paste layers). So the question is if we can do multivariable regression to separate the effects of material thickness and paste layers. I went ahead and did the multivariable regression by hand, and it looks great! The residuals make a beautiful Gaussian curve and the p values all show signifigance, so I\u0027m confident that it\u0027s a good application of the technique. There is an interesting wrinkle that runs with more layers of thermal paste tend to also have more total structural material thickness.\n\u003C/p\u003E\n\u003Cp\u003E\nI\u0027ve calculated standard error in the structural material\u0027s conductivity as though the paste resistance were a known offset at the value we calculated from the regression, just as you suggested! It looks good on paper and it\u0027s as far as I\u0027ve gotten. The question is then if I can get away with doing just this? Most experimentalists probably would, but I have a few weeks to play with so I think I\u0027ll plink at it a bit.\n\u003C/p\u003E\n"},{"CreatedByName":"Shpaget","CreatedById":45577,"CreatedDateTime":"2019-06-21T17:53:55Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00223623006\u0022 data-ipsquote-contentid=\u0022185611\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221561138531\u0022 data-ipsquote-userid=\u0022162109\u0022 data-ipsquote-username=\u0022Cunjo Carl\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n16 minutes ago, Cunjo Carl said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nThe question\u003Cspan\u003E\uFEFF\u003Cspan\u003E\uFEFF\u003C/span\u003E\u003C/span\u003E is then if I can get away with doing just thi\u003Cspan\u003E\uFEFF\u003C/span\u003Es\u003Cspan\u003E\uFEFF\u003C/span\u003E?\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nAdam Savage says that the difference between screwing around and science is taking notes. So, document the unconventional method and you\u0027re good to go! In my book anyway.\n\u003C/p\u003E\n"},{"CreatedByName":"wizzlebippi","CreatedById":85324,"CreatedDateTime":"2019-06-21T18:36:56Z","Content":"\n\u003Cp\u003E\nCan you calibrate the instrument now to determine the error, and apply the correction to the data analytically?\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"Starstruck69","CreatedById":196382,"CreatedDateTime":"2019-06-23T10:57:55Z","Content":"\n\u003Cp\u003E\nIf it is \u003Cu\u003Econsistantly\u003C/u\u003E out of calibration (thinking linear) then yes you may be able to salvage the work. It depends on instrumentation really. A statistician will help with the maths but how the instrument operates is something they won\u0027t know about and is crucial. You can\u0027t \u0027polish a turd \u0027so you may be better biting the bullet and starting again.\n\u003C/p\u003E\n\u003Cp\u003E\nIf you find a consistant pattern of error then your in luck. In my experience it doesn\u0027t work like that and\u00A0your data will always have a ? next to it.\n\u003C/p\u003E\n\u003Cp\u003E\nSuck it up and start again..\n\u003C/p\u003E\n\u003Cp\u003E\nEdit:\n\u003C/p\u003E\n\u003Cp\u003E\nJust a thought, if you contact the manufacturer of the instrument and have a chat with their technical engineers\u00A0they may throw you a life line..\n\u003C/p\u003E\n\u003Cp\u003E\nBe honest with them and you will get the answer you need. Their is no shame in admitting your mistake and holding your hands up. As hard as this to do sometimes its the best option. You don\u0027t want to be that guy who fudges data...\n\u003C/p\u003E\n\u003Cp\u003E\nI have been on both sides of this and honesty is the best policy here.\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222019-06-23T11:10:44Z\u0022 title=\u002206/23/2019 11:10  AM\u0022 data-short=\u00225 yr\u0022\u003EJune 23, 2019\u003C/time\u003E by Starstruck69\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"Cunjo Carl","CreatedById":162109,"CreatedDateTime":"2019-06-30T23:03:54Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00223623778\u0022 data-ipsquote-contentid=\u0022185611\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221561287475\u0022 data-ipsquote-userid=\u0022196382\u0022 data-ipsquote-username=\u0022Starstruck69\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nOn 6/23/2019 at 3:57 AM, Starstruck69 said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nIf it is \u003Cu\u003Econsistantly\u003C/u\u003E out of calibration (thinking linear) then yes you may be able to salvage the work. It depends on instrumentation really. A statistician will help with the maths but how the instrument operates is something they won\u0027t know about and is crucial. You can\u0027t \u0027polish a turd \u0027so you may be better biting the bullet and starting again.\n\u003C/p\u003E\n\u003Cp\u003E\nIf you find a consistant pattern of error then your in luck. In my experience it doesn\u0027t work like that and\u00A0your data will always have a ? next to it.\n\u003C/p\u003E\n\u003Cp\u003E\nSuck it up and start again..\n\u003C/p\u003E\n\u003Cp\u003E\nEdit:\n\u003C/p\u003E\n\u003Cp\u003E\nJust a thought, if you contact the manufacturer of the instrument and have a chat with their technical engineers\u00A0they may throw you a life line..\n\u003C/p\u003E\n\u003Cp\u003E\nBe honest with them and you will get the answer you need. Their is no shame in admitting your mistake and holding your hands up. As hard as this to do sometimes its the best option. You don\u0027t want to be that guy who fudges data...\n\u003C/p\u003E\n\u003Cp\u003E\nI have been on both sides of this and honesty is the best policy here.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nThanks for the ideas! The instrument was a one-off made by my predecessor, with retrofits and modifications by myself for the current project. So, as the technical engineer on staff the buck falls right back to me!\u00A0\u003Cimg alt=\u0022^_^\u0022 data-emoticon=\u0022\u0022 src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_happy.png\u0022 title=\u0022^_^\u0022\u003E It always has, somehow. Also, I agree about being honest. I\u0027ve always been a straight shooter about this sort of thing, though it did make me very unpopular with the higherups in my last job. \u003Cimg alt=\u0022\u0026lt;_\u0026lt;\u0022 data-emoticon=\u0022\u0022 src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_dry.png\u0022 title=\u0022\u0026lt;_\u0026lt;\u0022\u003E\u003C/p\u003E\n\u003Cp\u003E\nAnyways, I spent a while in the books, found a good set of techniques for double-checking the analysis, and helped the student write their paper in time for the deadline! They don\u0027t all turn out this well, but I\u0027ll happily take it when they do.\n\u003C/p\u003E\n\u003Cp\u003E\nA little more in detail, the calibration we were missing was two pieces, a constant and a linear offset, so I was able to pull it from the rest of the data using multiple linear regression. I knew there was a subtle weakness in the way I was applying the linear regression though, and it took me a while to find the name of it: \u0022multicollinearity\u0022. Once I had this in hand, I was able to find a way to do the analysis without falling victim to it, and double check with statistical rigor that it was being done correctly. The analysis section of the paper is now twice as long as we were first intending, but the results are fortunately very nearly as high quality as if we had calibration data in hand.\u00A0 Again, thanks for the help and advice everyone- it was really good to have some fallback plans in the back pocket.\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"Starstruck69","CreatedById":196382,"CreatedDateTime":"2019-07-02T10:26:42Z","Content":"\n\u003Cp\u003E\nI like a happy ending. Good job Carl i\u0027m glad it all worked out for you:)\n\u003C/p\u003E\n"}]}