{"TopicId":21251,"ForumId":44,"TopicTitle":"\u0026quot;Philosophy will be the key that unlocks artificial intelligence\u0026quot;","CreatedByName":"Ted","CreatedById":26298,"CreatedDateTime":"2012-10-03T23:05:37Z","PageNum":1,"Articles":[{"CreatedByName":"Ted","CreatedById":26298,"CreatedDateTime":"2012-10-03T23:05:37Z","Content":"\n\u003Cp\u003EI was reading an article in the Guardian, a newspaper in the UK, and it was discussing how the missing property of your average Artificial Intelligence is the General Intelligence of it. In other words, the AI is unable to think about and view the world like a person would. This seemed interesting to me as isn\u0027t something you often think about, but when considered, you realise that a lot of fictional AIs did have this subtle property that really added to them.\u003C/p\u003E\u003Cp\u003EYou can read the article \u003Ca href=\u0022http://www.guardian.co.uk/science/2012/oct/03/philosophy-artificial-intelligence\u0022 rel=\u0022external nofollow\u0022\u003Ehere\u003C/a\u003E.\u003C/p\u003E\u003Cp\u003EWhat are your thoughts on it?\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222012-10-13T12:44:54Z\u0022 title=\u002210/13/2012 12:44  PM\u0022 data-short=\u002211 yr\u0022\u003EOctober 13, 2012\u003C/time\u003E by Ted\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"zapy97","CreatedById":45133,"CreatedDateTime":"2012-10-03T23:15:13Z","Content":"\n\u003Cp\u003Ei didn\u0027t read the article but i do know it is why robots cant be like humans, also emotions are important to philsophy, which makes them nessecary to be human like...\u003C/p\u003E\u003Cp\u003Eit is like how in doctor who that there are a race called cyber men which a cyber man is a human brain crammed inside a robotic body, and they cant have emotions because the brain is so delicate that it hurts to be like a cyber man because a human brain is only human with emotions still there, so wype out the emotional inhibiter and the cybermen die, so a robot is like a cyber man from doctor who exceapt one is (technically) a living organism, and the other is a machine\u003C/p\u003E\n"},{"CreatedByName":"ddavis425","CreatedById":14725,"CreatedDateTime":"2012-10-03T23:27:48Z","Content":"\n\u003Cp\u003EI\u0027m not sure that we can create a true artificial intelligence capable of thinking, in my opinion the best we can do is get them to act like they are human. Even if we could make a true intelligence, how could we tell if it is real or if it is just copying behavior?\u003C/p\u003E\n"},{"CreatedByName":"Person012345","CreatedById":33728,"CreatedDateTime":"2012-10-03T23:31:49Z","Content":"\n\u003Cp\u003EThere are certain tests you could do to determine if they are capable of \u0022thinking outside the box\u0022.\u003C/p\u003E\n"},{"CreatedByName":"RedDwarfIV","CreatedById":11716,"CreatedDateTime":"2012-10-03T23:48:20Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Person012345\u0022 data-cite=\u0022Person012345\u0022\u003E\u003Cdiv\u003EThere are certain tests you could do to determine if they are capable of \u0022thinking outside the box\u0022.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003ETuring Test.\u003C/p\u003E\u003Cp\u003ESo long as it\u0027s more intelligent than damned Cleverbot, maybe we can have a proper conversation with an AI.\u003C/p\u003E\n"},{"CreatedByName":"Person012345","CreatedById":33728,"CreatedDateTime":"2012-10-03T23:51:19Z","Content":"\n\u003Cp\u003EEh, I don\u0027t like that test. People often said that cleverbot MUST have been human. It relies on the idea that people aren\u0027t idiots. But they are. I\u0027d prefer more objective standards.\u003C/p\u003E\n"},{"CreatedByName":"Vanamonde","CreatedById":27914,"CreatedDateTime":"2012-10-04T00:16:44Z","Content":"\n\u003Cp\u003EWhat in the world was Deutsch talking about when he said self-awareness is already possible for software? A program can certainly be recursively responsive to its own state, but that is orders of magnitude away from being able to say, \u0022Cogito ergo sum.\u0022 \u003C/p\u003E\u003Cp\u003E\u0022AGIs will indeed be capable of self-awareness\u0022 Not necessarily. Some science fiction authors I\u0027ve been reading lately (Charles Stross?) have made the interesting point that just as aircraft are not structured like birds despite performing similar functions, there\u0027s no reason for an effective AI to resemble human thought. (I\u0027m sure actually AI researchers have said the same thing, but I\u0027ve encountered it in SF.) Self-awareness is one aspect of human intelligence, but not the only one, and an AI wouldn\u0027t necessarily have or need it. \u003C/p\u003E\u003Cp\u003EOn the subject of science fiction, one of the more interesting worlds is Wright\u0027s Golden Age trilogy, where the lines between software, machine, and human are blurry and can be crossed easily.\u003C/p\u003E\n"},{"CreatedByName":"Nikolai","CreatedById":23085,"CreatedDateTime":"2012-10-04T00:54:09Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Person012345\u0022 data-cite=\u0022Person012345\u0022\u003E\u003Cdiv\u003EEh, I don\u0027t like that test.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EYou\u0027re far from alone. Turing wasn\u0027t trying to create an infallible proof of intelligence, though. He lived at a time when people\u0027s notions of what constituted \u0022human intelligence\u0022 were being seriously challenged. For a long time, it was reason that was considered the defining characteristic of human thought. After all, even \u003Cstrong\u003Eanimals\u003C/strong\u003E had emotions, for example. But then machines were created with the ability to manipulate symbols in a way we might call \u0022reason\u0022, and do it more reliably than the humans that created them!\u003C/p\u003E\u003Cp\u003ESo what \u003Cstrong\u003Eis\u003C/strong\u003E this thing we call \u0022human thought\u0022, anyway?\u003C/p\u003E\u003Cp\u003ETuring\u0027s suggestion was his test. If it could carry on a human-seeming conversation in a convincing way, could it be considered to be thinking like a human? Many people decided the test was good enough. Sure, it has holes, but so does \u003Cstrong\u003Eevery test for human thought yet devised\u003C/strong\u003E. (That\u0027s arguably the biggest obstacle to AI programming; for many things, we\u0027re not exactly sure how our own thoughts work. For example, we recognize ourselves in a mirror as nothing more than a reflection; but exactly \u003Cstrong\u003Ehow\u003C/strong\u003E do we do that?)\u003C/p\u003E\u003Cp\u003EThere\u0027s an important concept called \u0022meta-reasoning\u0022 that I think will prove the key to unlocking artificial intelligence. We humans can examine our thoughts; determine whether our examinations are valid; process whether those determinations might be reasonable; and so on, seemingly \u003Cem\u003Ead infinitum\u003C/em\u003E (at least in principle). Computers can only examine their own programming to a level that is determined by some elementary instructions somewhere.\u003C/p\u003E\u003Cp\u003EUltimately, the question is whether symbol manipulations can ever be arranged in patterns that resemble intelligence. I don\u0027t see any good reason why not (though that\u0027s hardly a proof that they can).\u003C/p\u003E\u003Cp\u003EOf course, there\u0027s also no guarantee that intelligence \u003Cstrong\u003Ehas\u003C/strong\u003E to resemble human intelligence. Our own brains were constructed from the inside out, and we still bear our evolutionary heritage in the bugs in our thinking (our tendency to follow charismatic leaders without question, our tendency to assume we\u0027re better at things than we really are, our tendency to collect information that agrees with our preconceived notions and discard information that disagrees as irrelevant, and so on). Perhaps AIs won\u0027t have those bugs, or will have different ones. Perhaps even emotions and considerations we think of as basic are more intimately tied into the conditions that led to the survival of our ancestors than we currently appreciate.\u003C/p\u003E\n"},{"CreatedByName":"Vanamonde","CreatedById":27914,"CreatedDateTime":"2012-10-04T01:35:07Z","Content":"\n\u003Cp\u003EThe insightful thing about Turing\u0027s test is that it\u0027s the only proof we have that other \u003Cem\u003Epeople \u003C/em\u003Eare thinking like we are, let alone machines. Neither can be directly observed, so his suggestion was to use the same method for both.\u003C/p\u003E\n"},{"CreatedByName":"phoenix_ca","CreatedById":50380,"CreatedDateTime":"2012-10-04T02:27:21Z","Content":"\n\u003Cp\u003EEmotions are \u003Cstrong\u003Enot\u003C/strong\u003E important. At all. In fact, I\u0027d strongly argue against them. Emotion gets in the way of rational thought.\u003C/p\u003E\u003Cp\u003EWhat would be more useful is ethics, which are fundamentally derived from logic and observation. I don\u0027t think a general intelligence would actually go on some sort of killing spree because of a consequentialist argument (a la I, Robot), because it would also realize the inherent problems with that sort of argument, just like humans realize the inherent problems in that argument when they apply logic.\u003C/p\u003E\u003Cp\u003EThe Turing test should not be misconstrued as a proof. It really, really isn\u0027t a proof. It depends on the infallibility of the human evaluating the other intelligence, which is just absurd.\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222012-10-04T02:29:39Z\u0022 title=\u002210/04/2012 02:29  AM\u0022 data-short=\u002211 yr\u0022\u003EOctober 4, 2012\u003C/time\u003E by phoenix_ca\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"PsychoLucario","CreatedById":14242,"CreatedDateTime":"2012-10-04T02:30:46Z","Content":"\n\u003Cp\u003Ep forCurrently we are missing some fundimental base for ai, I believe some day we with enough power, we will be able to emulate human consciousness because it is only a matter of refining the algorithms and models of human being, which like the super computer simulations today, are getting better and better, but at what point does it become conscious? I can\u0027t say because you will always know its just a simulation and can be changed,\u003C/p\u003E\u003Cp\u003EI\u0027ve always entertained the idea that ai of the future will be based on mirroring the neuron map of the human brain down to exacting detail, which will be possible with increasingly sophisticated scanning techniques like how DNA mapping has become possible on a chip today, \u003C/p\u003E\u003Cp\u003ETo say if this is emulating a soul, that\u0027s up for the people living at the time, but I do believe it is a hard problem because if you treat them like people, you have an exponentially increasing population of virtual citizens who can all be edited, those decisions are not up to me, its up to whoever births the first true ai and unleashes it on the world\u003C/p\u003E\n"},{"CreatedByName":"Nikolai","CreatedById":23085,"CreatedDateTime":"2012-10-04T15:10:06Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022phoenix_ca\u0022 data-cite=\u0022phoenix_ca\u0022\u003E\u003Cdiv\u003EEmotions are \u003Cstrong\u003Enot\u003C/strong\u003E important. At all. In fact, I\u0027d strongly argue against them. Emotion gets in the way of rational thought.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EWhat\u0027s curious is that modern psychological science has come to disagree with you. Research has shown that cognition and emotion are \u003Cstrong\u003Einterwoven systems\u003C/strong\u003E, with emotion helping logic decide what is desirable and what is virtuous.\u003C/p\u003E\u003Cp\u003E(In fact, there\u0027s been some work done with people who\u0027ve had damage to their ventromedial prefrontal cortex. People with damage to this area of their brain often have difficulty connecting emotions to how they make decisions or plans. Individuals thus afflicted can make long pro-versus-con lists and can obviously explore the implications of following a particular decision or plan, and in great detail, but never reach a final decision on their own, apparently because they lack emotional weight as some kind of stalemate-breaker that helps us to opt for one or the other.)\u003C/p\u003E\n"},{"CreatedByName":"LukeTim","CreatedById":4138,"CreatedDateTime":"2012-10-04T16:41:24Z","Content":"\n\u003Cp\u003ETrue artificial intelligence, which is indistinguishable from genuine human intelligence, is very possible... and so are artificial emotions (And emotions are incredibly, ridiculously important to a social species like ours... without them we would not have any of the technology or civilization we have today).\u003C/p\u003E\u003Cp\u003ETo suggest, however, that these artificial intelligences will be operating on devices anything like the computers we have to day is just naive. We cannot begin to imagine the sort of computing devices which will be in existence in 100 year\u0027s time... let alone 1000.\u003C/p\u003E\n"},{"CreatedByName":"Person012345","CreatedById":33728,"CreatedDateTime":"2012-10-04T19:01:44Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Vanamonde\u0022 data-cite=\u0022Vanamonde\u0022\u003E\u003Cdiv\u003EThe insightful thing about Turing\u0027s test is that it\u0027s the only proof we have that other \u003Cem\u003Epeople \u003C/em\u003Eare thinking like we are, let alone machines. Neither can be directly observed, so his suggestion was to use the same method for both.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EI\u0027ve talked to people, especially online, who I\u0027d be convinced are not thinking like a human. I mean, especially on certain issues, people will happily parrot the same pre-programmed responses over and over even after you explain to them the answer, simply because they don\u0027t have anything better and this is what they\u0027ve been told to say. I mean, ok, if all your looking for is a computer that \u0022thinks\u0022 like a human, then fine. But if you want to determine whether it\u0027s sentient then clearly this isn\u0027t a good test (since a cow is sentient and conscious, but I seriously doubt would be mentally capable of carrying on a human-like conversation even if it was physically capable of doing so) and it\u0027s not a good test if you want to test for any useful level of cognitive behaviour (because people often act like stupid machines, to some degree we \u003Cem\u003Eare\u003C/em\u003E just machines).\u003C/p\u003E\u003Cp\u003ENot saying we do it all the time of course, but just because you can convince me that I\u0027m talking to a person for 10 minutes doesn\u0027t necessarily mean you\u0027ve done anything particularly special (I mean, it\u0027s worthy of note maybe since I don\u0027t think that\u0027s been done before, but it doesn\u0027t mean you have a good AI). Perhaps if you built a robot that acted precisely human all the time I might be more likely to be excited.\u003C/p\u003E\n"},{"CreatedByName":"Person012345","CreatedById":33728,"CreatedDateTime":"2012-10-04T19:07:49Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Nikolai\u0022 data-cite=\u0022Nikolai\u0022\u003E\u003Cdiv\u003EWhat\u0027s curious is that modern psychological science has come to disagree with you. Research has shown that cognition and emotion are \u003Cstrong\u003Einterwoven systems\u003C/strong\u003E, with emotion helping logic decide what is desirable and what is virtuous.\u003Cp\u003E(In fact, there\u0027s been some work done with people who\u0027ve had damage to their ventromedial prefrontal cortex. People with damage to this area of their brain often have difficulty connecting emotions to how they make decisions or plans. Individuals thus afflicted can make long pro-versus-con lists and can obviously explore the implications of following a particular decision or plan, and in great detail, but never reach a final decision on their own, apparently because they lack emotional weight as some kind of stalemate-breaker that helps us to opt for one or the other.)\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EAs I have said before to people, you simply \u003Cem\u003Ecannot\u003C/em\u003E derive a particular course of action from logic alone. You need some sort of emotional/moral basics, to decide what you want to achieve. However, emotions are simply pre-programmed things that have evolved into our brains. They can easily be replaced with any other pre-programmed basic guidelines, emotion is not necessary, if we\u0027re talking about creating an intelligence.\u003C/p\u003E\n"},{"CreatedByName":"Moach","CreatedById":9,"CreatedDateTime":"2012-10-05T04:27:28Z","Content":"\n\u003Cp\u003EA purely logical method of thinking could be an infalible way of preventing any meaningful accomplishment whatsoever... If logic alone dictates that making no effort to develop new ideas has a lower \u0022cost\u0022 than attempting futher optimization even if at minimal risk, then logic will stay put....\u003C/p\u003E\u003Cp\u003EA man would not (most could, perhaps... But someone will have that urge to improve on the current affair of things)\u003C/p\u003E\u003Cp\u003ELet us consider a creature from a race such as vulcans, no emotions, just reason....\u003C/p\u003E\u003Cp\u003EHow would such species ever evolve past a minimum survival conditions era? - a logical being would consider death, even of a dear one a natural and necessary occurrence... Surviving until one is grown sufficiently to produce offspring should suffice, theres no reasoning to justify any further expense of \u0022more useful\u0022 energy\u003C/p\u003E\u003Cp\u003EIntelligence is not about making logical decisions.... If we even know what it is at all.... That we can think about the fact that we\u0027re thinking and reflect as to how well we\u0027re interpreting the way we interpret stimulae.... It\u0027s extremely hard just to define goals to what could be understood as an \u0022intelligent machine\u0022\u003C/p\u003E\u003Cp\u003EA large problem with trying to replicate human intelligence would be the undeniable fact that more often that not, humans are NOT intelligent....\u003C/p\u003E\u003Cp\u003ENot just by emotion clouding judgement, but frequently failing on the opposite side.... And of course, the fatal combination of failure to think properly in any of either way....\u003C/p\u003E\u003Cp\u003EThen there are darwin awards.... \u003C/p\u003E\u003Cp\u003EI\u0027m a game programmer by trade... AI is just a day at the office for me, but recurringly i find that what feels more human in machine decision-making is not that it acts intelligently, but that it simulates stupidity \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif\u0022 alt=\u0022:)\u0022\u003E\u003C/p\u003E\u003Cp\u003EOnce i inadvertedly produced a highly believable RTS opponent AI - you never knew what it would do next, it seemed to sometimes send out units to scout ahead or even to \u0022spy\u0022 on you and turn back.... Or it would just attack violently in some manner that appeared either as a greatly considered plan, or at times as a poorly antecipated turn of events....\u003C/p\u003E\u003Cp\u003EAll this fantastically human strategic machination was brought up by a unique concept:\u003C/p\u003E\u003Cp\u003E it was built only for demonstration, so the decisions of where to send platoons were simply - random!\u003C/p\u003E\u003Cp\u003EAI is an illusion.... And sometimes i wonder of the natural type isn\u0027t one as well\u003C/p\u003E\u003Cp\u003ECheers!\u003C/p\u003E\n"},{"CreatedByName":"phoenix_ca","CreatedById":50380,"CreatedDateTime":"2012-10-05T05:01:40Z","Content":"\n\u003Cp\u003EI don\u0027t see any compelling reason why an AI that is entirely different from human beings would necessarily need to be like us. To place such constraints on a hypothetical other intelligence is rather short-sighted. There are undoubtedly possible intelligences greater than ours that are so far detached from our own that we could not (at least intuitively) understand them. Thus I don\u0027t see why any AI necessarily needs to have anything that at all resembles human emotions. The arguments brought forward in favour of intelligence requiring emotion are based on evidence gathered from human minds, not non-human ones.\u003C/p\u003E\u003Cp\u003EI can grant you that some level of controlled and interpreted randomness may well be a requirement for another mind to function, but not emotion, at least not in the classical sense. Emotions drive persons to do incredibly inept and illogical actions, like killing others in fits of passion.\u003C/p\u003E\u003Cp\u003EThe argument that emotions are somehow required to determine what is virtuous, good or evil, also seems to me to be a continuation of the somewhat misguided assertion by Hume that one cannon derive an ought from an is. Well, no, we can use logic and science to aid in the determinations of what is moral, and better yet, it can possibly be done in a way that is universal to all minds, or rather, all complex systems capable of self-analysis and analysis of the universe.\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222012-10-05T05:05:39Z\u0022 title=\u002210/05/2012 05:05  AM\u0022 data-short=\u002211 yr\u0022\u003EOctober 5, 2012\u003C/time\u003E by phoenix_ca\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"Awaras","CreatedById":15671,"CreatedDateTime":"2012-10-05T05:25:22Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022PsychoLucario\u0022 data-cite=\u0022PsychoLucario\u0022\u003E\u003Cdiv\u003Ep forCurrently we are missing some fundimental base for ai, I believe some day we with enough power, we will be able to emulate human consciousness because it is only a matter of refining the algorithms and models of human being, which like the super computer simulations today, are getting better and better, but at what point does it become conscious? I can\u0027t say because you will always know its just a simulation and can be changed\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EAnd you think that humans could not be \u0027changed\u0027 given sufficiently advanced technology?\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022PsychoLucario\u0022 data-cite=\u0022PsychoLucario\u0022\u003E\u003Cdiv\u003EI\u0027ve always entertained the idea that ai of the future will be based on mirroring the neuron map of the human brain down to exacting detail, which will be possible with increasingly sophisticated scanning techniques like how DNA mapping has become possible on a chip today, \u003Cp\u003ETo say if this is emulating a soul, that\u0027s up for the people living at the time, but I do believe it is a hard problem because if you treat them like people, you have an exponentially increasing population of virtual citizens who can all be edited, those decisions are not up to me, its up to whoever births the first true ai and unleashes it on the world\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EFirst of all, are you sure that WE have \u0027souls\u0027? What exactly is a \u0027soul\u0027? What makes you sure that a \u0027soul\u0027 is not just an emergent property of a sufficiently complex, adequately organised neural network, natural or artificial?\u003C/p\u003E\u003Cp\u003EAs I said previously, given advances in neural imaging, in the understanding of the functioning of our own brains (that will be necessary if we want to create a true AI IMO - How can you recreate something you don\u0027t really understand yet?) and other technology, it will probably be no more difficult to \u0027edit\u0027 a person\u0027s brain and change whatever you want. The only thing preventing people from doing that will be laws and ethics, and the same should apply to virtual citizens...\u003C/p\u003E\n"},{"CreatedByName":"Khrissetti","CreatedById":29557,"CreatedDateTime":"2012-10-05T11:03:05Z","Content":"\n\u003Cp\u003EThe problem I think we have is that we\u0027re trying to run before we can crawl with AI. Human intelligence doesn\u0027t spring forth fully formed in one jump and yet that is precisely what we try to make AIs do.the human mind grows gradually from somethnig less developed than even simple AIs when we\u0027re in the womb.\u003C/p\u003E\u003Cp\u003EIn addition, our intelligence is adapted to operating a human body, interacting with a human world and interacting with other humans. An AI, grown organically would obviously develop a very different intelligence for the world it finds itself in.\u003C/p\u003E\u003Cp\u003EPerhaps this is how we should let our AIs develop, letting them slowly, surely piece themselves together allowing even fatal mistakse to add up over the period of a decade or two in the presence of other developing AIs. We might not recognise the intelligence we create but we have to be understanding parents to our technological children and let them develop and grow outside our narrow expectations.\u003C/p\u003E\n"},{"CreatedByName":"Accelerando","CreatedById":543,"CreatedDateTime":"2012-10-05T11:28:23Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Person012345\u0022 data-cite=\u0022Person012345\u0022\u003E\u003Cdiv\u003EAs I have said before to people, you simply \u003Cem\u003Ecannot\u003C/em\u003E derive a particular course of action from logic alone. You need some sort of emotional/moral basics, to decide what you want to achieve. However, emotions are simply pre-programmed things that have evolved into our brains. They can easily be replaced with any other pre-programmed basic guidelines, emotion is not necessary, if we\u0027re talking about creating an intelligence.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EHappiness and sadness in and of themselves may be givens of the human condition, but when and how they are felt is hardly a simple pre-programmed thing with a simple and consistently easily identifiable set of triggers. Small changes can affect people and how they feel and think greatly. What preprogrammed guidelines, exactly, do you propose to implement in this hypothetical artificial being to the extent that it will be possible to create intelligence? Intelligence we can recognize as such?\u003C/p\u003E\n"},{"CreatedByName":"Foamy","CreatedById":608,"CreatedDateTime":"2012-10-05T11:51:57Z","Content":"\n\u003Cp\u003EI\u0027m a robotics student with a strong interest in philosophy so I\u0027ve thought about AI quite a bit over the last few years. This is a long one but hopefully someone reads it \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif\u0022 alt=\u0022:)\u0022\u003E\u003C/p\u003E\u003Cp\u003EFirstly the \u0027intelligence\u0027 part of AI is a very controversial word as intelligence is incredibly easy to create artificially, I mean my phone is perfectly capable of intelligently interpreting my actions and acting on them and in that way we have a form of AI in just about all computing devices. This is where the concept of \u0027strong\u0027 and \u0027weak\u0027 AI comes from. So \u0027strong AI\u0027 is basically actually artificial consciousness while \u0027weak\u0027 AI is the kind of stuff that google\u0027s search is using or your credit card company uses to detect spending patterns that suggest you\u0027ve had your details stolen.\u003C/p\u003E\u003Cp\u003EWeak AI is certainly possible, and is being used widely today and will lead to huge advantages for humanity. There\u0027s not a whole lot that \u0027strong\u0027 AI can do that \u0027weak\u0027 AI can\u0027t do just as well or better. This is why there\u0027s so much more funding and research going into weak AI.\u003C/p\u003E\u003Cp\u003EBut to be honest, strong AI is the interesting one. In this case you\u0027re aiming to actually create an entity you could consider conscious or alive. So my thinking for this is that to judge if this is even possible, we need to look at the absolute basics of consciousness. \u003C/p\u003E\u003Cp\u003ESo I think we can all agree that we\u0027re not the only conscious animal on earth, obviously dolphins, great apes, etc, are easily recognisable and testable as conscious. They\u0027re not as complex or as advanced as us however, so where\u0027s the cutoff where an animal\u0027s not \u0027intelligent\u0027 enough to be considered conscious? Well my opinion is that this is a spectrum, there\u0027s many areas to consciousness but mostly we can fit everything along a scale from not conscious to more conscious (as a side note, this would mean that we humans are not as \u0027concious\u0027 as is possible!).\u003C/p\u003E\u003Cp\u003ESo what\u0027s the key thing that decided your place on the \u0027consciousness\u0027 scale? Well, the number of neurons you\u0027ve got in your brain seems to be roughly related (the brain structure and configuration is pretty important too). So what is it about more neurons that makes things more intelligent? Well a neuron is pretty simple and can\u0027t do much alone but as a collective they can do a lot more. So you\u0027ve got a large number of simple little machines working together that creates the consciousness phenomenon. This suggests that the key to our consciousness (and other animals) is the sheer complexity of our neural network that gives rise to intelligence (the combination of many simple components reacting with each other giving rise to a collective intelligence).\u003C/p\u003E\u003Cp\u003ENow we\u0027re not perfect conscious beings but we\u0027re relatively very intelligent (and conscious) compared to a plant. So the key to this strong AI will be to something that can fit along this consciousness scale. Now here\u0027s my main argument for why it\u0027s impossible to have true strong AI on a regular computer:\u003C/p\u003E\u003Cp\u003EIf you took a PC like we have today (running on binary computations) and just made it infinitely fast and small and stuck it in a persons body and hooked up all the control systems, so it\u0027s basically a robot with a biological body, then is there any software you could run on it that would qualify it as conscious? The fact that all of the actions/thoughts of this robot would be defined in code means that any consciousness it shows would actually be a simulation of consciousness. Maybe that counts, I can\u0027t say for sure but my gut feeling is that this doesn\u0027t because it\u0027s not actually a complicated system. There\u0027s no complexity in a binary computer, the instructions it performs on the code are simple, it just does them quickly. So rather than lots of simple components working together to create a complex system, we have one simple component running extremely quickly to create the appearance of a complex system.\u003C/p\u003E\u003Cp\u003ENow here\u0027s the tricky bit, say you swapped the computer in the robot with a collection ob billions of little computers all wired up together like neurons? Does that count? My thought would be that it\u0027s farther along the spectrum than the original computer but not quite as far as a regular biological brain. The reason is that our neurons are each a collection of a huge number of much simpler mechanisms (chemical reactions).\u003C/p\u003E\u003Cp\u003ESo in conclusion, no I don\u0027t think philosophy has a damn thing to do with creating strong AI, there\u0027s no code to be written (or at least not much). Really it\u0027s just about creating an artificial recreation of the brain using simple mechanisms in a high quantity, then working out how to create the \u0027spark\u0027 that starts the whole thing moving so that, from the self perpetuating chain reaction between the components, a consciousness arises.\u003C/p\u003E\u003Cp\u003EThe good news? Others agree with me and there are several projects underway to do something just like this, it\u0027s early days and there\u0027s not a lot of money in it though so don\u0027t expect quick results but they\u0027ll keep slowly moving along that consciousness spectrum until one day in the future they have something nobody can deny is alive.\u003C/p\u003E\n"},{"CreatedByName":"Aescwulf","CreatedById":51988,"CreatedDateTime":"2012-10-05T12:18:24Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Ted\u0022 data-cite=\u0022Ted\u0022\u003E\u003Cdiv\u003EI was reading an article in the Guardian, a newspaper in the UK, and it was discussing how the missing property of your average Artificial Intelligence is the General Intelligence of it. In other words, the AI is unable to think about and view the world like a person would. This seemed interesting to me as isn\u0027t something you often think about, but when considered, you realise that a lot of fictional AIs did have this subtle property that really added to them.\u003Cp\u003EYou can read the article \u003Ca href=\u0022http://www.guardian.co.uk/science/2012/oct/03/philosophy-artificial-intelligence\u0022 rel=\u0022external nofollow\u0022\u003Ehere\u003C/a\u003E.\u003C/p\u003E\u003Cp\u003EWhat are your thoughts on it?\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EI agree on this once you have something that\u0027s questioning its own existence then you\u0027ve got intelligence and I firmly believe that the first man made thing that will get this intelligence will be the Internet just because its connected to everything and everything about everything is on it. \u003C/p\u003E\u003Cp\u003EBut then again could happen through \u0027evolution\u0027 like thing where as time goes on it will start becoming self aware ( cough SKYNET )\u003C/p\u003E\n"},{"CreatedByName":"Awaras","CreatedById":15671,"CreatedDateTime":"2012-10-05T12:38:20Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Foamy\u0022 data-cite=\u0022Foamy\u0022\u003E\u003Cdiv\u003EIf you took a PC like we have today (running on binary computations) and just made it infinitely fast and small and stuck it in a persons body and hooked up all the control systems, so it\u0027s basically a robot with a biological body, then is there any software you could run on it that would qualify it as conscious? The fact that all of the actions/thoughts of this robot would be defined in code means that any consciousness it shows would actually be a simulation of consciousness. \u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EWhat if you have an infinitely fast and small binary computer that is running a simulation of all neurons in a person\u0027s brain? If the simulation is accurate enough, shouldn\u0027t it allow conciousness?\u003C/p\u003E\n"},{"CreatedByName":"Moach","CreatedById":9,"CreatedDateTime":"2012-10-05T13:50:58Z","Content":"\n\u003Cp\u003Ethat might be one of the biggest questions known to man... together with \u0022are we alone?\u0022\u003C/p\u003E\u003Cp\u003Ebut then, scientists everywhere are more and more agreeing that most likely, we are not alone (tho why any other intelligent race would ever wanna play with us morons is another matter)\u003C/p\u003E\u003Cp\u003Edefine \u0022conciousness\u0022 - is it just a matter of knowing one\u0027s ability to reflect and be a critic of one\u0027s own thought? or is there more to it?\u003C/p\u003E\u003Cp\u003Ehow would we ever know if it\u0027s safe to unplug an \u0022intelligent machine\u0022 without \u0022killing\u0022 it?\u003C/p\u003E\u003Cp\u003Ethere are books and books and bad movies^2 about this....\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222012-10-05T13:55:21Z\u0022 title=\u002210/05/2012 01:55  PM\u0022 data-short=\u002211 yr\u0022\u003EOctober 5, 2012\u003C/time\u003E by Moach\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"Person012345","CreatedById":33728,"CreatedDateTime":"2012-10-05T13:57:35Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Moach\u0022 data-cite=\u0022Moach\u0022\u003E\u003Cdiv\u003EA purely logical method of thinking could be an infalible way of preventing any meaningful accomplishment whatsoever... If logic alone dictates that making no effort to develop new ideas has a lower \u0022cost\u0022 than attempting futher optimization even if at minimal risk, then logic will stay put....\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003ENo, but it doesn\u0027t. Go ahead and purely logically justify lowering the \u0022cost\u0022, minimizing risk etc.\u003C/p\u003E\n"}]}