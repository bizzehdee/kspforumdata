{"TopicId":69939,"ForumId":44,"TopicTitle":"FP64 \u002B FP64 = FP128? Is that possible?","CreatedByName":"Aghanim","CreatedById":76587,"CreatedDateTime":"2014-04-20T10:46:38Z","PageNum":1,"Articles":[{"CreatedByName":"Aghanim","CreatedById":76587,"CreatedDateTime":"2014-04-20T10:46:38Z","Content":"\n\u003Cp\u003EYes, I know that this question is probably as stupid as someone asking about if I install Windows 7 32 bit twice does it makes 64 bit question, but here is the question. If we have two FP64 processor, is it possible to combine them in software somehow to create quad precision number? And is it possible to combine two FP32 processor to create double precision number?\u003C/p\u003E\n"},{"CreatedByName":"andrewas","CreatedById":24662,"CreatedDateTime":"2014-04-20T11:57:39Z","Content":"\n\u003Cp\u003ENope. Quad precision is a thing, but no domestic cpus support them. If double is not good enough you can emulate higher precision in software, though that\u0027ll come with a performance hit. Don\u0027t try to code it yourself, find a math library that offers arbitrary precision. Another alternative is fixed point math. Integer artithmatic isn\u0027t faster than floating point anymore, but it\u0027s not much slower and you get constant accuracy across the entire range which may be helpful. 64 but fixed point can model the entire solar system at nanometer precision if I remember rightly.\u003C/p\u003E\n"},{"CreatedByName":"Luis","CreatedById":55075,"CreatedDateTime":"2014-04-20T17:20:08Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022andrewas\u0022 data-cite=\u0022andrewas\u0022\u003E\u003Cdiv\u003ENope. Quad precision is a thing, but no domestic cpus support them. If double is not good enough you can emulate higher precision in software, though that\u0027ll come with a performance hit. Don\u0027t try to code it yourself, find a math library that offers arbitrary precision. Another alternative is fixed point math. Integer artithmatic isn\u0027t faster than floating point anymore, but it\u0027s not much slower and you get constant accuracy across the entire range which may be helpful. 64 but fixed point can model the entire solar system at nanometer precision if I remember rightly.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EI\u0027m afraid you remember incorrectly. 2^64 nanometres is just over 18 million kilometres, which is well inside the orbit of Mercury (69 million km) in our solar system, and about a quarter of the way to Jool in the KSP system.\u003C/p\u003E\n"},{"CreatedByName":"Nuke","CreatedById":10883,"CreatedDateTime":"2014-04-20T17:24:57Z","Content":"\n\u003Cp\u003Enewer chips have avx which i think is capable of 128bit fp math (my i7 has this), avx2 which came out last july doubled this to 256bit. this will be upgraded again to avx-512 some time in the next couple generations of processors. even the aging x87 instruction set is capable of 80-bit floating point maths.\u003C/p\u003E\u003Cp\u003Ethe problem is every time a new hardware capability comes out, it takes forever for software developers to start making use of it, because they still have to support the legacy bunch and their aging cpus/gpus. and its easier to just use the legacy instructions than it is to conditionally utilize one or the other based on the user\u0027s hardware.\u003C/p\u003E\u003Cp\u003Eyou can do soft float math, but this is costly. there are infinite* precision libraries often used for scientific purposes.\u003C/p\u003E\u003Cp\u003E*you can have as much or as little precision as you want. of course this is limited by amount of ram on your rig and the amount of time you want to wait for an add or a multiply.\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222014-04-20T17:38:50Z\u0022 title=\u002204/20/2014 05:38  PM\u0022 data-short=\u002210 yr\u0022\u003EApril 20, 2014\u003C/time\u003E by Nuke\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"andrewas","CreatedById":24662,"CreatedDateTime":"2014-04-20T21:19:30Z","Content":"\n\u003Cp\u003Eavx(2) allows you to work with 128(256) bits of data at a time, but you still don\u0027t get quad precision, just the ability to work with 2(4) doubles at the time time. \u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Luis\u0022 data-cite=\u0022Luis\u0022\u003E\u003Cdiv\u003EI\u0027m afraid you remember incorrectly. 2^64 nanometres is just over 18 million kilometres, which is well inside the orbit of Mercury (69 million km) in our solar system, and about a quarter of the way to Jool in the KSP system.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EYeah ... doing the math again your resolution is a couple of microns to a couple of centimeters depending on how you define \u0027solar system\u0027. The point is that 64 bit fixed math gives you either huge range, huge resolution or some combination of both, and is sometimes a viable alternative to 64 bit floating point which only gives 53 bits of precision, the other 11 are used to store how big the number is.\u003C/p\u003E\n"},{"CreatedByName":"xEvilReeperx","CreatedById":75857,"CreatedDateTime":"2014-04-20T21:56:54Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Aghanim\u0022 data-cite=\u0022Aghanim\u0022\u003E\u003Cdiv\u003EYes, I know that this question is probably as stupid as someone asking about if I install Windows 7 32 bit twice does it makes 64 bit question, but here is the question. If we have two FP64 processor, \u003Cstrong\u003Eis it possible to combine them in software somehow\u003C/strong\u003E to create quad precision number?\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThe only limitation to precision is memory if you\u0027re working in software\u003C/p\u003E\n"},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2014-04-20T22:10:07Z","Content":"\n\u003Cp\u003ESSE2 can already do 2 double precision operations at a time. But no, performing two double operations at the same time doesn\u0027t give you 128 bit precision. However, for many practical applications, where exponent does not change much, 256 bit integer math gives you the same results. AVX2 does, indeed, allow you to perform 256 bit integer operations, which you can use to fake 128 bit floating point math in most cases.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003EThe only limitation to precision is memory if you\u0027re working in software\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003ETrue. But I think, the implication is a way to combine data without significant loss of performance, which is not going to be the case.\u003C/p\u003E\n"},{"CreatedByName":"Nuke","CreatedById":10883,"CreatedDateTime":"2014-04-20T22:42:31Z","Content":"\n\u003Cp\u003Ewith 256 bits you could do 128.128 fixed point math. that would give you pretty good precision, about 38 orders of magnitude either side of the decimal point. and unlike with floating point you can do operations between big and small numbers, and you never have to screw with epsilon values when doing compares, mt, lt, mte, lte. of course fixed point isnt that simple though. adds and subtracts of same precision can be done just fine, but multiplies and divides need higher precision intermediates to prevent overflows and loss of precision respectively. of course if you want to do operations between different fixed point formats you can do that but you need room to shift sometimes.\u003C/p\u003E\u003Cp\u003Eboth fixed and float have their quirks though. fixed cant do infinity or negative infinity, but dont ever result in nan or quantization error, and gives you predictable precision (float has a non linear precision curve with magnitude). the other side is they can overflow on you. fixed point is faster than soft float, but it cant beat hard float because modern cpus have faster fpus than integer units.\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222014-04-20T23:08:24Z\u0022 title=\u002204/20/2014 11:08  PM\u0022 data-short=\u002210 yr\u0022\u003EApril 20, 2014\u003C/time\u003E by Nuke\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2014-04-20T22:51:30Z","Content":"\n\u003Cp\u003EThat\u0027s a bad idea. Because prior to multiplying these together, you\u0027d do a 128 bit shift to the right. If you happen to work with small numbers, you\u0027d be losing most of your precision. You are much better off keeping track of the exponent somewhere in software, rather than having a truly fixed point.\u003C/p\u003E\n"},{"CreatedByName":"Nuke","CreatedById":10883,"CreatedDateTime":"2014-04-20T23:15:40Z","Content":"\n\u003Cp\u003Efixed point is really complicated. sometimes it works and sometimes you are slamming your head into the desk. i had to use it trying to do some filtering on imu data on an 8-bit mcu. doing trig, vector, and matrix math with fixed point numbers. i think i gave up. but im comfortable doing small stuff with fixed point maths.\u003C/p\u003E\n"},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2014-04-20T23:27:11Z","Content":"\n\u003Cp\u003EOf course. When you know in advance what sort of magnitudes you are going to be dealing with, you can just hard-code fixed point. Most MCU applications are going to be like this. But if you are writing something a little more general, it\u0027s not a lot of work to have computations done in fixed-point style, but with ability to adjust the position of the point. It\u0027s not true floating-point, because you don\u0027t adjust the point for every operation and for each operand. But that\u0027s why you don\u0027t lose much in terms of performance. You have to do shifts between multiplication operations anyways. Might as well hold the shift amount in one of the registers and shift by that, rather than by fixed amount. (Actually, is there even an immediate shift in SSE/AVX instruction sets?)\u003C/p\u003E\n"},{"CreatedByName":"Nuke","CreatedById":10883,"CreatedDateTime":"2014-04-20T23:30:04Z","Content":"\n\u003Cp\u003Eidk, ive never done fixed point on anything more powerful than an avr.\u003C/p\u003E\n"}]}