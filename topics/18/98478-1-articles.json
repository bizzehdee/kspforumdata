{"TopicId":98478,"ForumId":18,"TopicTitle":"With GPU is better for gamers AMD Radeon or NVIDIA Geforce","CreatedByName":"Pawelk198604","CreatedById":35539,"CreatedDateTime":"2015-02-01T18:36:03Z","PageNum":1,"Articles":[{"CreatedByName":"Pawelk198604","CreatedById":35539,"CreatedDateTime":"2015-02-01T18:36:03Z","Content":"\n\u003Cp\u003EI bought laptop with AMD Raedon but is show that i have Intel HD 4400 i wonder does is swith to Radeon when i try to launch KSP, Sims 4, MassEffect or Total War Rome 2 \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_cheesy.gif\u0022 alt=\u0022:D\u0022\u003E\u003C/p\u003E\n"},{"CreatedByName":"gmpd2000","CreatedById":37101,"CreatedDateTime":"2015-02-01T18:37:13Z","Content":"\n\u003Cp\u003EI\u0027m no expert, but Nvidia seems to work better for me.\u003C/p\u003E\u003Cp\u003EAlso, doesn\u0027t this belong to the Space Lounge?\u003C/p\u003E\n"},{"CreatedByName":"ZedNova","CreatedById":57175,"CreatedDateTime":"2015-02-01T18:46:52Z","Content":"\n\u003Cp\u003EIt should automatically switch to the Radeon GPU when you start up a game, if not you can change which applications will use it in the settings.\u003C/p\u003E\u003Cp\u003EThe Intel card is used for everything else to save battery power.\u003C/p\u003E\n"},{"CreatedByName":"Redjoker","CreatedById":68444,"CreatedDateTime":"2015-02-01T18:56:49Z","Content":"\n\u003Cp\u003ESince you are asking one question in your title and another in your post. \u003C/p\u003E\u003Cp\u003ENvidia and AMD\u0027s GPU are competitive with each other with each having its own drawbacks and advantages and to be able to tell which one would be better for you we would need more information. \u003C/p\u003E\u003Cp\u003E On the subject of your laptop, unless you bought a fairly expensive laptop it is unlikely to have a discrete GPU, so would you posting the model of the laptop and/or a link to a store page that sells it.\u003C/p\u003E\n"},{"CreatedByName":"linkxsc","CreatedById":67350,"CreatedDateTime":"2015-02-01T20:01:49Z","Content":"\n\u003Cp\u003EWell ive been using both all throughout my gaming career (since 03 when i built my first machine. It was ati then) and 90% of the time... it really doesnt matter. Nvidia does pull ahead when it comes to games that were optimized for it, but theres always cost as a factor. Either way if you spend 350-500 on a card you should be all set for a couple years either way. I find that nowadays, having a good speed processor and high speed ram has a bit more of an effect.\u003C/p\u003E\u003Cp\u003E(And when i say high speed i dont mean lol 4-8 processors. I mean a good quad core with 3.5-4ghz. Really for gaming due to how few games actually support multiple cores. If you could get a dual core at 4.5-5ghz, youd prolly be better off than some lol 8 core thing. But high speed processors like that can be expensive.)\u003C/p\u003E\u003Cp\u003EClean your heat sinks every few months though. I have had a raging overheated nvidia card once because the heat sinks are often too tightly spaced, and will cake up with dust over a few months.\u003C/p\u003E\u003Cp\u003EEdit, sry i got cut off there. Got a call and when answering hit post\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222015-02-01T20:09:56Z\u0022 title=\u002202/01/2015 08:09  PM\u0022 data-short=\u00229 yr\u0022\u003EFebruary 1, 2015\u003C/time\u003E by linkxsc\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"Leszek","CreatedById":119053,"CreatedDateTime":"2015-02-01T20:28:56Z","Content":"\n\u003Cp\u003EThe Intel HD 4400 is the on CPU video card. It is low end. Laptops with a discrete GPU\u0027s often are set to use the CPU video card most of the time and switch to the more powerful card when playing games. On my laptop (MSI Gaming laptop) the power light changes from white to red when using the Nvidia. For some games it didn\u0027t change automatically, as my laptop has an Nvidia card I go and change it so that it opens automatically for those games. Since you have a Radeon, you could do something similar with catalyst control center. The icon for that is either in the right click menu on an empty desktop, or in the bottom right by the time.\u003C/p\u003E\u003Cp\u003EIt is a good idea to see if you can find what the indication is on your particular laptop regarding what GPU it is using. Before I knew my power light changed colours I would think the game was lagging when in fact I was on the CPU video.\u003C/p\u003E\n"},{"CreatedByName":"Pawelk198604","CreatedById":35539,"CreatedDateTime":"2015-02-01T21:32:40Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Redjoker\u0022 data-cite=\u0022Redjoker\u0022\u003E\u003Cdiv\u003ESince you are asking one question in your title and another in your post. \u003Cp\u003ENvidia and AMD\u0027s GPU are competitive with each other with each having its own drawbacks and advantages and to be able to tell which one would be better for you we would need more information. \u003C/p\u003E\u003Cp\u003E On the subject of your laptop, unless you bought a fairly expensive laptop it is unlikely to have a discrete GPU, so would you posting the model of the laptop and/or a link to a store page that sells it.\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EIt\u0027s Lenovo B50-70.\u003C/p\u003E\n"},{"CreatedByName":"Redjoker","CreatedById":68444,"CreatedDateTime":"2015-02-01T22:07:28Z","Content":"\n\u003Cp\u003EAfter some research on laptops with an intergrated and discrete GPUs, if you go to device manager it should show you display devices. There a 3 possibilities here. \u003C/p\u003E\u003Cp\u003E1.Only the intel shows up, this means either yours does not have a radeon R5 M230 or you have a driver problem. \u003C/p\u003E\u003Cp\u003E2.Both an intel and amd show up, then you laptop can switch between gpus and will likely use the amd if on ac power. \u003C/p\u003E\u003Cp\u003E3.Only the amd shows up, then your laptop does have an R5 M230 and it is always on.\u003C/p\u003E\n"},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2015-02-01T23:33:22Z","Content":"\n\u003Cp\u003ENVidia tends to be better supported. They release more driver patches to fix issues in AAA games, and a lot of devs optimize for nVidia.\u003C/p\u003E\n"},{"CreatedByName":"Elthy","CreatedById":63317,"CreatedDateTime":"2015-02-01T23:37:06Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003EThey release more driver patches to fix issues in AAA games, and a lot of devs optimize for nVidia. \u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThats the reason why AMD is slower in the first benches of new games. After a month or two its most times equal, then both brand have their better games...\u003C/p\u003E\n"},{"CreatedByName":"longbyte1","CreatedById":17521,"CreatedDateTime":"2015-02-02T01:11:18Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022K^2\u0022 data-cite=\u0022K^2\u0022\u003E\u003Cdiv\u003ENVidia tends to be better supported. They release more driver patches to fix issues in AAA games, and a lot of devs optimize for nVidia.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EBut only if you buy the new higher end cards (GTX 600\u002B). Otherwise, NVIDIA is likely to not give you any extra \u0022stuff\u0022 like GeForce Experience or game optimizations. My card is 6 years old and it still runs games just fine, but CUDA kernels don\u0027t support my card (important when using Blender).\u003C/p\u003E\n"},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2015-02-02T04:46:39Z","Content":"\n\u003Cp\u003EThat\u0027s because you, effectively, need a DX11 compliant card to use CUDA efficiently. There were drivers to make it work with older cards, but there really isn\u0027t a point now. All CUDA software targets CUDA 3.0\u002B, and yeah, that\u0027s 600\u002B.\u003C/p\u003E\u003Cp\u003EThere were also some bad generations and bad years for nVidia, when ATI stuff was way ahead. But if the question is which card OP should buy, odds are, he\u0027ll be marginally happier with a modern nVidia card.\u003C/p\u003E\n"},{"CreatedByName":"Camacha","CreatedById":59088,"CreatedDateTime":"2015-02-02T05:48:28Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022K^2\u0022 data-cite=\u0022K^2\u0022\u003E\u003Cdiv\u003EBut if the question is which card OP should buy, odds are, he\u0027ll be marginally happier with a modern nVidia card.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EBoth brands provide pretty much the exact same experience. None is better, none is worse. There are some specific technologies that can be interested in either case, but for most \u003Cspan style=\u0022text-decoration:line-through;\u0022\u003Epeople\u003C/span\u003E gamers are not very relevant, and it can vary a bit between cards and generations, but flat out saying one is better than the other is folly.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022K^2\u0022 data-cite=\u0022K^2\u0022\u003E\u003Cdiv\u003ENVidia tends to be better supported. They release more driver patches to fix issues in AAA games, and a lot of devs optimize for nVidia.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThat really is not the case any more. Both AMD and Nvidia have agreements with game developers. It pretty much depends on the game you want to play whether this is true of not.\u003C/p\u003E\n"},{"CreatedByName":"Newt","CreatedById":131025,"CreatedDateTime":"2015-02-02T05:53:05Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Camacha\u0022 data-cite=\u0022Camacha\u0022\u003E\u003Cdiv\u003EThat really is not the case any more. Both AMD and Nvidia have agreements with game developers. It pretty much depends on the game you want to play whether this is true of not.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EI am pretty sure that Blender still only supports Nvidia. \u003C/p\u003E\u003Cp\u003EBut that is not a game.\u003C/p\u003E\n"},{"CreatedByName":"Camacha","CreatedById":59088,"CreatedDateTime":"2015-02-02T05:58:45Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Newt\u0022 data-cite=\u0022Newt\u0022\u003E\u003Cdiv\u003EI am pretty sure that Blender still only supports Nvidia.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EBlender runs fine on an AMD card, though I suspect you might be talking about the renderer. Cycles runs fine when combined with an AMD card too, though CPU rendering is required.\u003C/p\u003E\u003Cp\u003EBut yes, there are some (primarily production) user cases where CUDA is a neat thing to have, that is why I crossed out the term \u003Cem\u003Epeople\u003C/em\u003E in my earlier post. Though I must add there is a distinct shift towards OpenCL going - quite a few programs that used to be CUDA exclusive now are also OpenCL enabled.\u003C/p\u003E\n"},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2015-02-02T08:50:46Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Camacha\u0022 data-cite=\u0022Camacha\u0022\u003E\u003Cdiv\u003EBoth brands provide pretty much the exact same experience. None is better, none is worse. There are some specific technologies that can be interested in either case, but for most \u003Cspan style=\u0022text-decoration:line-through;\u0022\u003Epeople\u003C/span\u003E gamers are not very relevant, and it can vary a bit between cards and generations, but flat out saying one is better than the other is folly.\u003Cp\u003EThat really is not the case any more. Both AMD and Nvidia have agreements with game developers. It pretty much depends on the game you want to play whether this is true of not.\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EAre you familiar with the game development/update process? For starters, nVidia hardware is more common among developers. CUDA is not the last factor in that. While games don\u0027t use CUDA, a lot of the tools used in making games do. So any nVidia-related bugs tend to be caught really early on. Then it goes on to QA. nVidia there is also more prevalent. Partly because it\u0027s easier to have the same hardware across the entire studio, and partly because it \u003Ca href=\u0022http://store.steampowered.com/hwsurvey/directx/\u0022 rel=\u0022external nofollow\u0022\u003E\u003Cspan style=\u0022text-decoration:underline;\u0022\u003Ereflects market share\u003C/span\u003E\u003C/a\u003E. Finally, after the game goes out to users, nVidia generates more bug reports, simply because there are more nVidia cards out there. So any problems with nVidia hardware get fixed faster.\u003C/p\u003E\u003Cp\u003ESaying that nVidia vs AMD experience is identical simply because hardware is very similar is very naive. Yes, nVidia and AMD both have contracts with devs. There are devs out there that target AMD first. Majority of the devs, however, don\u0027t specifically target either, and still end up with better nVidia support.\u003C/p\u003E\u003Cp\u003EThe actual difference is marginal. Most gamers will never be aware of the quality change switching from one to another. But there is most certainly a difference, and it\u0027s silly not to go with hardware that gives you even that much better chances of having smooth experience.\u003C/p\u003E\n"},{"CreatedByName":"steve_v","CreatedById":69272,"CreatedDateTime":"2015-02-02T09:17:45Z","Content":"\n\u003Cp\u003EPretty much echoes my experiences, I\u0027ve owned both (never again AMD, but only because the Linux driver is awfull) and It does appear that NVIDIA gets feature support and bugfixes a fraction quicker than AMD. While the price/performance ratio is a case of back and forth, and generally pretty darn close between the two, NVIDIA does seem to get the polish first.\u003C/p\u003E\u003Cp\u003EShame there\u0027s only two real players in the GPU / CPU market now.\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222015-02-02T09:20:10Z\u0022 title=\u002202/02/2015 09:20  AM\u0022 data-short=\u00229 yr\u0022\u003EFebruary 2, 2015\u003C/time\u003E by steve_v\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"Camacha","CreatedById":59088,"CreatedDateTime":"2015-02-02T09:51:40Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022K^2\u0022 data-cite=\u0022K^2\u0022\u003E\u003Cdiv\u003EMost gamers will never be aware of the quality change switching from one to another. But there is most certainly a difference [...]\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EIt sounds like a great story, but I have never seen much definitive evidence to back it up. Looking at market share the numbers they vary a bit from source to source, but neither party seems to be convincingly on top. \u003C/p\u003E\u003Cp\u003EIt truly depends on the game what card is better for you, or more precisely, better for that specific application. Some games run better on one card, other games run better on others. This can be due to a number of factors - basic architecture, certain technologies used, sponsoring et cetera. Whatever the case, benchmarks show us this variance and it tends to be different every time.\u003C/p\u003E\u003Cp\u003E\u003Cspan style=\u0022font-size:8px;\u0022\u003E\u003Cspan style=\u0022color:#C0C0C0;\u0022\u003E- - - Updated - - -\u003C/span\u003E\u003C/span\u003E\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022steve_v\u0022 data-cite=\u0022steve_v\u0022\u003E\u003Cdiv\u003EPretty much echoes my experiences, I\u0027ve owned both (never again AMD, but only because the Linux driver is awfull) and It does appear that NVIDIA gets feature support and bugfixes a fraction quicker than AMD.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThough the sample group is awfully small, I cannot say I share this experience. I have switched brands almost every time I bought a new card the past ~15 years (a little under 2 years per card on average) and neither brand seems to have distinguished itself in any notable fashion. I based the decision on the merits of the cards every time, and continuous switching was the result.\u003C/p\u003E\n"},{"CreatedByName":"SargeRho","CreatedById":25468,"CreatedDateTime":"2015-02-02T10:02:27Z","Content":"\n\u003Cp\u003ETo me it seems like AMD\u0027s cards are better in terms of performance per unit of money spent, but you can get a higher performance with nVidia.\u003C/p\u003E\n"},{"CreatedByName":"78stonewobble","CreatedById":97559,"CreatedDateTime":"2015-02-02T10:05:10Z","Content":"\n\u003Cp\u003EWell perhaps I\u0027ve missed it, but I haven\u0027t really seen any comprehensive \u0022survey\u0022 of either brands: driver support, error rates, performance, cost, consumer satisfaction and so on. \u003C/p\u003E\u003Cp\u003EWithout that I\u0027d say for the casual user either is probably equally good. \u003C/p\u003E\u003Cp\u003EIf you then have specific needs... in a certain game or games or applications, then you need to look up benchmarks in those areas.\u003C/p\u003E\n"},{"CreatedByName":"Camacha","CreatedById":59088,"CreatedDateTime":"2015-02-02T10:10:53Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022SargeRho\u0022 data-cite=\u0022SargeRho\u0022\u003E\u003Cdiv\u003ETo me it seems like AMD\u0027s cards are better in terms of performance per unit of money spent, but you can get a higher performance with nVidia.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EAt the moment that is true. Though the top dog \u003Cem\u003Emost performance on a singe GPU core\u003C/em\u003E tends to switch with almost every generation release too.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u002278stonewobble\u0022 data-cite=\u002278stonewobble\u0022\u003E\u003Cdiv\u003EIf you then have specific needs... in a certain game or games or applications, then you need to look up benchmarks in those areas.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThat is pretty much the only sensible advice. If you have specific needs, look at benchmarks and make your pick. If not, pick the most performance for money and be happy. Or pick the other option and be equally happy, because you will probably never know the difference.\u003C/p\u003E\n"},{"CreatedByName":"K^2","CreatedById":57710,"CreatedDateTime":"2015-02-02T10:43:21Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Camacha\u0022 data-cite=\u0022Camacha\u0022\u003E\u003Cdiv\u003EIt sounds like a great story, but I have never seen much definitive evidence to back it up. Looking at market share the numbers they vary a bit from source to source, but neither party seems to be convincingly on top.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003ESteam hardware survey is by far the most comprehensive report, dwarfing statistical significance of just about any other analysis. And for what it\u0027s worth, hardware surveys and crash reports I\u0027ve seen from our titles are consistent with these figures. I don\u0027t know if you are operating on outdated, biased, or simply statistically insignificant data, but nVidia does currently have greater market share among gamers, and game developers most certainly do end up catering to nVidia more.\u003C/p\u003E\n"},{"CreatedByName":"Linear","CreatedById":26619,"CreatedDateTime":"2015-02-02T10:59:11Z","Content":"\n\u003Cp\u003EIf you\u0027re playing a wide range of games then go with nVidia - if you only play a few work out which one works better.\u003C/p\u003E\u003Cp\u003EPersonally, i\u0027ve used both types and the AMD cards always let me down somehow.\u003C/p\u003E\n"},{"CreatedByName":"Camacha","CreatedById":59088,"CreatedDateTime":"2015-02-02T11:04:11Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022K^2\u0022 data-cite=\u0022K^2\u0022\u003E\u003Cdiv\u003ESteam hardware survey is by far the most comprehensive report, dwarfing statistical significance of \u003Cp\u003Ejust about any other analysis. [...] I don\u0027t know if you are operating on outdated, biased, or simply statistically \u003C/p\u003E\u003Cp\u003Einsignificant data\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EI have looked at the different numbers available for market share, not just a survey on Steam. Steam numbers do not signify market share, as there is some obvious overlap and as a result the total percentage goes well past 100%.\u003C/p\u003E\u003Cp\u003EIf Steam numbers are any guide and your statements are true, we would see significant game development for Intel graphics. I am pretty sure neither of us wants to argue that is the case.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003EAnd for what it\u0027s worth, hardware surveys and crash reports I\u0027ve seen from our titles are consistent with these \u003Cp\u003Efigures.\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EFor what it\u0027s worth, they are not consistent with what I have seen \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif\u0022 alt=\u0022:)\u0022\u003E There does seem to be a general bias, but upon enquiry real reasons never materialize - outside of the mentioned specific user cases.\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222015-02-02T11:11:59Z\u0022 title=\u002202/02/2015 11:11  AM\u0022 data-short=\u00229 yr\u0022\u003EFebruary 2, 2015\u003C/time\u003E by Camacha\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"Kryten","CreatedById":348,"CreatedDateTime":"2015-02-02T11:13:25Z","Content":"\n\u003Cp\u003EThere\u0027s enough overlap that it depends on budget and what performance you\u0027re trying to get; you need to compare cards, not manufacturers. \u003Ca href=\u0022http://www.eurogamer.net/articles/digitalfoundry-2015-graphics-card-upgrade-guide\u0022 rel=\u0022external nofollow\u0022\u003EThis\u003C/a\u003E is a pretty good guide for that.\u003C/p\u003E\n"}]}