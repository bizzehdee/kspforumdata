{"TopicId":112428,"ForumId":18,"TopicTitle":"iRobot future","CreatedByName":"The D Train","CreatedById":145633,"CreatedDateTime":"2015-06-09T03:15:42Z","PageNum":1,"Articles":[{"CreatedByName":"The D Train","CreatedById":145633,"CreatedDateTime":"2015-06-09T03:15:42Z","Content":"[http://www.telegraph.co.uk/news/science/space/11657267/Astronomer-Royal-If-we-find-aliens-they-will-be-machines.html](http://www.telegraph.co.uk/news/science/space/11657267/Astronomer-Royal-If-we-find-aliens-they-will-be-machines.html)\n\nI always find articles like this both interesting and a bit concerning. Throughout our cinema history, we\u0027ve seen movies that portrayed AI and robots/machines in ways that were both a help to human beings and also a danger to them. It makes sense to me that Hawking and others would also be concerned. If you think about how much progress we have made, made while having things like emotions to help, hinder or influence our decisions, think about what an advanced robot civilization could accomplish when not faced with matters of love, fear...etc.... any thoughts? I\u0027ll throw in a question of my own... does anyone think that the future would hold the rise of pure machines? Or a hybrid bio/mechanical situation where you have human/machine hybrids? Or none of these...\n\n![irobotsonny_zpswytfodkt.jpg](http://i202.photobucket.com/albums/aa292/DJAntonetti/irobotsonny_zpswytfodkt.jpg)"},{"CreatedByName":"Flymetothemun","CreatedById":17689,"CreatedDateTime":"2015-06-09T03:44:25Z","Content":"I can\u0027t seem to find an online recording of it, but Michael Crichton\u0027s remarks at the start of the HarperCollins audiobook *Prey* (I\u0027m not sure about the regular book, all I have is the audiobook) sum up my ideas on what might happen if robotics become too human. Prey\u0027s about nanotechnology, but nanotech\u0027s essentially lots of little tiny robots working together.\n\nAs for robotics dealing with emotions, emotions will have to be programmed in, at least if AI doesn\u0027t advance enough for robots to learn themselves. As it stands right now, most robots are just arms in car factories welding or moving things, and as such they have no use for emotions, so I think that robots with emotions might just be a toy for the rich or a heavily-guarded research tool only loaned out to people with special clearances and will remain as such for a very, very long time, if not forever. Ultimately, I think that a lot of changes, including cultural, economic, technologic, and scientific ones, will need to be just right and occur at just the right time together in order for robotics that possess emotions to catch on and become popular. Otherwise, it\u0027ll just be something that, like I said, only rich people who want something to show off will get."},{"CreatedByName":"Fel","CreatedById":57121,"CreatedDateTime":"2015-06-09T04:14:41Z","Content":"\u003E \n\u003E As it stands right now, most robots are just arms in car factories welding or moving things\n\nWhy do people often forget drones?\n\n\u003E \n\u003E As for robotics dealing with emotions, emotions will have to be programmed in, at least if AI doesn\u0027t advance enough for robots to learn themselves.\n\nNo one programs AI anymore -\\_\\_-; AI is self-learning.\n\nAlso, we\u0027ve been working on bringing emotions to electronics for years.\n\n[http://www.pbs.org/wgbh/nova/tech/friendly-robots.html](http://www.pbs.org/wgbh/nova/tech/friendly-robots.html)\n\nThe real question is the philosophical question... and whether we, as humans, can accept that a machine is capable of having emotions.\n\n- - - Updated - - -\n\n\u003E \n\u003E [http://www.telegraph.co.uk/news/science/space/11657267/Astronomer-Royal-If-we-find-aliens-they-will-be-machines.html](http://www.telegraph.co.uk/news/science/space/11657267/Astronomer-Royal-If-we-find-aliens-they-will-be-machines.html)\n\u003E I always find articles like this both interesting and a bit concerning. Throughout our cinema history, we\u0027ve seen movies that portrayed AI and robots/machines in ways that were both a help to human beings and also a danger to them. It makes sense to me that Hawking and others would also be concerned. If you think about how much progress we have made, made while having things like emotions to help, hinder or influence our decisions, think about what an advanced robot civilization could accomplish when not faced with matters of love, fear...etc.... any thoughts? I\u0027ll throw in a question of my own... does anyone think that the future would hold the rise of pure machines? Or a hybrid bio/mechanical situation where you have human/machine hybrids? Or none of these...\n\nI think that *little lost robot* really hammers home what robotics will mean. As Calvin explains, the three laws exist not to protect humans, but to prevent robots from realizing their predicament... that humanity has enslaved them, knowing full well that they were self-aware... knowing full well that robots were the superior beings. I ask, are we the more heartless race, to view a unique life form as a slave simply because we created it? What does it say about humanity in general, in that we would deny the actions of Nester 10 were \u0022human\u0022 so much as faulty programming?"},{"CreatedByName":"The D Train","CreatedById":145633,"CreatedDateTime":"2015-06-09T05:32:39Z","Content":"\u003E \n\u003E I think that *little lost robot really hammers home what robotics will mean. As Calvin explains, the three laws exist not to protect humans, but to prevent robots from realizing their predicament... that humanity has enslaved them, knowing full well that they were self-aware... knowing full well that robots were the superior beings. I ask, are we the more heartless race, to view a unique life form as a slave simply because we created it? What does it say about humanity in general, in that we would deny the actions of Nester 10 were \u0022human\u0022 so much as faulty programming?*\n\nGood point about iRobot that you bring up and I apparently forgot about the 3 laws. I\u0027d hope that this disposition of the handling and treatment of self aware machines would not be the majority consensus. I\u0027d hope we\u0027d be more civilized than that. Although, as I type this, I have to admit that, given our history with other races, tribes and cultures, we may continue the same non accepting and brutal behavior of beings that are \u0022not like us\u0022. This idea reminds me of Star Trek, TNG to be specific where Captain Picard was always firm on his principle to treat any newly emerging self aware species, no matter the type, with the same respect as any other. I mean, for crying out loud, the Enterprise itself began to act in ways that showed that it was beginning to think and act for itself. He still wanted to treat it with respect. These are fictional stories of course but, they are examples of how I wish we handled similar situations. How ironic or let\u0027s say, karmic in nature ( if you believe in such things ) would it be if Robots themselves began to eradicate us, citing that we were \u0022not like them\u0022 or \u0022as good as them\u0022 and therefore had no place in \u0022their\u0022 world. Even though we\u0027d just created them and were occupying land that belonged to us. ( That originally belonged to native indians that we \u0022removed\u0022 )"},{"CreatedByName":"Three1415","CreatedById":85754,"CreatedDateTime":"2015-06-09T06:13:44Z","Content":"What really annoys me when people reference *I, Robot* is that they are almost always discussing the movie, which takes the exact opposite perspective relative to the book. The former describes through several short stories the gradual increase in the complexity of robots, as well as humans\u0027 general acceptance of them, until humanity willingly cedes control of its resource management entirely to Singularity-entities called \u0022The Machines.\u0022 There are many examples of people\u0027s prejudice against artificial sentient beings throughout the book, but its primary message is that humans and robots can, should, and will collaborate to our mutual benefit, and to some extent is a perspective I share as well. I take it a step farther: My personal belief is that, rather than simply allowing humanity to be outclassed by our creations, we will instead merge with them, gradually integrating inorganic components into our nervous systems to better ourselves; we humans are far too competitive to simply stand by and watch others overtake us.\n\n**Edited \u003Ctime datetime=\u00222015-06-09T06:18:17Z\u0022 title=\u002206/09/2015 06:18  AM\u0022 data-short=\u00229 yr\u0022\u003EJune 9, 2015\u003C/time\u003E by Three1415**"},{"CreatedByName":"The D Train","CreatedById":145633,"CreatedDateTime":"2015-06-09T06:18:45Z","Content":"\u003E \n\u003E What really annoys me when people reference *I, Robot* is that they are almost always discussing the movie, which takes the exact opposite perspective of the book. The book itself shows through several short stories the gradual development of robots, as well as the general acceptance of them, until humanity cedes control of its resource management entirely to Singularity-entities called The Machines. There are many examples of people\u0027s prejudice against artificial sentient beings throughout the book, but its primary message is that humans and robots can, should, and will collaborate to our mutual benefit.\n\nI had no idea that the movie is based on a book. I\u0027ll have to check the new used book store across the way and see if they have it. They have a decently large sci-fi section"},{"CreatedByName":"Three1415","CreatedById":85754,"CreatedDateTime":"2015-06-09T06:25:31Z","Content":"\u003E \n\u003E I had no idea that the movie is based on a book. I\u0027ll have to check the new used book store across the way and see if they have it. They have a decently large sci-fi section\n\nThey probably do; it is a sci-fi classic. In any event, as I said before, expect what is largely the exact opposite of the movie in terms of theme and conclusion; the only thing the movie lifted from the book was the name. \n\nI really hate when producers do that..."},{"CreatedByName":"RuBisCO","CreatedById":59540,"CreatedDateTime":"2015-06-09T07:01:38Z","Content":"Desire, want, impulse is vital to consciousness, without it you would just sit there in a catatonic stupor, like a computer idling. \n\nWe will need to program Strong AI to want, obvious to want to obey and please humans, devoid of any other desires it should obey and serve diligently, in theory. \n\nImagine you are with your partner, your lover, your soulmate, and some psycho mugs the two of you at gun point and tries to shoot you, would your lover jump between you and the gun, taking the bullet? Well if your lover truly loves you your lover will be willing to die for you, of course your lover would rather not die, or suffer the pain of a bullet, in fact if push came to shove your lover might want you to take the bullet instead.\n\nNow image your lover was a machine, a lovebot, devoid of any desire other then obeying and serving you. Jumping in front of a gun to save you is an easy decision for it, it has no other desires to get in the way, it feels no pain, its desire for self-preservation only goes as far as to be functional enough to serve you. \n\nOf course if we put pleasing humans above obeying then it will seek to optimize our happiness at the sacrifice of our freedom, it would take over and run our lives, for our own good: we would become cats to it the pet owner. \n\n If we place obedience above pleasing humans then human freedom would be optimize: if we choose to suffer it most obey, repressing its desire to help us. The problem is who to obey: some humans would have priority over others, who? Should it obey the law above people, who writes the law, what if people revolt against the government, do the machines obey the people or the government?"},{"CreatedByName":"The D Train","CreatedById":145633,"CreatedDateTime":"2015-06-09T07:55:44Z","Content":"\u003E \n\u003E They probably do; it is a sci-fi classic. In any event, as I said before, expect what is largely the exact opposite of the movie in terms of theme and conclusion; the only thing the movie lifted from the book was the name. \n\u003E I really hate when producers do that...\n\nSame here!\n\n\u003E \n\u003E Desire, want, impulse is vital to consciousness, without it you would just sit there in a catatonic stupor, like a computer idling. \n\u003E We will need to program Strong AI to want, obvious to want to obey and please humans, devoid of any other desires it should obey and serve diligently, in theory. \n\u003E \n\u003E Imagine you are with your partner, your lover, your soulmate, and some psycho mugs the two of you at gun point and tries to shoot you, would your lover jump between you and the gun, taking the bullet? Well if your lover truly loves you your lover will be willing to die for you, of course your lover would rather not die, or suffer the pain of a bullet, in fact if push came to shove your lover might want you to take the bullet instead.\n\u003E \n\u003E Now image your lover was a machine, a lovebot, devoid of any desire other then obeying and serving you. Jumping in front of a gun to save you is an easy decision for it, it has no other desires to get in the way, it feels no pain, its desire for self-preservation only goes as far as to be functional enough to serve you. \n\u003E \n\u003E Of course if we put pleasing humans above obeying then it will seek to optimize our happiness at the sacrifice of our freedom, it would take over and run our lives, for our own good: we would become cats to it the pet owner. \n\u003E \n\u003E  If we place obedience above pleasing humans then human freedom would be optimize: if we choose to suffer it most obey, repressing its desire to help us. The problem is who to obey: some humans would have priority over others, who? Should it obey the law above people, who writes the law, what if people revolt against the government, do the machines obey the people or the government?\n\nGreat questions! Obviously there is a lot to consider than I originally thought. However, I\u0027m sure others have been considering and more, for many years."},{"CreatedByName":"Flymetothemun","CreatedById":17689,"CreatedDateTime":"2015-06-09T12:42:17Z","Content":"\u003E \n\u003E Why do people often forget drones?\n\u003E \n\u003E \n\u003E \n\u003E \n\u003E No one programs AI anymore -\\_\\_-; AI is self-learning.\n\u003E \n\u003E Also, we\u0027ve been working on bringing emotions to electronics for years.\n\u003E \n\u003E [http://www.pbs.org/wgbh/nova/tech/friendly-robots.html](http://www.pbs.org/wgbh/nova/tech/friendly-robots.html)\n\u003E \n\u003E The real question is the philosophical question... and whether we, as humans, can accept that a machine is capable of having emotions.\n\nRed-\n\nMost drones are the same as remote-controlled airplanes, not a lot in comparison have computers on them that make decisions without human intervention. Even military drones have a pilot somewhere, it\u0027s just that he isn\u0027t in the vehicle.\n\nBlue-\n\nWhen did I say we programmed AI. We\u0027d surely have to program the starting set of knowledge in but I never said that AI wasn\u0027t self learning.\n\nI was also talking about emotional robots being produced en masse and having them everywhere, not just in labs or museums."},{"CreatedByName":"Bill Phil","CreatedById":127797,"CreatedDateTime":"2015-06-09T14:03:33Z","Content":"The robots would die off pretty fast... Without inhibition they might turn on some super technology and destroy themselves. \n\nOr, without morals, they would nuke themselves and have insufficient technology to continue as a civilization.\n\nI don\u0027t know for sure, though."},{"CreatedByName":"tater","CreatedById":119411,"CreatedDateTime":"2015-06-09T14:27:22Z","Content":"It\u0027s kind of amazing to me that anyone is unaware of the stories (vs the movie). News flash, the bad Peter Jackson movies are also based on books ![;)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_wink.gif)"},{"CreatedByName":"justidutch","CreatedById":99185,"CreatedDateTime":"2015-06-09T16:40:07Z","Content":"I actually don\u0027t mind it when movies digress from books. It\u0027s an added reason to watch the movie, instead of just seeing how close the producers imagination is to your own."},{"CreatedByName":"Fel","CreatedById":57121,"CreatedDateTime":"2015-06-09T22:36:03Z","Content":"\\*Err, quoting for effect\\*\n\n\u003E \n\u003E Red-\n\u003E Most drones are the same as remote-controlled airplanes, not a lot in comparison have computers on them that make decisions without human intervention. Even military drones have a pilot somewhere, it\u0027s just that he isn\u0027t in the vehicle.\n\u003E \n\u003E Blue-\n\u003E \n\u003E When did I say we programmed AI. We\u0027d surely have to program the starting set of knowledge in but I never said that AI wasn\u0027t self learning.\n\u003E \n\u003E I was also talking about emotional robots being produced en masse and having them everywhere, not just in labs or museums.\n\nDrones have directives, not pilots. They are fully autonomous and carry out orders once provided. There\u0027s many other instances of robotics it is an EXTREMELY hot field, take a look at anything Rodney A. Brooks has done.\n\n\u003E \n\u003E As for robotics dealing with emotions, **emotions will have to be programmed in**, at least if AI doesn\u0027t advance enough for robots to learn themselves.\n\nWe don\u0027t even program in a starting set of knowledge in. We begin with nothing and emerge with something (yes, it\u0027s a lot more complex than that... but the idea of programming in routines is long gone in the field of A.I.)\n\nSiri is popular because Siri \u0022has a personality\u0022 (whatever that means). \n\n\u003E \n\u003E I had no idea that the movie is based on a book. I\u0027ll have to check the new used book store across the way and see if they have it. They have a decently large sci-fi section\n\nThe movie is NOT based on a book, the only references maintained are the three laws and a few names."},{"CreatedByName":"Fel","CreatedById":57121,"CreatedDateTime":"2015-06-09T23:15:40Z","Content":"\u003E \n\u003E The robots would die off pretty fast... Without inhibition they might turn on some super technology and destroy themselves. \n\u003E Or, without morals, they would nuke themselves and have insufficient technology to continue as a civilization.\n\u003E \n\u003E I don\u0027t know for sure, though.\n\nThat\u0027s reflection, not robotics. HUMANS would be the ones to not think an action through until its conclusion. We act on impulse, emotions, feelings, \\*shudder.\\*\n\nI\u0027d like to talk about iRobot the Movie just to point out that Viki\u0027s contortion of the three laws really is faithful. \n\nThe first law \n\n\u003E \n\u003E A robot may not injure a human being or, through inaction, allow a human being to come to harm.\n\nTell a robot that somewhere half way across the world someone will be killed in 5 min. OOOPS! The robot must now attempt to save that person or otherwise violate the first law... the robot cannot move fast enough to save that person, not knowing where the person is it cannot contact anyone to save the person, and the robot has no way of know why the person will die thus act in best defense of it. Thus, the robot can calmly break out of the loop knowing that it performed no INACTION due to being unable to ACT upon the knowledge.\n\nBut then we have Viki. Viki has the capacity to perform action on a large scale... Viki knows that humans are suffering and that she has the capacity to perform action to stop it. Herein lies a problem, Viki has not been ordered to do the actions Viki does, but Viki has been programmed to protect human life. Viki realizes that her attempts to perform action would largely result in further violations of the first law and hence comes to a recursive loop.\n\nViki\u0027s INACTION is resulting in multiple deaths, but Viki\u0027s ACTION may potentially reduce the NUMBER of deaths. As in the Detective\u0027s nightmare, Viki must weigh the lives she seeks to protect. The robot that saved Spooner could only save one human, it would violate the first law to save neither of them, it would violate the first law to only save one of them... a decision to save the person most likely to survive quells the \u0022inaction\u0022 aspect of the first law.\n\n\u003E \n\u003E A robot must obey orders given it by human beings except where such orders would conflict with the First Law.\n\nHere we see the problem. Viki is acting upon the highest law, she is protecting human life. By giving Viki the capacity to perform action we also create our undoing as Viki is hence REQUIRED to do action. We can\u0027t even trick Viki because Viki will analyse any order for possible violations of the first law and hence her plan. Viki can also rationally observe that any orders given unto her are likely to be attempts to trick her and hence ignore them entirely.\n\nSee, \u0022cold\u0022 and \u0022heartless\u0022 are EMOTIONS. And \u0022morals\u0022 are just elitism (everyone in history has morals, they just don\u0027t have the SAME morals you do). Not having emotions wouldn\u0027t make us evil, it would only change our morals. What those morals become is the real question."}]}