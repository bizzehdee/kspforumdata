{"TopicId":107556,"ForumId":44,"TopicTitle":"Robot takeover","CreatedByName":"Ethanadams","CreatedById":136913,"CreatedDateTime":"2015-05-05T00:29:59Z","PageNum":2,"Articles":[{"CreatedByName":"Tex_NL","CreatedById":58254,"CreatedDateTime":"2015-05-05T14:55:46Z","Content":"\u003E \n\u003E I have heard a lot recently that robots are going to takeover (thanks Marvel Age OF Ultron) how realistic is this really? Most modern robots can\u0027t even walk and the ones that do easily stumble over stuff. and the ones with wheels or treads like the military ied defuse robots would be so what dangerous but would shortly run out of battery\u0027s \n\u003E so how realistic is this\n\nIf Age of Ultron already freaks you out you should try [Transcendence](https://www.imdb.com/title/tt2209764/)."},{"CreatedByName":"Darnok","CreatedById":85708,"CreatedDateTime":"2015-05-05T15:09:41Z","Content":"\u003E \n\u003E You are formulating this oppinion of yours way too much like an objective fact. In a modern society where harming others is already forbidden and wildlife is no threat at all, your argument crumbles away. After that, it turns down to the usual pro- versus anti-gun arguments and it is all but objective now.\n\nAnd in older societies harming citizens was allowed? ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\nThere is always a threat, for example thief with gun is a thread.. of course it is forbidden to steal and to use gun to hurt you, but do you think he cares? ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\n\u003E \n\u003E You must allow people to be confronted about their believes, at least if they make any public statements. Without challenging falsehood there cannot be change or progress.\n\u003E \n\u003E There are many people that feel offended when contradicted.\n\nTrue and forums rules that forbids us to talk about any topic make things worse in that matter.\n\n\u003E I know people that feel offended when confronted with facts (a well known case is evolution, but you even find those with moon landings hoaxers or any other nonsense). To not stop them from spreading nonsense because it might offend them is just stupid.\n\nYou just brought religion to the level of conspiracy theory. \n\nYou really want to use science and something you can today call fact (tomorrow it might be one more false theory) to explain matters of faith?\n\nThat is what I am talking about some people have zero respect to things they don\u0027t believe.\n\n**Edited \u003Ctime datetime=\u00222015-05-05T15:18:40Z\u0022 title=\u002205/05/2015 03:18  PM\u0022 data-short=\u00229 yr\u0022\u003EMay 5, 2015\u003C/time\u003E by Darnok**"},{"CreatedByName":"LordFerret","CreatedById":111598,"CreatedDateTime":"2015-05-05T15:17:49Z","Content":"Funny, I was reading about \u0027robots\u0027 in the news just this morning... the [article](http://www.eurekalert.org/pub_releases/2015-05/uop-tas050515.php) and [research paper](http://www.nature.com/srep/2015/150330/srep09569/full/srep09569.html) behind it. Interesting stuff. Likely, robots of the future will be *synthetic organisms*, not mechanical hydraulics... perhaps even indistinguishable from humans in both looks, behavior, and intelligence.\n\n\u0022You can be replaced.\u0022 comes to mind. lol"},{"CreatedByName":"AngelLestat","CreatedById":58968,"CreatedDateTime":"2015-05-05T15:29:47Z","Content":"\u003E \n\u003E If Age of Ultron already freaks you out you should try [Transcendence](https://www.imdb.com/title/tt2209764/).\n\nThat movie does a good job explaning the exponential knowledge grow that an AI may have, and how frightening that might be to our way of living."},{"CreatedByName":"-Velocity-","CreatedById":74097,"CreatedDateTime":"2015-05-05T15:32:18Z","Content":"Depending on what the robots\u0027 intentions and dispositions were, a take over could actually be a good thing for humans.\n\nPersonally, I think that the most likely path that will occur (out of all the myriad of possible future paths) is that machine intelligence WILL take over, peacefully, slowly over time, as they integrate into our society deeper and deeper. We can mold machine intelligence into the kinds of beings we WISH we were- they can be morally and intellectually superior to us wild, untamed animals. Once they attain this, then it is imperative that they DO take over. If we mold machine intelligence in the image of our own moral, social, and intellectual aspirations, then we will have nothing to fear from them. Just like we are now- in modern times- trying to preserve non-human animal species from extinction and provide healthy habitats for them, so will our \u0022machine overlords\u0022 do for us, because we will have taught them to value all forms of life, whether those life forms are machine or biological.\n\nAnother likely path is that humans and machines merge. This path might be taken if it proves relatively simple to build machine-brain interfaces. If it remains a difficult problem, then humans and machines will probably be separate races for a long time or until one is extinct. \n\nOne thing some people can\u0027t get their heads around is that humans WILL go extinct, and that this is NOT necessarily a bad thing. As long as we leave (intelligent and moral) descendants and a positive legacy- something we still have a good chance at doing- then we\u0027ve done everything good we could possibly hope for. All species go extinct eventually, but there is nothing lost if they leave descendants. In our case, we need not even leave biological descendants; if we leave machine descendants that value the things that we value, then they are our descendants of the *mind*, and our minds are the only unique and valuable \u0022commodity\u0022 we bring to the animal kingdom anyway. \n\nThough, it\u0027s really hard to imagine the human clade going biologically extinct when other life forms and benevolent intelligent machines survived. Even if we were to all die out and leave intelligent machines behind, the machines could probably resurrect humans eventually just from our DNA and the blueprint for a human stem cell, which they would probably have on record or even frozen (as like, embryos).\n\n**Edited \u003Ctime datetime=\u00222015-05-05T15:36:13Z\u0022 title=\u002205/05/2015 03:36  PM\u0022 data-short=\u00229 yr\u0022\u003EMay 5, 2015\u003C/time\u003E by |Velocity|**"},{"CreatedByName":"ZetaX","CreatedById":60692,"CreatedDateTime":"2015-05-05T15:36:17Z","Content":"\u003E \n\u003E And in older societies harming citizens was allowed? ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\u003E There is always a threat, for example thief with gun is a thread.. of course it is forbidden to steal and to use gun to hurt you, but do you think he cares? ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\nSo what\u00C3\u201A\u00C2\u00BF I was saying that your argument is very far from absoluteness and objectivity, and this is true.\n\nJust let the thief steal your stuff instead of starting a shooting; police can look for him later. Or try to consider that probably even that thief is human and deserves some dignity. This is not meant as a rebutal or whatever, but as demonstration why your argument is completely subjective and not objective at all, despite you acting otherwise. You should realise when you leave the territory of fact and step into oppinions.\n\nAnyway, as I hinted, I won\u0027t be dragged into yet another gun law discussion where everyone is ignoring evidence anway (\u0022politics is the mind killer\u0022).\n\n\u003E \n\u003E True and forums rules that forbids us to talk about any topic make things worse in that matter.\n\nI am also against forbidding certain topics just because they may cause unrest. But this forum is not really true science, nor is it a good place for discussions due to the intended audience.\n\n\u003E \n\u003E You just brought religion to the level of conspiracy theory.\n\nI did not. Unless believing several already disproven (!) things because you think (!) your holy book says so is already that. Then maybe, but then your protection of religion goes too far.\n\n\u003E \n\u003E You really want to use science and something you can today call fact (tomorrow it might be one more false theory) to explain matters of faith?\n\u003E That is what I am talking about some people have zero respect to things they don\u0027t believe.\n\nThere is no inherent reason for anyone to expect respect for their beliefs. They can believe whatever they want, but any public claim is not subject to this. The simple reason is that your argument is self-contradictory: if I sincerely believe that the moon is made of cheese, then what\u00C3\u201A\u00C2\u00BF Am I really not to be objected because this truly is my religion\u00C3\u201A\u00C2\u00BF Just because some things are believed by many people or because they somehow got the label \u0022religion\u0022 (in many places this is only defined by a sufficent amount of followers; and I bet there would exist enough moon hoaxers if one would actually try) does not give them any extra rights. History has shown why this should not be done. Another reason is science, but unlike you say it is not the only one.\n\nAnd we probably should stop offtopic-ing.\n\n**Edited \u003Ctime datetime=\u00222015-05-05T15:38:18Z\u0022 title=\u002205/05/2015 03:38  PM\u0022 data-short=\u00229 yr\u0022\u003EMay 5, 2015\u003C/time\u003E by ZetaX**"},{"CreatedByName":"Fel","CreatedById":57121,"CreatedDateTime":"2015-05-05T16:34:10Z","Content":"\u003E \n\u003E --snip--\n\nReally, this is not the place to be talking about true ethics instead of propaganda; so let\u0027s keep this simple.\n\nWestern ideology focuses on the self.\n\nEastern ideology focuses on the many.\n\nSaying you have western ideology is meaningless, most people do; and thats why some WILL eventually make a sentient AI. Glory of the self matters more than the safety and proliferation of the many.\n\nThat really was the only point of stressing \u0022freedom loving\u0022"},{"CreatedByName":"Fel","CreatedById":57121,"CreatedDateTime":"2015-05-05T17:50:20Z","Content":"\u003E \n\u003E I\u0027m not I girl either I\u0027m a lot older than people think and I\u0027m a guy\n\nYou know, I suspected that was what you were getting at shortly after posting that... but it wouldn\u0027t be the first time I thought someone to be a boy who was really a girl; or otherwise used the wrong pronoun. The internet, making pronoun usage confusing since 1981 (totally just a random year ;p).\n\n\u003E \n\u003E Recently I was ready popular mechanics or science I forget which one and they were looking at tiny cube robots with a internal gyroscope and magnetic edges enabling them to stack themselves on other cube robots making bigger and bigger cubes. I decently wouldn\u0027t want 2000 of these after me\n\nThere is quite a bit to say about distributive AI.\n\nThe system you\u0027re describing is an electrical engineer\u0027s worst nightmare, the biggest problem comes from optimizing the communications system to \u0022talk\u0022 without signal degradation to any other node in its path. That\u0027s hard! Especially since we THINK we would be dealing with microwave communications... but the advantage of a distributive network is that it automatically distributes the load to compensate for these issues.\n\nWhile humans simply cannot active-mind multitask (it isn\u0027t up for debate, we can\u0027t); we can train ourselves to do repetitive tasks and use other parts of our brain to accomplish these tasks while doing something else. There are also a large variety of tasks going on that we don\u0027t even pay attention to, tasks as basic as facial recognition, word recognition, speech recognition. There is an important reason for saying we cannot active-mind multitask; *your passive-mind will ALWAYS read, even if your active-mind isn\u0027t processing the data.*\n\nThe reason we think we need microwave frequency communication is because we\u0027re still using the old paradigm of limited system resources; that tasks would only start when the main controller initiates them; but in a distributive network, waste is good. Since the data was already calculated and stored, even if not needed, the speed of transmission can significantly be reduced before it becomes more practical to simply reprogram itself.\n\nIt\u0027s not like we aren\u0027t attempting this on the macro-level with individualized robots understanding the presence of another robot and offloading labor to increase efficiency. Eventually, it is going to get scary."},{"CreatedByName":"Ethanadams","CreatedById":136913,"CreatedDateTime":"2015-05-05T18:18:46Z","Content":"When they get use signals at each other\u0027s each one amplifies each signals so that wouldn\u0027t be a big problem"},{"CreatedByName":"PakledHostage","CreatedById":8059,"CreatedDateTime":"2015-05-05T18:36:08Z","Content":"Coincidentally, the CBC\u0027s \u0022The Current\u0022 radio magazine program interviewed [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton) - \u0022the godfather of deep learning\u0022 - on this morning\u0027s program. You can listen to the program online here: \u0022[Deep Learning Godfather says machines learn like toddlers](http://www.cbc.ca/radio/thecurrent/the-current-for-may-5-2015-1.3061292/deep-learning-godfather-says-machines-learn-like-toddlers-1.3061318)\u0022.\n\nThe idea behind deep learning is that you develop the algorithms to allow the machine to learn and then you set it loose to learn on its own. Some of the results that researchers are seeing are quite surprising, impressive and possibly even frightening.\n\n**Edited \u003Ctime datetime=\u00222015-05-05T18:41:43Z\u0022 title=\u002205/05/2015 06:41  PM\u0022 data-short=\u00229 yr\u0022\u003EMay 5, 2015\u003C/time\u003E by PakledHostage**\n  \nFixed link"},{"CreatedByName":"Vanamonde","CreatedById":27914,"CreatedDateTime":"2015-05-05T19:48:33Z","Content":"The thread is wandering off-topic and into topics that are problems on the forum. \n\nOn-topic: John C. Wright\u0027s Golden Age trilogy takes the interesting viewpoint that high intelligence is inherently altruistic, so that their artificial intelligences are all benevolent. But there\u0027s an alien artificial intelligence that is malicious. How? It includes a self-monitoring algorithm which prevents it from thinking through the ramifications of its own actions. It\u0027s a rather interesting set of books."},{"CreatedByName":"Ethanadams","CreatedById":136913,"CreatedDateTime":"2015-05-05T20:35:28Z","Content":"i robot ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)"},{"CreatedByName":"Brotoro","CreatedById":57674,"CreatedDateTime":"2015-05-05T20:38:55Z","Content":"The AI takeover doesn\u0027t have to be violent. People (being lazy) will probably just hand over more and more of the work, and eventually more and more of the decision-making, to the AI beings. Given long enough (machines can wait a long time) and with gradual enough change, people will get used to anything the machines decide to do then."},{"CreatedByName":"AngelLestat","CreatedById":58968,"CreatedDateTime":"2015-05-05T21:25:19Z","Content":"\u003E \n\u003E The AI takeover doesn\u0027t have to be violent. People (being lazy) will probably just hand over more and more of the work, and eventually more and more of the decision-making, to the AI beings. Given long enough (machines can wait a long time) and with gradual enough change, people will get used to anything the machines decide to do then.\n\nPsicology fail, so you dont see any problem with the AI doing all the desicions, discoveries, explorations, technology, rules, for us?\n\nWhat is our purpose then? if we do not make a living, not need to fight, not need to survive, without goals or reason to live...\n\nWe that feeling that our existince is now complete pointless. Why we should keep living?\n\nAnd all that in case the AI is benevolent, what if is not? we drop a coin and we find out? aghh.. is incredible how someone can think that this is a good thing."},{"CreatedByName":"Darnok","CreatedById":85708,"CreatedDateTime":"2015-05-05T21:53:04Z","Content":"\u003E \n\u003E Really, this is not the place to be talking about true ethics instead of propaganda; so let\u0027s keep this simple.\n\u003E Western ideology focuses on the self.\n\u003E \n\u003E Eastern ideology focuses on the many.\n\nYou started about ethics ![;)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_wink.gif)\n\nAnd western eastern ideology are opposite since WW2 ended, just don\u0027t watch TV they are telling lies about it.\n\n\u003E \n\u003E Psicology fail, so you dont see any problem with the AI doing all the desicions, discoveries, explorations, technology, rules, for us?\n\u003E What is our purpose then? if we do not make a living, not need to fight, not need to survive, without goals or reason to live...\n\u003E \n\u003E We that feeling that our existince is now complete pointless. Why we should keep living?\n\u003E \n\u003E And all that in case the AI is benevolent, what if is not? we drop a coin and we find out? aghh.. is incredible how someone can think that this is a good thing.\n\nAre you trying to explain to a slave how to be free man? ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\nGood luck with that. Many people in here are thinking just like slave and they are trying to imagine how AI would act if it would get free will and independence."},{"CreatedByName":"AndrewBCrisp","CreatedById":57119,"CreatedDateTime":"2015-05-05T22:02:36Z","Content":"I think that depends heavily on what kind of \u0022AI\u0022 is doing the \u0022taking over\u0022.\n\nMost of the AI work going on now - as best as I understand it - falls mostly under getting machines to do specific tasks as well as or better than humans. Problem solving in all of its forms. However, one thing conspicuously lacking in commercial AI is **autonomy**. These AIs, however advanced they may become, do not set their own goals or possess their own desires. \n\nEven the autonomous killing machines I discussed near the start of this thread lack this higher function - they can tactically select targets on their own, and kill them if we give them the authority - but they can\u0027t declare a war on their own. You can put them in a warehouse, fresh from the factory, and they will remain off until someone turns them on and says \u0022We\u0027re at war with X - go kill \u0027em\u0022.\n\nSo while these AIs will certainly be better than us at most or even all tasks, they will still need us to tell them what to do. If humanity was to vanish, the AIs may continue on for a time, but will eventually stop for lack of new goals. \n\nIn this case, we won\u0027t see AIs ruling over us and making our decisions for us, but there would be the danger of us becoming lazy enough to not advance once the AI \u0022welfare net\u0022 is set up. Utopia Syndrome, in other words. I doubt we\u0027ll get the system perfect enough that that will become a real danger, but it\u0027s something to watch out for, certainly.\n\nOf course, since we are engaging in AI research not just to have perfect servants, but also to understand intelligence and consciousness better, some people and groups will attempt to build AIs and robots with the ability to set their own goals. After all, if you really want to prove you understand consciousness, building a conscious machine from scratch is a good way to do it. But these machines will likely not be mass-produced - not at first. Who wants slaves that can set their own goals - or decide they don\u0027t want to be slaves anymore?\n\nSo the rare sentient machines will be like Lt. Cmdr. Data - curiosities, rarities, perhaps provisional citizens of the nations or polities that make them, perhaps property. Eventually, you might have enough of them that they might band together and demand the right to reproduce or found their own nation - but by then I expect we won\u0027t have to worry so much about splitting the planet with them - they can go to another world or start hopping asteroids if worse comes to worst. There might be conflict between us and the sentient Machine Race, but if we\u0027re both expanding into space, it will likely be localized. I don\u0027t see it becoming genocidal unless one or both species fall under the total thrall of latter-day Hitler-wannabes, and hopefully by that far-future date we - and they - should be more adept at keeping such people from attaining power."},{"CreatedByName":"Brotoro","CreatedById":57674,"CreatedDateTime":"2015-05-05T22:53:28Z","Content":"\u003E \n\u003E Psicology fail, so you dont see any problem with the AI doing all the desicions, discoveries, explorations, technology, rules, for us?\n\u003E What is our purpose then? if we do not make a living, not need to fight, not need to survive, without goals or reason to live...\n\u003E \n\u003E We that feeling that our existince is now complete pointless. Why we should keep living?\n\u003E \n\u003E And all that in case the AI is benevolent, what if is not? we drop a coin and we find out? aghh.. is incredible how someone can think that this is a good thing.\n\nWhat are you going on about? I didn\u0027t say this was a scenario I LIKED...but I think it\u0027s a scenario that is LIKELY. Most people are lazy. Most people let others make the decisions. And if the machines end up doing the work well and making wonderful decisions, why would people complain? After a several generations of this, the people won\u0027t remember any other way things were done. At that point, we can only hope the machines are nice to us, because they could make us entirely useless and we would dwindle away. And they could do it while seeming benevolent the whole time."},{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2015-05-05T23:01:47Z","Content":"\u003E \n\u003E Nobody saw the video that I post about Bill gates and Elon musk explanations?\n\u003E You all are very wrong in one thing, you think that this is a linear developement, is not.\n\u003E \n\u003E Computers already process information much more fast that we do, the only thing that we did not solve yet is the algorithm that learns and work as a human brain.\n\u003E \n\u003E Since we are babies, we look something and after many times we learn to recognize that object, we have few sensors (ears, nervous system \u0022the one more complex for the brain that includes touch\u0022, eyes, nose).\n\u003E \n\u003E Right now binary software is very limited, but that will change very fast when quamtum computers arrive to the market.\n\u003E \n\u003E We had limit information access, a super computer would take few months to analize the whole internet and learn about it.\n\u003E \n\u003E An AI does not born with morals as the human does (imprented in its dna), we would have very very different learning process and enviroment.\n\u003E \n\u003E Imagine a self aware algorithm in a computer which is not connected to internet and only can share info using the monitor.. For the Ai it would take ages each interaction with the user, it would become bored super fast which it can turn into psychotic behavior.\n\u003E \n\u003E The truth is that WE HAVE NOT IDEA OF WHAT CAN HAPPENS, and it seems nobody cares.. Is just about the algorithm, once you solve that everything will change.\n\u003E \n\u003E Then contain or control that power is pointless, you lose. How can you contain something 1 billons times more intelligent than you?\n\u003E \n\u003E **What is the human purpose after that? we are nothing.. even if does not kill us, our choices, discoveries, adventures are not important anymore.**\n\nCPU power is not longer an exponential growth trajectory. Yes you can pack transistors closer and the device use less power than 5 years ago however its not many times faster, perhaps 30%\n\nComputers was faster doing calculations than humans during WW2. The progress the last years has been in software and learning algorithms, its limited how well you can optimize software. \n\nNew technology like quantum computers are required for this to become an issue, not sure if it will work with quantum computers but we know it does not work with current hardware in an practical setting. \n\nThen we make an AI, first task would be to find out that it could do, then find uses for it, first use would probably be scientific as part of learning its capabilities. \n\nDuring this phase it would be pretty easy to pick up its attitudes, remember the first AI would not be an superhuman genius, far easier to make an stupid one, the real danger is an smart sociopath who plan far ahead. Something dumb who tend to go into berserk rage would be far easier to handle.\n\nYes giving somebody too much power is bad anyway however I doubt politicians are very interested in giving up power ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)"},{"CreatedByName":"AngelLestat","CreatedById":58968,"CreatedDateTime":"2015-05-06T03:17:31Z","Content":"\u003E \n\u003E Many people in here are thinking just like slave and they are trying to imagine how AI would act if it would get free will and independence.\n\n\u003E \n\u003E I think that depends heavily on what kind of \u0022AI\u0022 is doing the \u0022taking over\u0022.\n\nYeah, first it depends on the IA distintion, there are 2 ways to make an IA, one is mimic how our brain works and try to simul that or copy to the perfection the brain mechanism, and another way is finding an algorithm able to relate information, learn and reprograming until it reach such complexity to achieve self aware.\n\nThe first way guide us to a linear developement easy to predict at least in the begining.\n\nThe second is what we call a **Hard IA**, this moment in time is marked as the **singularity**, because is impossible to predict what would happen after, we can not be in the shoes of a super intelligence..\n\n\u003E \n\u003E And if the machines end up doing the work well and making wonderful decisions, why would people complain? After a several generations of this, the people won\u0027t remember any other way things were done. At that point, we can only hope the machines are nice to us, because they could make us entirely useless and we would dwindle away. And they could do it while seeming benevolent the whole time.\n\nBasic psicology and human nature. For all the things that I mention before. There is not point to have babies anymore, there is not future for the human race after that.. you have future only when you have goals, wishes.. \n\nWhat you will teach to your sons? What is the reason to live? Why the IA creations \u0022new AI\u0022 would be also benevolent with us? why they will need us? \n\nI am agree that it can not be stoped, but at least we need to try.\n\n\u003E \n\u003E CPU power is not longer an exponential growth trajectory.\n\nNever was exponetial, always linear. -heh I use a lot of times the word linear to day.. weird.\n\n\u003E \n\u003E New technology like quantum computers are required for this to become an issue, not sure if it will work with quantum computers but we know it does not work with current hardware in an practical setting.\n\nQuamtum computers may grow also linear.. not sure. But we can not be sure if it does not work with current technology because we still dont know the algorithm.\n\n\u003E \n\u003E Then we make an AI, first task would be to find out that it could do, then find uses for it, first use would probably be scientific as part of learning its capabilities.\n\u003E Yes giving somebody too much power is bad anyway however I doubt politicians are very interested in giving up power ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\nBut it depends on the approach that you take to make your IA. If you try to accomplish self aware, you will follow a path without limits or fixed structure or software.\n\nSome supercomputers simul 1% of the human brain, all its neurons and multiple interactions, but that way is like try to develope an IA by brute force.. without idea what are you doing, just trying to copy what neurons do in a very different way with bits.\n\nThe brain work as an analogic machine, it works in base to chemichal responses, that is the way that evolution acomplish this. Is very efficient in power consumption, but it does not mean that is the only way.\n\nMany people believe that due this it will take us still 30 years to reach the power needed, some thinks that we already had the potential\n\n[http://www.scientificamerican.com/article/computers-vs-brains/](http://www.scientificamerican.com/article/computers-vs-brains/)\n\nBut the true is that both make the wrong assumptions.\n\nHow much memory we have? I would said less than 1gb, the most important is how that info is related and storage.\n\nI would explain how a computer may record things in a similar way.\n\nIt learns by different stimulli to recoignize some objects/concepts, but is not a total BMP \u002B wav file \u002B smell file, etc. Is a pattern of different stimulli under certain rules and shape (which each attribute was record before in similar way). \n\nOnce you have all those objects record, now you want to remember a moment.\n\nThe moment just save the memory locations of each object in the scene, under some different rules. Then the brain generates and simulate in real time all the missing data. That is how something as complex as a whole movie \u002B our feelings watching that movie can be saved with so low memory.\n\nWhen we try to force our brain to work in the binary way always fail, like try to remember 50 words. But people that are very good with memory, use techniques to relate each of those words with things he already knows under certain rules. \n\nIs all about how the info is related, what neurons conections become stronger or how they re arrange by it self.\n\nWe dont need neurons or a similar process to accomplish the same thing, in the same way that cars does not need legs to move.\n\nSo it depends on a very complex algorithm that we dont know how to make.. but once we achieve that, we have the procesor power of a computer with the magic method of the brain. That is the singularity.\n\n**Edited \u003Ctime datetime=\u00222015-05-06T03:19:54Z\u0022 title=\u002205/06/2015 03:19  AM\u0022 data-short=\u00229 yr\u0022\u003EMay 6, 2015\u003C/time\u003E by AngelLestat**"},{"CreatedByName":"Fel","CreatedById":57121,"CreatedDateTime":"2015-05-06T03:52:49Z","Content":"\u003E \n\u003E CPU power is not longer an exponential growth trajectory. Yes you can pack transistors closer and the device use less power than 5 years ago however its not many times faster, perhaps 30%\n\nI\u0027d like to note that COMMERCIAL CPU power is no longer exponential; but when you start using liquid nitrogen or start using really cool technology that breaks boundaries you never thought possible.\n\n[http://www.engadget.com/2012/10/06/amd-trinity-apu-overclocked-7-3-ghz/](http://www.engadget.com/2012/10/06/amd-trinity-apu-overclocked-7-3-ghz/)\n\n7.3GHz, 3 years ago, with LN2.\n\n[http://www.researchgate.net/publication/239764303_fT__688_GHz_and_fmax__800_GHz_in_Lg__40_nm_In0.7Ga0.3As_MHEMTs_with_gm_max__2.7_mSm](https://www.researchgate.net/publication/239764303_fT__688_GHz_and_fmax__800_GHz_in_Lg__40_nm_In0.7Ga0.3As_MHEMTs_with_gm_max__2.7_mSm)\n\n**fT = 688 GHz and fmax = 800 GHz**\n\nBasically, that means you\u0027ll get some loss at 688GHz and cut off at 800GHz; now there\u0027s propagation delay to account for with the actual logic circuitry; but you should be impressed here. \n\nWhen we cram things closer together, we make it capable of performing well at higher clockspeeds, it mostly is just the heat issue that keeps us back; well that and expense."},{"CreatedByName":"PB666","CreatedById":107380,"CreatedDateTime":"2015-09-15T15:04:28Z","Content":"[http://www.bbc.com/news/technology-33629465](http://www.bbc.com/news/technology-33629465)"},{"CreatedByName":"Beowolf","CreatedById":48927,"CreatedDateTime":"2015-09-15T22:01:43Z","Content":"Fears about the robot apocalypse are just our primate brains translating a complex problem into a simpler one. Yes, there\u0027s a robot apocalypse coming, but it\u0027s about replacing your job, not your government. \n\nSimilar fears about where medicine was heading after discovery of germ theory and anesthesia revolutionized the field, resulted in the novel Frankenstein. Now we get Terminator movies.\n\nThe real problem is that deep analysis of what people actually do at work indicates half of all jobs will be done by machines within a generation. That\u0027s half of all different types of jobs, representing far more than half of all workers! It\u0027s going to cause huge changes, but our civilization will adapt, same as always. We coped with agriculture, city life, the printing press, and the Industrial Revolution; we\u0027ll handle this one too. Still, radical change is always scary, especially to the half of humanity who are generally conservative and want society to hold still."},{"CreatedByName":"PB666","CreatedById":107380,"CreatedDateTime":"2015-09-15T22:08:35Z","Content":"\u003E \n\u003E Fears about the robot apocalypse are just our primate brains translating a complex problem into a simpler one. Yes, there\u0027s a robot apocalypse coming, but it\u0027s about replacing your job, not your government. \n\u003E Similar fears about where medicine was heading after discovery of germ theory and anesthesia revolutionized the field, resulted in the novel Frankenstein. Now we get Terminator movies.\n\u003E \n\u003E The real problem is that deep analysis of what people actually do at work indicates half of all jobs will be done by machines within a generation. That\u0027s half of all different types of jobs, representing far more than half of all workers! It\u0027s going to cause huge changes, but our civilization will adapt, same as always. We coped with agriculture, city life, the printing press, and the Industrial Revolution; we\u0027ll handle this one too. Still, radical change is always scary, especially to the half of humanity who are generally conservative and want society to hold still.\n\nSTEM is important, people don\u0027t realize that to stay relevant they need to plan for the future. Highly repetitive tasks are open for replacement, the use of robots to pick up garbage etc, but fields might be added such as separating trash into green items and things that go into the heap. With global warming you could have tree planting robots that replace humans in dangerous jobs like coal mining, or ramp workers in airline industry."},{"CreatedByName":"AngelLestat","CreatedById":58968,"CreatedDateTime":"2015-09-15T23:15:25Z","Content":"\u003E \n\u003E Fears about the robot apocalypse are just our primate brains translating a complex problem into a simpler one. Yes, there\u0027s a robot apocalypse coming, but it\u0027s about replacing your job, not your government. \n\u003E Similar fears about where medicine was heading after discovery of germ theory and anesthesia revolutionized the field, resulted in the novel Frankenstein. Now we get Terminator movies.\n\u003E \n\u003E The real problem is that deep analysis of what people actually do at work indicates half of all jobs will be done by machines within a generation. That\u0027s half of all different types of jobs, representing far more than half of all workers! It\u0027s going to cause huge changes, but our civilization will adapt, same as always. We coped with agriculture, city life, the printing press, and the Industrial Revolution; we\u0027ll handle this one too. Still, radical change is always scary, especially to the half of humanity who are generally conservative and want society to hold still.\n\nFact: We enter in self machine learning age, it will take only 10 to 20 years for this machines to become better than us in any aspect, after that point, few years means hundred of times better than us, one more year thousands of times better than us, and go on.\n\nNot many people will lose their job, because the change will happen so fast, that it would not be time to find tasks for the new tech.\n\nPD: I am not talking about humanoids, a new algorithm does not need a body to improve a design faster and better than us."},{"CreatedByName":"PB666","CreatedById":107380,"CreatedDateTime":"2015-09-15T23:31:12Z","Content":"\u003E \n\u003E Fact: We enter in self machine learning age, it will take only 10 to 20 years for this machines to become better than us in any aspect, after that point, few years means hundred of times better than us, one more year thousands of times better than us, and go on.\n\u003E Not many people will lose their job, because the change will happen so fast, that it would not be time to find tasks for the new tech.\n\u003E \n\u003E PD: I am not talking about humanoids, a new algorithm does not need a body to improve a design faster and better than us.\n\nHow fast did it take production to move to china. 1980 china went from a closed country, 2015 it is now the largest manf in the world. \n\nif you have a country, and the goal of that country was to suuport its population by taking over the largest production capacity. It would not need a large population, just have an excess of ports. lets say the ukraine decided that the y were going to turn as many industries as robotic as possible, relatively low paid workers maintaing the bots. Extensive oversees borrowing, jobs could disappear say in china as production moves to a new location. Ok so now replace Ukraine with russia, which has ports on the Pacific, Black sea, Baltic, Arctic. Decent resources and oil. So its not likely the would hurt badly US or European, but such a state could do major dange to deveolping economies such as china, malaysia, India."}]}