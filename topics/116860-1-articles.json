{"TopicId":116860,"ForumId":44,"TopicTitle":"Sentient Computer","CreatedByName":"Voyager275","CreatedById":128829,"CreatedDateTime":"2015-07-26T09:37:30Z","PageNum":1,"Articles":[{"CreatedByName":"Voyager275","CreatedById":128829,"CreatedDateTime":"2015-07-26T09:37:30Z","Content":"What would be needed to make a sentient machine? Is it even possible to make a sentient machine like those in science fiction?"},{"CreatedByName":"Tex_NL","CreatedById":58254,"CreatedDateTime":"2015-07-26T09:43:28Z","Content":"Have you read about this on wikipedia yet? [https://en.wikipedia.org/wiki/Artificial_intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence)"},{"CreatedByName":"Voyager275","CreatedById":128829,"CreatedDateTime":"2015-07-26T09:56:20Z","Content":"\u003E \n\u003E Have you read about this on wikipedia yet? [https://en.wikipedia.org/wiki/Artificial_intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence)\n\nI read it but it doesn\u0027t state what kind of processing power would be needed if sentience is based of information processing speed"},{"CreatedByName":"Godot","CreatedById":16902,"CreatedDateTime":"2015-07-26T10:28:35Z","Content":"\u003E \n\u003E I read it but it doesn\u0027t state what kind of processing power would be needed if sentience is based of information processing speed\n\nWhich may be too hard to guess.\n\nThe human brain is massive parallel, which every neuron being some kind of processor in itself (insofar as it receives input, gives output to connected cells as a result of the input (and or own underlying processes) and also changes its own structure as a result of received input.\n\nANNs are an approximation to real neuronal networks, but so far they are tiny compared to the size of the biological neuronal network of the human brain.\n\nAnd so far we understand only a little bit of the processes that generate human consciousness/sentience (and part of it may be not in programming, but rather in the actual learning experiences humans have when growing up).\n\nTherefore I\u00C3\u201A\u00C2\u00B4d say it is too early to make predictions on the processing power needed for artificial sentience"},{"CreatedByName":"Shpaget","CreatedById":45577,"CreatedDateTime":"2015-07-26T10:40:04Z","Content":"First we need to define sentience.\n\nFrom Oxford dictionary:\n\n\u003E \n\u003E Definition of sentient in English:\n\u003E adjective\n\u003E \n\u003E Able to perceive or feel things\n\nwhich is a rather poor definition for the purposes of this discussion.\n\nA microcontroller with a simple light dependent resistor or a pressure plate is \u0022able to perceive or feel things\u0022. Would such a device be called sentient?"},{"CreatedByName":"Technical Ben","CreatedById":10512,"CreatedDateTime":"2015-07-26T10:49:03Z","Content":"People tend to define sentience as feeling in the same way they do. But also extend it to animals that feel in a similar way.\n\nThough people tend to define sapience as thinking and feeling in the same way a person does. As animals are observed to be different, we do not apply this ability or quality to most, if not all, animals.\n\nThis may give us definite cut offs between a person and a bird and a fly and a flower and a rock. Or it may give us gradual separation and differences.\n\nHowever, until we know how to **exactly** model one or the other, or all of them, it\u0027s rather hard to say and AI is \u0022the same\u0022 or not. So once we can model (if ever) human thinking and feeling, once we model animal thinking/reactions and feelings, then we can say yes or no to \u0022we can do the same with a computer\u0022.\n\nTheoretically, the answer is always \u0022yes\u0022. But there may be practical limitations to what we can construct, see the Rocket Equation for where we hit physical limits. We may just be unable to hold onto a brain and read it\u0027s patterns/arrangements long enough without damaging them, to be able to record and copy them. Or we may just be able to make a clock work fly and a clock work fish and a clock work person. Clock work Turing machines (computers) are totally possible, as as said, some things are too impractical though! So it may be too impractical to build a silicon \u0022brain\u0022 just as it\u0027s too impractical to build a clock work \u0022brain\u0022 or clock work \u0022Deep Blue\u0022 ( [https://en.wikipedia.org/wiki/Deep_Blue_%28chess_computer%29](https://en.wikipedia.org/wiki/Deep_Blue_%28chess_computer%29) ).\n\nFor now the answer has to be \u0022unknown\u0022, until we do more research or get wiser. ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\n**Edited \u003Ctime datetime=\u00222015-07-26T10:53:16Z\u0022 title=\u002207/26/2015 10:53  AM\u0022 data-short=\u00228 yr\u0022\u003EJuly 26, 2015\u003C/time\u003E by Technical Ben**"},{"CreatedByName":"Scotius","CreatedById":57622,"CreatedDateTime":"2015-07-26T11:44:13Z","Content":"This. We cant even say with 100% certainity that dolphins (which possess bigger and \u0027better\u0027 brains that we do) are intelligent or not. We need more Science on the subiect ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)"},{"CreatedByName":"Aanker","CreatedById":70274,"CreatedDateTime":"2015-07-26T11:45:51Z","Content":"Maybe sentience is just the sum of its parts, e.g. with the ability to perceive and feel, process this incoming data and analyze the consequences of actions based on it, arises automatically the sense of self-awareness \u0027in time and space\u0027 that humans seem to possess. We become aware of analyzing our environment, instead of acting automatically.\n\nWe can\u0027t be sure that sentience is a neatly defined quality. Maybe it is entirely illusory. Inevitably, a computer that matches the exact networking of the human brain but with different materials and parts should possess sentience (and other qualities of the human brain)."},{"CreatedByName":"Tex_NL","CreatedById":58254,"CreatedDateTime":"2015-07-26T11:55:59Z","Content":"\u003E \n\u003E ...\n\u003E For now the answer has to be \u0022unknown\u0022, until we do more research or get wiser. ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\nIndeed, we simply do not know ... yet.\n\nComputing power has been increasing exponentially since its invention. A modern smart phone dwarves the early 1960\u0027s room sized monstrosities when it comes down to mathematical power. And if [Moore\u0027s Law](https://en.wikipedia.org/wiki/Moore%27s_law) is to believed the end is still several decades in the future.\n\nCombine this with ground breaking development in quantum computers (those CAN do parallel calculations) and who knows where it\u0027ll end.\n\n[![Transistor_Count_and_Moore%27s_Law_-_2011.svg](https://upload.wikimedia.org/wikipedia/commons/0/00/Transistor_Count_and_Moore%27s_Law_-_2011.svg)](https://en.wikipedia.org/wiki/Moore%27s_law)"},{"CreatedByName":"Technical Ben","CreatedById":10512,"CreatedDateTime":"2015-07-26T12:04:24Z","Content":"Quantum computers though, have a risk of going back to the room sized computer for a singly byte of calculation power.\n\nPlus even with all the computational power in the world (the internet is not far off a single human brain in complexity/potential parts IIRC), we still don\u0027t know where to start on the software to run on it. XD"},{"CreatedByName":"Shpaget","CreatedById":45577,"CreatedDateTime":"2015-07-26T12:44:31Z","Content":"\u003E \n\u003E Quantum computers though, have a risk of going back to the room sized computer for a singly byte of calculation power.\n\u003E Plus even with all the computational power in the world (the internet is not far off a single human brain in complexity/potential parts IIRC), we still don\u0027t know where to start on the software to run on it. XD\n\nThe same was true when the first transistor was made. It was huge compared to a modern one and not very practical, certainly not for computation purposes. It took years to miniaturize them enough to make them a viable technology for computers.\n\nWhy would you expect quantum computers to skip the initial steps?"},{"CreatedByName":"DaMichel","CreatedById":93697,"CreatedDateTime":"2015-07-26T12:50:07Z","Content":"Some people are seriously trying to simulate a complete human brain, eventually. By 2023 the project is supposed to deliver some results ...\n\n[https://www.humanbrainproject.eu/discover/the-project/overview](https://www.humanbrainproject.eu/discover/the-project/overview)\n\nI suppose from a purely materialistic point of view, once it is possible to simulate all the neurons in the brain with all its connections, it would be possible to create a virtual human mind - provided we somehow miraculously get all the connections right. Might have to wait for a little while longer until our computers are powerful enough. We have 1,000 trillion synaptic connections. So i guess we need computer memory of the order of Petabytes to represent them in a simulation. ![:wink:](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_wink.gif)\n\nMeanwhile we can simulate little worms ![:D](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_cheesy.gif)[http://www.openworm.org/about.html](http://www.openworm.org/about.html)"},{"CreatedByName":"Technical Ben","CreatedById":10512,"CreatedDateTime":"2015-07-26T14:47:48Z","Content":"\u003E \n\u003E The same was true when the first transistor was made. It was huge compared to a modern one and not very practical, certainly not for computation purposes. It took years to miniaturize them enough to make them a viable technology for computers.\n\u003E Why would you expect quantum computers to skip the initial steps?\n\nI don\u0027t. However, I expect the same problem with QM computers to apply to silicon/transistor ones. Try making either the size of a human brain, and running off the same wattage, without overheating and with at least 50 years lifespan/service life (doable for silicon ![;)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_wink.gif) but not sure on the other requirements).\n\nDoing 1 thing really well is easy. Doing all at the same time? Then we hit natural limits of physics. Biology already works on the atomic scale, it already has a lead start on us, and theoretically may already be using the most efficient, thus only means, to get to it\u0027s goal. An example being, we can make jumb jets, but making something fly as well as a bird on the same power requirements with the same maintenance (IE, self maintaining)? We need a bird, not a robot then. ![:P](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_tongue.gif)"},{"CreatedByName":"lajoswinkler","CreatedById":79159,"CreatedDateTime":"2015-07-26T14:54:17Z","Content":"\u003E \n\u003E First we need to define sentience.\n\u003E From Oxford dictionary:\n\u003E \n\u003E which is a rather poor definition for the purposes of this discussion.\n\u003E \n\u003E A microcontroller with a simple light dependent resistor or a pressure plate is \u0022able to perceive or feel things\u0022. Would such a device be called sentient?\n\nThat\u0027s a totally crappy definition. I\u0027m very surprised such crap is found in Oxford dictionary.\n\n\u003E \n\u003E This. We cant even say with 100% certainity that dolphins (which possess bigger and \u0027better\u0027 brains that we do) are intelligent or not. We need more Science on the subiect ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\nInteligence is not \u0022it exists\u0022 or \u0022it does not exist\u0022. It is a spectrum. And yes, dolphins possess an amazing degree of intelligence *for a mammal, humans excluded*. Compared to humans, they\u0027re like retarded juveniles with decent motoric skills."},{"CreatedByName":"PakledHostage","CreatedById":8059,"CreatedDateTime":"2015-07-26T15:55:11Z","Content":"\u003E \n\u003E Plus even with all the computational power in the world (the internet is not far off a single human brain in complexity/potential parts IIRC), we still don\u0027t know where to start on the software to run on it. XD\n\nBut you also need to consider the recent advances that have been achieved with [deep learning](https://en.m.wikipedia.org/wiki/Deep_learning) algorithms (software) and [neurosynaptic processors](http://research.ibm.com/cognitive-computing/neurosynaptic-chips.shtml#fbid=6hJ2v1A-Ntd) (hardware). \n\nPerhaps the problem isn\u0027t a lack of processing power so much as the lack of an appropriate architecture? IBM\u0027s SyNAPSE chip has 1 million neurons, 256 million synapses, is the size of a postage stamp and runs on 70 mW. And that\u0027s only the beginning of what is very likely to be a new paradigm in computing.\n\n\u003Ciframe width=\u0022480\u0022 height=\u0022270\u0022 src=\u0022https://www.youtube.com/embed/t4kyRyKyOpo?feature=oembed\u0022 frameborder=\u00220\u0022 allowfullscreen=\u0022true\u0022\u003E\u003C/iframe\u003E\n\n**Edited \u003Ctime datetime=\u00222015-07-26T16:12:47Z\u0022 title=\u002207/26/2015 04:12  PM\u0022 data-short=\u00228 yr\u0022\u003EJuly 26, 2015\u003C/time\u003E by PakledHostage**\n  \nAdded link to video"},{"CreatedByName":"heng","CreatedById":126869,"CreatedDateTime":"2015-07-26T16:18:19Z","Content":"Also to consider:\n\nWhat you want, is it a sentient computer? or a sentient program?\n\nthe difference is only in semantics, i know. but a very thoroughly discussed philosophical question...\n\nam \u0022I\u0022 my thoughts, my feelings, my memories \\_only\\_? or is my \u0022hardware\u0022 an integral and inescapable part of my \u0022self\u0022?\n\nPersonally? I am part of the \u0027hard AI\u0027 opinion, that a deterministic program can achieve consciousness regardless of the underlying hardware - given sufficient complexity. Ever since i read \u0027G\u00C3\u0192\u00C2\u00B6del, Escher, Bach\u0027."},{"CreatedByName":"Branjoman","CreatedById":123426,"CreatedDateTime":"2015-07-26T16:18:45Z","Content":"Doesn\u0027t such AI need programming as well? Because if you need to program every single variable and it\u0027s output into the computer, AI suddenly becomes very unfeasible. I\u0027m pretty sure there is something called distributed processing, in which instead of you putting in complicated processes and commands into one program, many smaller programs with simpler commands essentially create their own goals (this also is modelled after nature, specifically animal behaviours, like termite behaviour)"},{"CreatedByName":"Technical Ben","CreatedById":10512,"CreatedDateTime":"2015-07-26T16:38:45Z","Content":"Seen Googles latest image processing system? It\u0027s scary \u0022clever\u0022. It is however limited.\n\nSoftware problems are not really much different than engineering problems, which are physics problems. Which is to say, we can engineer things \u0022like\u0022 other things, but exactly the same, so as to say \u0022this is a person\u0022 or \u0022this is a [virtual] worm\u0022?\n\nTake Boston Dynamics PetaMan as an example in engineering. It should be theoretically easy to replicate the mechanical and software systems the human body (or any biological system) uses, right? Well, we can get close, we can do faster or stronger. But can we get all the attributes and qualities? And that\u0027s a mainly engineering problem, with power and control mechanics, not a software one with a few billion neurons worth of information to track. ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif)\n\nPS, I don\u0027t watch videos about \u0022scary computers can learn and hit the singularity\u0022. Mainly because diminishing returns and limits to hardware apply to AI as much as they do to squishy humans. An AI is as dangerous as any other human, car, bomb or animal. It\u0027s not anything \u0022special\u0022 beyond that (if AI can self improve at any speed, it will not be as fast as the existing intelligence, people and animals. Unless we magic in magic hardware for it to run on).\n\n**Edited \u003Ctime datetime=\u00222015-07-26T16:41:01Z\u0022 title=\u002207/26/2015 04:41  PM\u0022 data-short=\u00228 yr\u0022\u003EJuly 26, 2015\u003C/time\u003E by Technical Ben**"},{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2015-07-26T16:48:38Z","Content":"\u003E \n\u003E Quantum computers though, have a risk of going back to the room sized computer for a singly byte of calculation power.\n\u003E Plus even with all the computational power in the world (the internet is not far off a single human brain in complexity/potential parts IIRC), we still don\u0027t know where to start on the software to run on it. XD\n\nAll supercomputers are hall sized. This is hard to change even if we manage to increase cpu power 100 times. \n\nI think we will need new hardware for an sentinel ai, more like quantum computers or neural nets."},{"CreatedByName":"PakledHostage","CreatedById":8059,"CreatedDateTime":"2015-07-26T17:12:28Z","Content":"\u003E \n\u003E PS, I don\u0027t watch videos about \u0022scary computers can learn and hit the singularity\u0022.\n\nYour loss... [Jeremy Howard](https://en.m.wikipedia.org/wiki/Jeremy_Howard_%28entrepreneur%29) isn\u0027t some crackpot. Among other things, he\u0027s a Distinguished Research Scientist at the University of San Francisco, Data Science Faculty Member at Singularity University and Chief Executive Officer and Founder of Enlitic. The title of his TED talk video may be a bit sensationalist, but he almost certainly knows more than anyone here about the state of the art in AI."},{"CreatedByName":"comham","CreatedById":43245,"CreatedDateTime":"2015-07-26T17:47:10Z","Content":"\u003E \n\u003E PS, I don\u0027t watch videos about \u0022scary computers can learn and hit the singularity\u0022. Mainly because diminishing returns and limits to hardware apply to AI as much as they do to squishy humans. An AI is as dangerous as any other human, car, bomb or animal. It\u0027s not anything \u0022special\u0022 beyond that (if AI can self improve at any speed, it will not be as fast as the existing intelligence, people and animals. Unless we magic in magic hardware for it to run on).\n\nNot to hype it up too much, but a self improving AI is the nuclear bomb of the information age. It\u0027s called an Intelligence Explosion, or Hard Takeoff AI. I recommend the book Superintelligence by Nick Bostrom, although that\u0027s more about design strategies for a safe AI than \u0022what does it take to make an AI?\u0022.\n\nConsciousness is a Hard Problem."},{"CreatedByName":"PakledHostage","CreatedById":8059,"CreatedDateTime":"2015-07-26T18:25:11Z","Content":"\u003E \n\u003E Consciousness is a Hard Problem.\n\nAnd to be clear, Voyager275\u0027s question was about sentience, not sapience. Sentience is not the same thing as (nor does it even require) consciousness."},{"CreatedByName":"Shpaget","CreatedById":45577,"CreatedDateTime":"2015-07-26T18:27:03Z","Content":"Computerphile recently did a couple of videos on the matter.\n\n\u003Ciframe width=\u0022480\u0022 height=\u0022270\u0022 src=\u0022https://www.youtube.com/embed/tcdVC4e6EV4?feature=oembed\u0022 frameborder=\u00220\u0022 allowfullscreen=\u0022true\u0022\u003E\u003C/iframe\u003E\n\n\u003Ciframe width=\u0022480\u0022 height=\u0022270\u0022 src=\u0022https://www.youtube.com/embed/5qfIgCiYlfY?feature=oembed\u0022 frameborder=\u00220\u0022 allowfullscreen=\u0022true\u0022\u003E\u003C/iframe\u003E"},{"CreatedByName":"Technical Ben","CreatedById":10512,"CreatedDateTime":"2015-07-26T19:16:17Z","Content":"\u003E \n\u003E Your loss... [Jeremy Howard](https://en.m.wikipedia.org/wiki/Jeremy_Howard_%28entrepreneur%29) isn\u0027t some crackpot. Among other things, he\u0027s a Distinguished Research Scientist at the University of San Francisco, Data Science Faculty Member at Singularity University and Chief Executive Officer and Founder of Enlitic. The title of his TED talk video may be a bit sensationalist, but he almost certainly knows more than anyone here about the state of the art in AI.\n\nMany non-crackpots and extremely well educated and professional people claim either FTL, perpetual motion, or magic. It\u0027s no loss to me. I\u0027ve seen it first hand in general life, professionalism in no way protects against disillusion and risk to others (eg banking crisis, most peoples family life).\n\nThe runaway problem with AI, is the same as with any system we use, or tool. A car or aircraft has simple \u0022ai\u0022 and autopilot. It can malfunction, or cause a problem because we ask it to do a specific thing really well, and we made a mistake on the destination.\n\nSo the same applies to AI. A car cannot take over the world can it? A well trained cat or dog? An intelligent person? A car has speed and armour, a person intelligence and craftiness. It\u0027s impossible to combine the two and not make a *sacrifice on efficiency* in one area or the other.\n\n**Edited \u003Ctime datetime=\u00222015-07-26T19:19:18Z\u0022 title=\u002207/26/2015 07:19  PM\u0022 data-short=\u00228 yr\u0022\u003EJuly 26, 2015\u003C/time\u003E by Technical Ben**"},{"CreatedByName":"Kinglet","CreatedById":58832,"CreatedDateTime":"2015-07-26T19:21:07Z","Content":"\u003E \n\u003E All supercomputers are hall sized. This is hard to change even if we manage to increase cpu power 100 times. \n\u003E I think we will need new hardware for an sentinel ai, more like quantum computers or neural nets.\n\nSupercomputer size is inversely proportional to available transistor size. If we end up having affordable computers with the power of today\u0027s supercomputers, then the supercomputers of that time will still be as big, but much more powerful."}]}