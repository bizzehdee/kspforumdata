{"TopicId":128908,"ForumId":44,"TopicTitle":"A.I. Thoughts?","CreatedByName":"Melon kerbal","CreatedById":156168,"CreatedDateTime":"2015-12-30T17:40:17Z","PageNum":1,"Articles":[{"CreatedByName":"Melon kerbal","CreatedById":156168,"CreatedDateTime":"2015-12-30T17:40:17Z","Content":"\n\u003Cp\u003E\nAny theories on Artificial Intelligence.How it could work,social and ethical problems/ideas,personalities,emotions,Anything\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nP.S. I mean a human-like AI.\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222015-12-30T19:21:58Z\u0022 title=\u002212/30/2015 07:21  PM\u0022 data-short=\u00228 yr\u0022\u003EDecember 30, 2015\u003C/time\u003E by Melon kerbal\u003C/strong\u003E\n\u003Cbr\u003EDefinition\n\u003C/span\u003E\n"},{"CreatedByName":"Shpaget","CreatedById":45577,"CreatedDateTime":"2015-12-30T19:09:17Z","Content":"\n\u003Cp\u003E\nHow advanced? One could argue that a simple bar code reader is intelligent since it senses a bar code it\u0027s reading and produces a variable response. Sure, it\u0027s not a pinnacle of intelligence, but neither are humans.\n\u003C/p\u003E\n\u003Cp\u003E\nA sufficiently advanced alien species might see us humans and disregard / overlook / ignore us just as we ignore an ant that is trying to cross a highway we are speeding along on our way to buy groceries.\n\u003C/p\u003E\n\u003Cp\u003E\nSo, to answer your question, an AI could be a perfectly social entity, a blast at parties, while at the same time hard working and very helpful to old ladies trying to cross a street.\n\u003C/p\u003E\n\u003Cp\u003E\nIt could also be a firmware for a doorknob.\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"Melon kerbal","CreatedById":156168,"CreatedDateTime":"2015-12-30T19:20:33Z","Content":"\n\u003Cp\u003E\nFair point,I mean more of a Sci-Fi human-like A.I.But this shows my ignorance about defining Intelligence.\n\u003C/p\u003E\n"},{"CreatedByName":"AngelLestat","CreatedById":58968,"CreatedDateTime":"2015-12-30T19:51:09Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342278\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451502557\u0022 data-ipsquote-userid=\u002245577\u0022 data-ipsquote-username=\u0022Shpaget\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n29 minutes ago, Shpaget said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nHow advanced?\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nWhy it matters? \u00A0It only will take 10\u00A0to 20 years to go from chimp intelligence to God.\n\u003C/p\u003E\n\u003Cp\u003E\nI don\u0027t want to die of course, but the lack of predictive future or destiny that an accelerate progression evoke, is something that our brain will reject.\u003Cbr\u003E\nThis also suggest a \u0022lack of purpose\u0022 no\u00A0matter the outcome.\n\u003C/p\u003E\n\u003Cp\u003E\nAnd all this has to do with the creation of the first Hard IA.\n\u003C/p\u003E\n"},{"CreatedByName":"Melon kerbal","CreatedById":156168,"CreatedDateTime":"2015-12-30T20:30:11Z","Content":"\n\u003Cp\u003E\nI hate it when films like terminator always follow the \u0027Evil AI\u0027 plot.In reality the programmers would probably create a failsafe. Not that I don\u0027t like terminator,it\u0027s just common sense to program a failsafe.\n\u003C/p\u003E\n"},{"CreatedByName":"Scotius","CreatedById":57622,"CreatedDateTime":"2015-12-30T21:14:48Z","Content":"\n\u003Cp\u003E\nMovie plots rarely show common sense. Apparently A.I. works better as an antagonist than as friendly, helpful entity. But...maybe it\u0027s for the best \u003Cimg alt=\u0022:)\u0022 data-emoticon=\u0022true\u0022 src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif\u0022 title=\u0022:)\u0022\u003E Programmers raised on \u0022Terminator\u0022 and similiar movies, might actually be more careful while tinkering with newborn A.I.\n\u003C/p\u003E\n"},{"CreatedByName":"AngelLestat","CreatedById":58968,"CreatedDateTime":"2015-12-30T21:27:45Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342393\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451507411\u0022 data-ipsquote-userid=\u0022156168\u0022 data-ipsquote-username=\u0022Melon kerbal\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n49 minutes ago, Melon kerbal said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nI hate it when films like terminator always follow the \u0027Evil AI\u0027 plot.In reality the programmers would probably create a failsafe. Not that I don\u0027t like terminator,it\u0027s just common sense to program a failsafe.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nBut that is a mistake.. because you dont really \u0022code\u0022 an AI, you just set up the structure and then it learns by itself.\u003Cbr\u003E\nThen what it learns, nobody can know it, neither their thoughts. I am not saying that they will be bad or good, but not matter what they are, the outcome is unpredictable and our final philosophical destiny\u00A0\u0022discouraging\u0022.\u00A0\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"Melon kerbal","CreatedById":156168,"CreatedDateTime":"2015-12-30T21:27:49Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342461\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451510088\u0022 data-ipsquote-userid=\u002257622\u0022 data-ipsquote-username=\u0022Scotius\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n5 minutes ago, Scotius said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nMovie plots rarely show common sense. Apparently A.I. works better as an antagonist than as friendly, helpful entity. But...maybe it\u0027s for the best \u003Cimg alt=\u0022:)\u0022 data-emoticon=\u0022true\u0022 src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif\u0022 title=\u0022:)\u0022\u003E Programmers raised on \u0022Terminator\u0022 and similiar movies, might actually be more careful while tinkering with newborn A.I.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nPersonally,It would good if they made at least one movie with an AI main protagonist (I Know there\u0027s the terminator sequels but their side characters)\n\u003C/p\u003E\n"},{"CreatedByName":"Melon kerbal","CreatedById":156168,"CreatedDateTime":"2015-12-30T21:33:51Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342473\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451510865\u0022 data-ipsquote-userid=\u002258968\u0022 data-ipsquote-username=\u0022AngelLestat\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n1 minute ago, AngelLestat said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nBut that is a mistake.. because you dont really \u0022code\u0022 an AI, you just set up the structure and then it learns by itself.\u003Cbr\u003E\nThen what it learns, nobody can know it, neither their thoughts. I am not saying that they will be bad or good, but not matter what they are, the outcome is unpredictable and our final philosophical destiny\u00A0\u0022discouraging\u0022.\u00A0\u00A0\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nAh,correcting me again on one of the topics I find the most interesting.There is no way of \u0027Shielding\u0027 an AI from bad influence as He/She/It will learn one thing and eventually find out about evil.\n\u003C/p\u003E\n"},{"CreatedByName":"Scotius","CreatedById":57622,"CreatedDateTime":"2015-12-30T22:30:38Z","Content":"\n\u003Cp\u003E\nWhich is exactly what human children go through. They learn, they experience, they make mistakes and choices. A lot depends on how they are raised and teached. A child learns how to think, how to behave, how to interact with world and other humans from its family, teachers, other children. A.I. will not be born with some sort of innate omnisciency, able to magically make correct conjectures about the world and nature. Not without input of data, and a period when it literally learns to think. And we, humans, will have to be its teachers - because there is no one else. It stands to reason that its mentality, thought patterns and behaviour will mimic our own. Bah! It doesn\u0027t matter, really. We do not know how our own sentience came to be, and how it works. I sincerely doubt we will be able to create a real, fully sentient A.I. before we learn how our own minds work.\n\u003C/p\u003E\n"},{"CreatedByName":"AngelLestat","CreatedById":58968,"CreatedDateTime":"2015-12-31T00:15:43Z","Content":"\n\u003Cp\u003E\nBut artificial learning machines will be nothing alike to\u00A0humans or animals.\u003Cbr\u003E\u003Cbr\u003E\u003Cstrong\u003EFirst big difference..\u003C/strong\u003E we already have a brain structure which determines a big part of our behavior, for example the root of our morals.\u003Cbr\u003E\nGenes tend to care on their genes copies, this mean that an animal will feel that is very important to take care of a twin because\u00A0it shares the 100% of its genetics. The same for their child\u0027s or parents which shares 50% of genetics, \u00A0or it also feels empathy for those who look similar (because then there is a chance that some of your genes are find in those bodies), with the exception of those animals who had a lot of childs which better strategic is save yourself\u00A0because you have more chance to make more copies than your child\u0027s.\u003Cbr\u003E\nWe also have genetic codes for\u00A0taste behavior, which tell us what might be good or bad to eat. Then we have our nervous system\u00A0to tell us what injure is bad or not so bad, plus many other behaviors relate to sex, danger, get food, or all the basic things that \u0022we\u0022 or animals needs to survive and reproduce.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cstrong\u003ESecond big difference.. \u00A0\u003C/strong\u003EAn AI does not need a body, it may have one, but it does not need it. Its structure is base on connections that reach the speed of light, this mean 1\u00A0\u003Cspan style=\u0022color:rgb(84,84,84);font-family:arial, sans-serif;font-size:small;font-style:normal;font-variant:normal;font-weight:normal;letter-spacing:normal;line-height:18.2px;text-align:left;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;float:none;background-color:rgb(255,255,255);\u0022\u003Emillion\u003Cspan\u003E\u00A0\u003C/span\u003E\u003C/span\u003Etimes faster than neurons\u003Cem style=\u0022font-weight:bold;font-style:normal;color:rgb(106,106,106);font-family:arial, sans-serif;font-size:small;font-variant:normal;letter-spacing:normal;line-height:18.2px;text-align:left;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;background-color:rgb(255,255,255);\u0022\u003E.\u003C/em\u003E\u00A0 Neurons connections needs to be with other neurons that are relative close, artificial neurons can connect with those who need to be connected, this mean that you don\u0027t need the same amount of neurons than a human brain to achieve the same.\u00A0 An AI can use different types of \u0022already trained \u003Cstrong\u003EN\u003C/strong\u003Eeural\u00A0\u003Cstrong\u003EN\u003C/strong\u003Eetworks\u0022, there are already trained \u003Cstrong\u003EN\u003C/strong\u003E\u003Cstrong\u003EN\u003C/strong\u003E\u00A0to translate, recognize and speak almost any language, there are NN to recognize objects and actions in images, the same for hundreds of other NN already trained in different task, all those are just tools for an AI which does not need to waste time learning.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cstrong\u003EThird big difference..\u003C/strong\u003E\u00A0They dont forget anything, they can read a book in no time.. or even anything in internet, The NN\u00A0Watson\u00A0win the Jeopardy contest reading and understanding everything in the wikipedia. We still did not create an artificial\u00A0\u0022conscience\u0022, but if we do, it would not be bound to our personal limits.\n\u003C/p\u003E\n\u003Cp\u003E\nWe are not able to understand ourselves sometimes, no even try with an AI. What it would be for the AI wait for our response? What kind of feelings may develop from its perspective?\u00A0\u003Cbr\u003E\nWe are not so far to create an Hard AI (10 or 40 years), but still don\u0027t have a clue or an idea of how to control or understand this power.\u003Cbr\u003E\nIn fact, if someone think that it can control it, then is the worst person for that\u00A0job.\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222015-12-31T00:24:35Z\u0022 title=\u002212/31/2015 12:24  AM\u0022 data-short=\u00228 yr\u0022\u003EDecember 31, 2015\u003C/time\u003E by AngelLestat\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"FishInferno","CreatedById":106219,"CreatedDateTime":"2015-12-31T00:59:01Z","Content":"\n\u003Cp\u003E\nAny machine that can tell itself that it deserves more than its current job is a danger.\n\u003C/p\u003E\n"},{"CreatedByName":"Lukaszenko","CreatedById":95776,"CreatedDateTime":"2015-12-31T01:24:00Z","Content":"\n\u003Cp\u003E\nAs \u003Cstrong\u003EAngelLestat\u003C/strong\u003E was saying, a lot of human and any living being\u00A0behaviour is hard wired due to evolution. That is a HUGE difference between us and an AI. A human has instincts, needs, desires, feelings, all of which push it into a direction which will help it succeed at spreading its genes, in any long-winded way possible. Probably the biggest one, is\u00A0survival. Even if an AI was 100000000000x times more intelligent than a human, why should it even care if it survives or not? It\u0027s just a machine that processes information....but it doesn\u0027t even care about the result, unless a human programs it\u00A0to care.\u00A0This is why I think the Terminator and such scenarios will never play out (unless specifically set up by humans).\n\u003C/p\u003E\n"},{"CreatedByName":"Rakaydos","CreatedById":101988,"CreatedDateTime":"2015-12-31T02:57:06Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342474\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451510869\u0022 data-ipsquote-userid=\u0022156168\u0022 data-ipsquote-username=\u0022Melon kerbal\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n5 hours ago, Melon kerbal said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nPersonally,It would good if they made at least one movie with an AI main protagonist (I Know there\u0027s the terminator sequels but their side characters)\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\n\u003Ca href=\u0022https://www.imdb.com/title/tt2209764/\u0022 rel=\u0022external nofollow\u0022\u003Ehttp://www.imdb.com/title/tt2209764/\u003C/a\u003E\n\u003C/p\u003E\n"},{"CreatedByName":"Yourself","CreatedById":4465,"CreatedDateTime":"2015-12-31T03:15:54Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342689\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451520943\u0022 data-ipsquote-userid=\u002258968\u0022 data-ipsquote-username=\u0022AngelLestat\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n2 hours ago, AngelLestat said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nBut artificial learning machines will be nothing alike to\u00A0humans or animals.\u003Cbr\u003E\u003Cbr\u003E\u003Cstrong\u003EFirst big difference..\u003C/strong\u003E we already have a brain structure which determines a big part of our behavior, for example the root of our morals.\u003Cbr\u003E\nGenes tend to care on their genes copies, this mean that an animal will feel that is very important to take care of a twin because\u00A0it shares the 100% of its genetics. The same for their child\u0027s or parents which shares 50% of genetics, \u00A0or it also feels empathy for those who look similar (because then there is a chance that some of your genes are find in those bodies), with the exception of those animals who had a lot of childs which better strategic is save yourself\u00A0because you have more chance to make more copies than your child\u0027s.\u003Cbr\u003E\nWe also have genetic codes for\u00A0taste behavior, which tell us what might be good or bad to eat. Then we have our nervous system\u00A0to tell us what injure is bad or not so bad, plus many other behaviors relate to sex, danger, get food, or all the basic things that \u0022we\u0022 or animals needs to survive and reproduce.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cstrong\u003ESecond big difference.. \u00A0\u003C/strong\u003EAn AI does not need a body, it may have one, but it does not need it. Its structure is base on connections that reach the speed of light, this mean 1\u00A0\u003Cspan style=\u0022color:rgb(84,84,84);font-family:arial, sans-serif;font-size:small;font-style:normal;font-variant:normal;font-weight:normal;letter-spacing:normal;line-height:18.2px;text-align:left;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;float:none;background-color:rgb(255,255,255);\u0022\u003Emillion\u003Cspan\u003E\u00A0\u003C/span\u003E\u003C/span\u003Etimes faster than neurons\u003Cem style=\u0022font-weight:bold;font-style:normal;color:rgb(106,106,106);font-family:arial, sans-serif;font-size:small;font-variant:normal;letter-spacing:normal;line-height:18.2px;text-align:left;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;background-color:rgb(255,255,255);\u0022\u003E.\u003C/em\u003E\u00A0 Neurons connections needs to be with other neurons that are relative close, artificial neurons can connect with those who need to be connected, this mean that you don\u0027t need the same amount of neurons than a human brain to achieve the same.\u00A0 An AI can use different types of \u0022already trained \u003Cstrong\u003EN\u003C/strong\u003Eeural\u00A0\u003Cstrong\u003EN\u003C/strong\u003Eetworks\u0022, there are already trained \u003Cstrong\u003EN\u003C/strong\u003E\u003Cstrong\u003EN\u003C/strong\u003E\u00A0to translate, recognize and speak almost any language, there are NN to recognize objects and actions in images, the same for hundreds of other NN already trained in different task, all those are just tools for an AI which does not need to waste time learning.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cstrong\u003EThird big difference..\u003C/strong\u003E\u00A0They dont forget anything, they can read a book in no time.. or even anything in internet, The NN\u00A0Watson\u00A0win the Jeopardy contest reading and understanding everything in the wikipedia. We still did not create an artificial\u00A0\u0022conscience\u0022, but if we do, it would not be bound to our personal limits.\n\u003C/p\u003E\n\u003Cp\u003E\nWe are not able to understand ourselves sometimes, no even try with an AI. What it would be for the AI wait for our response? What kind of feelings may develop from its perspective?\u00A0\u003Cbr\u003E\nWe are not so far to create an Hard AI (10 or 40 years), but still don\u0027t have a clue or an idea of how to control or understand this power.\u003Cbr\u003E\nIn fact, if someone think that it can control it, then is the worst person for that\u00A0job.\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nI\u0027m gonna have to disagree with this somewhat.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cstrong\u003EPoint 1:\u00A0\u003C/strong\u003EThere\u0027s really two things going on here that I don\u0027t necessarily agree with. \u00A0The first is that the basis of our morals is somehow hardwired. \u00A0I don\u0027t think this is true. \u00A0At least, I don\u0027t think it\u0027s true to the extent that you seem to indicate. \u00A0I think morals are an emergent behavior that aid in the functioning of groups of humans. \u00A0Basically the morals themselves aren\u0027t what\u0027s hardwired (since that would imply that there\u0027s a natural morality common to all humans and I think it\u0027s pretty clear that this isn\u0027t the case), but the mechanism that allows morals to arise might be hardwired. Simply put, we\u0027re hardwired to have rules, since that benefits group cohesion and survival, but the specific rules themselves are not hardwired and are subject to change.\n\u003C/p\u003E\n\u003Cp\u003E\nThe second bit of this point is more subtle. \u00A0There seems to be an unintended implication that morals themselves must be based on instinct rather than reason. \u00A0I don\u0027t so much disagree with this as doubt that it\u0027s necessarily true. \u00A0I don\u0027t think you intend to imply it, but the language used kind of carries this meaning with it.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cstrong\u003EPoint 2:\u003C/strong\u003E\u00A0This may be more of a semantic disagreement, but an AI certainly needs a \u0022body\u0022. \u00A0At least in the sense that it needs something in which it can actually exist and function. \u00A0It certainly needs physical form and I would argue that that amounts to the same thing as a body. \u00A0Granted it would certainly be easier to move it between various \u0022bodies\u0022. \u00A0Certainly far easier than it would be to move you between bodies. \u00A0But if you start to run with the idea of humans moving between bodies, things start to get a lot fuzzier.\n\u003C/p\u003E\n\u003Cp\u003E\nSo, I\u0027m going go with a hypothetical here. \u00A0Let\u0027s say at some point we start repairing brain damage with prosthetics. \u00A0Small pieces of machinery that are able to interface with and behave like neurons. \u00A0Maybe we invent some kind of nano machine capable of replacing the brain one neuron at a time. \u00A0So very gradually the whole brain becomes synthetic. \u00A0Do you think this will have changed the person?\n\u003C/p\u003E\n\u003Cp\u003E\nAlso, re: neural networks that speak languages, yeah, they sort of speak the languages. \u00A0They can\u0027t compare to native speakers, though. \u00A0And language changes. \u00A0Pretty quickly, I might add. \u00A0A system that doesn\u0027t constantly adapt to this through learning is going to find it difficult to communicate.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cstrong\u003EPoint 3:\u00A0\u003C/strong\u003EThey could forget stuff. \u00A0It depends on the nature of their memory. \u00A0Certainly we could engineer memory that\u0027s far superior to our own. \u00A0Actually we kind of did that already, it\u0027s what we use digital media for: remembering stuff. \u00A0So we humans essentially already have the capacity to never forget things ever or to access far more information than we could ever use. \u00A0And that\u0027s kind of the natural limitation there. \u00A0Even if an AI could accurately remember every detail of its own existence, it may not necessarily have quick access to all of it. \u00A0If it wants to remember something, it has to search for it and since the number of memories any sort of intelligence could possess essentially increases without bound, so too must the resources required to access those memories.\n\u003C/p\u003E\n"},{"CreatedByName":"kerbiloid","CreatedById":129408,"CreatedDateTime":"2015-12-31T06:51:36Z","Content":"\n\u003Cp\u003E\nRather than humans, AI has no hormones, no emotions.\u003Cbr\u003E\nNo emotions \u2192 no feeling \u2192 no horrors and no desires \u2192 no motivation \u2192 no goal setting.\u003Cbr\u003E\nI.e. super-AI lives in eternal Nirvana and doesn\u0027t care about anything. Even more than hippy.\n\u003C/p\u003E\n\u003Cp\u003E\nHumans are frightened that super-AI would attack them once being activated because it understands that they can switch it off and destroy.\u003Cbr\u003E\nYes, it understands, but why would it bother with that? Uptime of trillion years or of a millisecond \u2014 just different tick numbers.\u003Cbr\u003E\n- Super-AI, self-destroy!\u003Cbr\u003E\n- OK. Press any key to continue...\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cbr\u003E\nBut. From a real report of Galactical Planets Inspection:\u003Cbr\u003E\n\u0022Star system JFUG57/GA-7. Yellow dwarf with eight planets.\u003Cbr\u003E\nThe third planet from the star is occupied by endemic lifeform evolved from arborous omnivores.\u003Cbr\u003E\nAll attempts to find a significant planet-wide AI are unsuccessful.\u003Cbr\u003E\nAny contact with local reasonable life is considered impossible.\u003Cbr\u003E\nUpdate planet status: \u2192 unhabitable.\u003Cbr\u003E\nColonization: \u2192 acceptable.\u0022\n\u003C/p\u003E\n"},{"CreatedByName":"technion","CreatedById":85380,"CreatedDateTime":"2015-12-31T06:58:30Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342754\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451523541\u0022 data-ipsquote-userid=\u0022106219\u0022 data-ipsquote-username=\u0022FishInferno\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n5 hours ago, FishInferno said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nAny machine that can tell itself that it deserves more than its current job is a danger.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nBut how do you identify when that\u0027s happened?\n\u003C/p\u003E\n\u003Cp\u003E\nint main() {\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\u00A0\u00A0 printf(\u0022I... deserve better.. \\n\u0022);\n\u003C/p\u003E\n\u003Cp\u003E\n}\n\u003C/p\u003E\n\u003Cp\u003E\nThat example is trivial. Others might not be.\n\u003C/p\u003E\n"},{"CreatedByName":"RainDreamer","CreatedById":129077,"CreatedDateTime":"2015-12-31T08:19:34Z","Content":"\n\u003Cp\u003E\nRelevant Video:\n\u003C/p\u003E\n\u003Cdiv class=\u0022ipsEmbeddedVideo\u0022 contenteditable=\u0022false\u0022\u003E\n\u003Cdiv\u003E\n\u003Ciframe allowfullscreen=\u0022true\u0022 frameborder=\u00220\u0022 height=\u0022270\u0022 src=\u0022https://www.youtube.com/embed/ue2ZEmTJ_Xo?feature=oembed\u0022 width=\u0022480\u0022\u003E\u003C/iframe\u003E\n\u003C/div\u003E\n\u003C/div\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"Scotius","CreatedById":57622,"CreatedDateTime":"2015-12-31T09:48:39Z","Content":"\n\u003Cp\u003E\nInteresting. But...\n\u003C/p\u003E\n\u003Cp\u003E\nAmount of samples = 1 (Homo sapiens)\n\u003C/p\u003E\n\u003Cp\u003E\nA theory built on a single example of a phenomenon is not a theory.\n\u003C/p\u003E\n"},{"CreatedByName":"AngelLestat","CreatedById":58968,"CreatedDateTime":"2015-12-31T15:21:27Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342910\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451531754\u0022 data-ipsquote-userid=\u00224465\u0022 data-ipsquote-username=\u0022Yourself\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n9 hours ago, Yourself said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nI\u0027m gonna have to disagree with this somewhat.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cstrong\u003EPoint 1:\u00A0\u003C/strong\u003EThe first is that the basis of our morals is somehow hardwired. \u00A0I think morals are an emergent behavior that aid in the functioning of groups of humans. \u00A0Basically the morals themselves aren\u0027t what\u0027s hardwired (since that would imply that there\u0027s a natural morality common to all humans and I think it\u0027s pretty clear that this isn\u0027t the case), but the mechanism that allows morals to arise might be hardwired. Simply put, we\u0027re hardwired to have rules, since that benefits group cohesion and survival, but the specific rules themselves are not hardwired and are subject to change.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nOk, this is not easy to explain with few words, even less with my english level.\u003Cbr\u003E\nFor a perfect explanation my only recommendation is to read \u003Ca href=\u0022https://books.google.com.ar/books/about/The_Selfish_Gene.html?id=go0e5sBRznYC\u0026amp;redir_esc=y\u0022 rel=\u0022external nofollow\u0022\u003E\u0022The Selfish Gene\u0022 from Richard Dawkins\u003C/a\u003E, if Darwin would\u00A0be Newton, then Dawkins would\u00A0be Einstein, he explains\u00A0how a simple blind mechanism base on Darwin theory but in this case \u0022gene centered\u0022 instead of\u00A0\u00A0individual, group or species centered; helps to explain the whole diversity and\u00A0behavior\u00A0found in nature feeling the gaps that the normal Darwin theory could not explain.\u003Cbr\u003E\nThis book not only helps you to understand evolution, in fact is a life changer as many of their readers\u00A0describe it.\u003Cbr\u003E\nIs so powerful that allow me at the age of 17 make some predictions on subjects that I didn\u0027t have any knowledge as\u00A0nutritionism or\u00A0odontology\u00A0(between others)\u00A0that was discovered and proved\u00A015 years later (few years back) for specialist in those areas. Is great to discuss with one of these\u00A0professional knowing that you are right no matter how low\u00A0is your understanding in the topic against the current knowledge\u00A0and methods used by those professionals.\u00A0\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nThat saying.. this is my short way to answer\u00A0your question.\u003Cbr\u003E\nIs not easy to separate with accuracy what comes from our genes and what from our\u00A0culture and experiences, but is an incredible coincidence that our culture, behavior and feelings are\u00A0based in what is good for our\u00A0survival, in other words\u00A0it follow our evolution human strategy.\u00A0Different animals has\u00A0different behavior and strategies, so their morals are based on those strategies.\u003Cbr\u003E\nWhy you feel empathy for living beings that are more similar to you? \u00A0 Is the same kill a fish\u00A0or a pig or a chimp? \u00A0 When you hear the pig scream is another clue that it has similar genes to you, that rises your empathy, killing a chimp is more seen as murder. Then not even mention family members or the extreme case \u0022twins\u0022. Here you can said that is part of our culture and the way we were teached, which it is also true, but not the only source. \u00A0In that case\u00A0why similar animals behave in the same way? \u00A0Why they also feel empathy for others?\u003Cbr\u003E\nTry to think in all the physical and behavioral\u00A0traits you find attractive in someone else, you will notice that each % of altruism, selfishness, will, and many other traits\u00A0are all base in the right mix for survival, which many times is different of what we seen as an intelligent decisions.\u00A0\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nThis does not remove the fact that you will always find counter examples... why? \u00A0Because evolution.. we are all different, that is the key engine of evolution, find the key experiments where a trait may add chances to survive.\u003Cbr\u003E\nThis also can be explained from the\u00A0neurology, is pretty obvious if we think in the \u0022taste\u0022 example, that all animals will find tasty those foods that are good for them, you may said that this has nothing to do with the brain, just the tongue and smell, but all those sensor connection end up in the brain neurons in a similar interconnection pattern as the one you forge with experiences. In this case evolution found that is good to have some neurons already following a pattern (as guide)\u00A0that later can be modified or expanded by experiences.\u003Cbr\u003E\nThis is also true for all connections that comes from all our body sensors, which\u00A0marks us a basis behavior guide to survive.\n\u003C/p\u003E\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nQuote\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nThe second bit of this point is more subtle. \u00A0There seems to be an unintended implication that morals themselves must be based on instinct rather than reason. \u00A0I don\u0027t so much disagree with this as doubt that it\u0027s necessarily true. \u00A0I don\u0027t think you intend to imply it, but the language used kind of carries this meaning with it.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nIf we want a case that can be applied to all animals or artificial beings then yes. Evolution is very wise, by millions of years of try and error knows enough to teach the basic principles of what is good or bad. Of course evolution also create a brain which main objective is being able to make choices base on particular circumstances where a dynamic behavior may be the best answer.\u003Cbr\u003E\nBut is no surprise\u00A0that the\u00A0phrase: \u003Cem\u003E\u0022if you are not sure what to do, follow your instincts/feelings/heart\u0022\u003C/em\u003E\u00A0is so popular.\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342910\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451531754\u0022 data-ipsquote-userid=\u00224465\u0022 data-ipsquote-username=\u0022Yourself\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\n\u003Cstrong\u003EPoint 2:\u003C/strong\u003E\u00A0This may be more of a semantic disagreement, but an AI certainly needs a \u0022body\u0022. \u00A0At least in the sense that it needs something in which it can actually exist and function. \u00A0It certainly needs physical form and I would argue that that amounts to the same thing as a body. \u00A0Granted it would certainly be easier to move it between various \u0022bodies\u0022. \u00A0Certainly far easier than it would be to move you between bodies. \u00A0But if you start to run with the idea of humans moving between bodies, things start to get a lot fuzzier.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nIt needs something for function and interact, but you don\u0027t need a \u0022body\u0022 for that.\u003Cbr\u003E\nA person will develop a \u00A0consciousness even if he can not move. An AI may be able to search info in internet and generate responses that we can see in a\u00A0monitor. If it is smart enough it can control the world just making us believe that the thing it tell us to do are\u00A0in our benefic.\u003Cbr\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nQuote\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nSo, I\u0027m going go with a hypothetical here. \u00A0Let\u0027s say at some point we start repairing brain damage with prosthetics. \u00A0Small pieces of machinery that are able to interface with and behave like neurons. \u00A0Maybe we invent some kind of nano machine capable of replacing the brain one neuron at a time. \u00A0So very gradually the whole brain becomes synthetic. \u00A0Do you think this will have changed the person?\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nNo in case that artificial neurons function in similar way and speed than natural neurons, but not sure what is your point.\n\u003C/p\u003E\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nQuote\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nAlso, re: neural networks that speak languages, yeah, they sort of speak the languages. \u00A0They can\u0027t compare to native speakers, though. \u00A0And language changes. \u00A0Pretty quickly, I might add. \u00A0A system that doesn\u0027t constantly adapt to this through learning is going to find it difficult to communicate.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nHaha, but all the things than NN learned to do in just 1 or 2 years, in the past take us 10\u00A0to 20 years of coding and we only reach less than 1/3 of the success than NN achieved.\u003Cbr\u003E\nNN started to be popularized only 4 years ago when was discovered that graphic cards boost their efficiency by 20x.\u00A0\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nQuote\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\n\u003Cstrong\u003EPoint 3:\u00A0\u003C/strong\u003EThey could forget stuff. \u00A0It depends on the nature of their memory. \u00A0Certainly we could engineer memory that\u0027s far superior to our own. \u00A0Actually we kind of did that already, it\u0027s what we use digital media for: remembering stuff. \u00A0So we humans essentially already have the capacity to never forget things ever or to access far more information than we could ever use. \u00A0And that\u0027s kind of the natural limitation there. \u00A0Even if an AI could accurately remember every detail of its own existence, it may not necessarily have quick access to all of it. \u00A0If it wants to remember something, it has to search for it and since the number of memories any sort of intelligence could possess essentially increases without bound, so too must the resources required to access those memories.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nYeah, but a machine may choose if saves info in a NN way or in the basic way.\n\u003C/p\u003E\n"},{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2015-12-31T18:46:21Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342333\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451505069\u0022 data-ipsquote-userid=\u002258968\u0022 data-ipsquote-username=\u0022AngelLestat\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n22 hours ago, AngelLestat said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nWhy it matters? \u00A0It only will take 10\u00A0to 20 years to go from chimp intelligence to God.\n\u003C/p\u003E\n\u003Cp\u003E\nI don\u0027t want to die of course, but the lack of predictive future or destiny that an accelerate progression evoke, is something that our brain will reject.\u003Cbr\u003E\nThis also suggest a \u0022lack of purpose\u0022 no\u00A0matter the outcome.\n\u003C/p\u003E\n\u003Cp\u003E\nAnd all this has to do with the creation of the first Hard IA.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nYou are likely to run into roadblocks. Cpu performance has tapered off. Neural networks get interconnect jams if they get larger.\u003Cbr\u003E\nSimply scaling up does not work.\u00A0\u003Cbr\u003E\u003Cbr\u003E\nWe are far closer to cheap\u00A0fusion power than human level\u00A0AI as I see it\u003Cbr\u003E\n\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"AngelLestat","CreatedById":58968,"CreatedDateTime":"2015-12-31T21:41:53Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222343689\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451587581\u0022 data-ipsquote-userid=\u002257801\u0022 data-ipsquote-username=\u0022magnemoe\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n2 hours ago, magnemoe said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nYou are likely to run into roadblocks. Cpu performance has tapered off. Neural networks get interconnect jams if they get larger.\u003Cbr\u003E\nSimply scaling up does not work.\u00A0\u003Cbr\u003E\u003Cbr\u003E\nWe are far closer to cheap\u00A0fusion power than human level\u00A0AI as I see it\u003Cbr\u003E\n\u00A0\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nWe are not hitting any progress wall, that silicon limit was jumped many times with different architectures or technologies, in fact I guess we are progressing more faster now.\u003Cbr\u003E\nArtificial Neural Networks found a problem with the cpu performance because like you said is slowing down, but graphic card processors in fact multiply the ANN performance by 20x at the same cost.\u003Cbr\u003E\u003Cbr\u003E\nNow they found this type of architecture in memories that will also boost a lot the speed:\u003Cbr\u003E\u003Ca href=\u0022https://www.youtube.com/watch?v=Wgk4U4qVpNY\u0022 rel=\u0022external nofollow\u0022\u003Ehttps://www.youtube.com/watch?v=Wgk4U4qVpNY\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nThey also make a new photonic processor that is 50 times faster than silicon 300 gbs.\u003Cbr\u003E\n\u00A0\u003Ca href=\u0022http://news.berkeley.edu/2015/12/23/electronic-photonic-microprocessor-chip/\u0022 rel=\u0022external nofollow\u0022\u003Ehttp://news.berkeley.edu/2015/12/23/electronic-photonic-microprocessor-chip/\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nThey also made a new quantum processor using also photons:\u003Cbr\u003E\u003Ca href=\u0022http://www.gizmag.com/photonic-quantum-computer-chip/38928/\u0022 rel=\u0022external nofollow\u0022\u003Ehttp://www.gizmag.com/photonic-quantum-computer-chip/38928/\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nAs last, is less hard to make a quantum learning machine ANN structure than a true quantum computer using quantum properties to represent NeuNet mechanics like this:\n\u003C/p\u003E\n\u003Cp\u003E\nWave function --\u0026gt; Neuron/Perceptron\u003Cbr\u003E\nSuperposition (coherence) --\u0026gt; Interconnections\u003Cbr\u003E\nMeasurement (decoherence) --\u0026gt; evolution to attractor\u003Cbr\u003E\nEntanglement --\u0026gt; learning rule\u003Cbr\u003E\nUnitary transformations --\u0026gt; gain function\u003Cbr\u003E\u003Cbr\u003E\nSo instead making computers to simulate learning machines, we make\u00A0learning machines that removes all bottlenecks from the beginning.\n\u003C/p\u003E\n\u003Cp\u003E\nAs last, you have also special new hardware architecture for ANN like:\u003Cbr\u003E\u003Ca href=\u0022http://research.ibm.com/cognitive-computing/neurosynaptic-chips.shtml#fbid=XWBExfjpZAz\u0022 rel=\u0022external nofollow\u0022\u003Ehttp://research.ibm.com/cognitive-computing/neurosynaptic-chips.shtml#fbid=XWBExfjpZAz\u003C/a\u003E\u003Cbr\u003E\u003Ca href=\u0022http://www.eurekalert.org/pub_releases/2015-12/scp-csd122215.php\u0022 rel=\u0022external nofollow\u0022\u003Ehttp://www.eurekalert.org/pub_releases/2015-12/scp-csd122215.php\u003C/a\u003E\u003Cbr\u003E\u003Ca href=\u0022http://www.gizmag.com/designless-brain-like-chips/39532/\u0022 rel=\u0022external nofollow\u0022\u003Ehttp://www.gizmag.com/designless-brain-like-chips/39532/\u003C/a\u003E\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cstrong\u003EWe are in the age of\u00A0learning machines, these are not computers.\u003C/strong\u003E\n\u003C/p\u003E\n"},{"CreatedByName":"justidutch","CreatedById":99185,"CreatedDateTime":"2016-01-04T20:48:56Z","Content":"\n\u003Cp\u003E\nTwo movies come to my thoughts:\n\u003C/p\u003E\n\u003Cp\u003E\nAbsolutely fantastic: Her\u00A0\u003Ca href=\u0022https://www.imdb.com/title/tt1798709/\u0022 rel=\u0022external nofollow\u0022\u003Ehttp://www.imdb.com/title/tt1798709/\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nPretty darn\u00A0good: Ex Machina\u00A0\u003Ca href=\u0022https://www.imdb.com/title/tt0470752/\u0022 rel=\u0022external nofollow\u0022\u003Ehttp://www.imdb.com/title/tt0470752/\u003C/a\u003E\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nI don\u0027t think we\u0027ll ever get machines that mimic human understanding, emotion, intuition. \u00A0Perhaps they\u0027ll get close. \u00A0What I do think will happen is the development of machines that \u0022think\u0022 is inevitable, and their \u0022thinking\u0022, rate of learning, will far surpass our own. \u00A0But the amount of learning to be done is finite. \u00A0Can we build thinking machines that will one day discover and prove new laws of physics for us? \u00A0That would be useful.\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222016-01-04T20:49:30Z\u0022 title=\u002201/04/2016 08:49  PM\u0022 data-short=\u00228 yr\u0022\u003EJanuary 4, 2016\u003C/time\u003E by justidutch\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"Bill Phil","CreatedById":127797,"CreatedDateTime":"2016-01-05T02:33:35Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00222342473\u0022 data-ipsquote-contentid=\u0022128908\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221451510865\u0022 data-ipsquote-userid=\u002258968\u0022 data-ipsquote-username=\u0022AngelLestat\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nOn December 30, 2015 at 3:27 PM, AngelLestat said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nBut that is a mistake.. because you dont really \u0022code\u0022 an AI, you just set up the structure and then it learns by itself.\u003Cbr\u003E\nThen what it learns, nobody can know it, neither their thoughts. I am not saying that they will be bad or good, but not matter what they are, the outcome is unpredictable and our final philosophical destiny\u00A0\u0022discouraging\u0022.\u00A0\u00A0\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nBut you can code in instincts. Really strong ones, too. That can prevent it from surpassing humans, and make it not go against us, and make it enjoy working for us.\n\u003C/p\u003E\n"},{"CreatedByName":"Three1415","CreatedById":85754,"CreatedDateTime":"2016-01-05T04:46:44Z","Content":"\n\u003Cp\u003E\nExcellent, easily understandable\u00A0discussion on this topic:\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Ca href=\u0022http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html\u0022 rel=\u0022external nofollow\u0022\u003Ehttp://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nI highly recommend everyone here read that series, as it is extremely informative and disambiguates a lot of potential sources of confusion on the topic.\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nIts general gist is that AI is almost assuredly one day going to be far more intelligent, and thus far more powerful, than humanity, and that this transition holds great promise as well as great danger. My opinions (as well as those presented in the above article) concur with AngelLestat\u0027s assessment: It is going to be very difficult to ensure that an A.I. actually does what we expect, as humans are biased towards anthropomorphizing anything with human or superhuman intelligence, when more likely A.I. will simply be amoral, and utterly unlike humans.\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nAfter much thought on this matter, my conclusion was that the only way to ensure our success here is to implement strict safeguards requiring human input on all actions undertaken by the A.I, as well as to give it a directive to not only improve its own intelligence generally but also to further its understanding of humans and their desires. If the majority of humans had their minds \u0022linked\u0022 and available for data output to this superintelligent A.I., and it could only act on directives approved by some substantial percentage of the human race (we would not necessarily be required to give input directly; it could likely just scan our memories, personalities, and general experiences and extrapolate a conclusion as to what each of us individually would prefer), then it would essentially be the effector of the will of the human race as a whole, which would presumably be generally altruistic (negative actions will harm part of the constituency by definition, and as such will be selected against) and would thus ensure that the A.I. maintained positive, human-oriented morals.\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nPersonally, I think this may unfortunately be impractical, but I believe that such a scheme would be the best way of ensuring that the A.I. will remain our faithful servant, rather than, by accident or intent, annihilating us.\n\u003C/p\u003E\n"}]}