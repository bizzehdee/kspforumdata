{"TopicId":84685,"ForumId":44,"TopicTitle":"Should sentient AIs be allowed to take control of something important?","CreatedByName":"gmpd2000","CreatedById":37101,"CreatedDateTime":"2014-09-15T19:46:03Z","PageNum":1,"Articles":[{"CreatedByName":"gmpd2000","CreatedById":37101,"CreatedDateTime":"2014-09-15T19:46:03Z","Content":"\n\u003Cp\u003E(AIs: Artificial Intelligences)\u003C/p\u003E\u003Cp\u003EWell, The classical example of this would be HAL9000 from 2001: ASO , (Spoilers!) when it doesn\u0027t let Dave into the ship, because they were talking about disconecting it, it even tries to apologize for what it did.\u003C/p\u003E\u003Cp\u003ESo, do you think that AIs should take control of something important (space mission, managing a space station, etc) ?\u003C/p\u003E\n"},{"CreatedByName":"Mazon Del","CreatedById":32991,"CreatedDateTime":"2014-09-15T20:15:00Z","Content":"\n\u003Cp\u003EIndeed we should. For a couple reasons really. Firstly something like an AI could be much better suited for tasks like say, piloting a starship while the human crew sleeps away than having a live awake human.\u003C/p\u003E\u003Cp\u003ESecondly, if we are talking about true AI in the sense of fully independent thinking creature. Then we definitely want to do that. One big thing to do with future AI\u0027s is that if their psychology ends up resembling humans at all (likely given that we only have human psychology to base it off of) the AI\u0027s will slowly build up resentment over being kept from important jobs, only kept for 2nd class citizen type work. Etc. The real trick to preventing a Skynet is to make AI\u0027s WANT to keep humans around.\u003C/p\u003E\n"},{"CreatedByName":"KerikBalm","CreatedById":91917,"CreatedDateTime":"2014-09-15T20:15:55Z","Content":"\n\u003Cp\u003Espace mission, managing a station, sure.\u003C/p\u003E\u003Cp\u003EDon\u0027t give it control of the nukes, or the factories needed to build more of itself \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_tongue.gif\u0022 alt=\u0022:P\u0022\u003E\u003C/p\u003E\n"},{"CreatedByName":"Scotius","CreatedById":57622,"CreatedDateTime":"2014-09-15T20:17:51Z","Content":"\n\u003Cp\u003EWhy not? Would you rather enslave those defenseless sentient beings from the moment they would be born? Because such treatment of another person never backfired horrifically \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_rolleyes.gif\u0022 alt=\u0022:rolleyes:\u0022\u003E And why would an AI even be hostile towards humans from the start? What would it gain? Money? Power? Sick satisfaction? Why would we program such desires into a computer program? Meh. I do not know when and if true AI will ever be created, but i\u0027m not scared of them. I\u0027m scared of people afraid of everything that is different, and ready to react on their fears alone.\u003C/p\u003E\n"},{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2014-09-15T20:35:37Z","Content":"\n\u003Cp\u003EWell nobody have made an sentinel AI or have any idea how it will behave.\u003C/p\u003E\u003Cp\u003EUntil you know how they behave it would not be an good idea to give it responsibility. \u003C/p\u003E\u003Cp\u003EFirst sentinel AI would probably also be pretty moronic and have other issues, say a 5 second attention span.\u003C/p\u003E\n"},{"CreatedByName":"Seret","CreatedById":41409,"CreatedDateTime":"2014-09-15T20:54:59Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022gmpd2000\u0022 data-cite=\u0022gmpd2000\u0022\u003E\u003Cdiv\u003E\u003Cp\u003ESo, do you think that AIs should take control of something important (space mission, managing a space station, etc)\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThere wouldn\u0027t be much point in building them otherwise. An AI itself would be an extremely valuable machine, they\u0027ll be expected to earn back their cost by managing important expensive things better than could be done without them. I don\u0027t think we\u0027ll see truly general purpose AI any time soon. What you will see is extremely smart machines doing things like trading on the stock market and navigating unmanned ships. Spacecraft goes without saying IMO. They\u0027ll be highly intelligent and autonomous, but they\u0027ll be specialised for what they were designed to do.\u003C/p\u003E\u003Cp\u003EInterstellar space exploration would pretty much necessitate powerful AI. At interstellar distances both remote control and a human crew are impractical, so any probes we ever send to other stars or planets will need to be highly autonomous and able to handle unexpected situations.\u003C/p\u003E\n"},{"CreatedByName":"vger","CreatedById":67603,"CreatedDateTime":"2014-09-15T21:13:28Z","Content":"\n\u003Cp\u003EWhy not? What\u0027s the worst that could happen?\u003C/p\u003E\u003Cp\u003E\u003Cimg src=\u0022http://heavyarmor.files.wordpress.com/2011/03/winner-none.jpg\u0022 alt=\u0022winner-none.jpg\u0022\u003E\u003C/p\u003E\n"},{"CreatedByName":"Jatwaa","CreatedById":59627,"CreatedDateTime":"2014-09-15T21:58:03Z","Content":"\n\u003Cp\u003EI would indeed allow an AI to perform actions. But depending on the coder doing the coding. What are the directives the system has to follow. That would be key. If the system over-rides the directives then it could question why the directives were in place. If anything new to the world starts to see itself as living and questioning its right and place in the universe then it would begin to access the threats around it. If we treat anything like it is a subservient beast of burden, then well, I would expect it to consider us a threat. Life needs equality. Life needs trust and belief. If we create that life, we should treat it as life and not a lesser. Then it could understand the need to lay down its life if needed for the people it holds dear in its...uh...well...heart. Then again, it could see the evil that occurs and decide that is correct. Being that it would be judging the situation based on 1s and 0s. It would be key to show it what we believe right and wrong is and should be. Show it what happens when people do morally bad things and morally good. All data would be processed and a determination would be made, is this \u0022right\u0022. I would hope that anything raised to look at logic would see the answer. But, what if it\u0027s instincts are survival over morals? Therein is the problem. \u0022To survive I associated with the enemy thereby securing my survival. Human instinct is survival.\u0022 But which holds more weight, compassion, unity, love or survival? That would have to be instilled in each logic from the base like a child. From there you would cross your fingers and hope that the right choice is made. Cause if not...well you would be boned. I still, would lean to Yes, let them. It is an ally worth the risk.\u003C/p\u003E\n"},{"CreatedByName":"cantab","CreatedById":104935,"CreatedDateTime":"2014-09-15T21:58:04Z","Content":"\n\u003Cp\u003EAuthority needn\u0027t require direct physical control; few human managers have that. It would be prudent to likewise not let an early sapient AI have direct control over anything in the real world, but rather have them act to work out possible business strategies.\u003C/p\u003E\n"},{"CreatedByName":"WestAir","CreatedById":59115,"CreatedDateTime":"2014-09-15T22:27:54Z","Content":"\n\u003Cp\u003EYes.\u003C/p\u003E\u003Cp\u003EThe first AI on the US Supreme Court will be the first infallible Justice. Imagine the benefits of a Justice that is pre-programmed to be a constitutionally faithful leader. \u003C/p\u003E\u003Cp\u003EThe same goes for CEO\u0027s. A CEO that is intelligent enough to accurately predict tomorrows stocks and the needs of the consumer, because it\u0027s an AI with more intelligence than every human on Earth combined, will lead companies into unseen revenue. As a stock-holder, I\u0027d definitely vote for that guy.\u003C/p\u003E\u003Cp\u003EWhat about in the military? An AI sitting next to our dispatchers in Command \u0026amp; Control, computing things like soldier rest-times, supply lines, satellite data from enemy movements. Talk about a General\u0027s best friend.\u003C/p\u003E\u003Cp\u003EAs for roles beyond that, like President, I would keep those roles for humans. The encroachment of AI superiority should be stopped just short of toppling us on the leadership food chain. Keep man on top, if only because we\u0027re the only ones who care.\u003C/p\u003E\n"},{"CreatedByName":"rtxoff","CreatedById":107622,"CreatedDateTime":"2014-09-15T22:52:17Z","Content":"\n\u003Cp\u003ESentient AI\u0027s are probably a bad idea. Sonner or later the less evolved species will get exterminated. That would be us not them. So no, don\u0027t ever make sentient AI\u0027s, i don\u0027t like it.\u003C/p\u003E\n"},{"CreatedByName":"WestAir","CreatedById":59115,"CreatedDateTime":"2014-09-15T23:07:49Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022gpisic\u0022 data-cite=\u0022gpisic\u0022\u003E\u003Cdiv\u003ESentient AI\u0027s are probably a bad idea. Sonner or later the less evolved species will get exterminated. That would be us not them. So no, don\u0027t ever make sentient AI\u0027s, i don\u0027t like it.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003ETake Data from Star Trek. A million of him wouldn\u0027t in a million years \u0022exterminate\u0022 mankind. I believe AI are no threat to humanity. In fact, they may be what\u0027s needed to ensure we survive another thousand years.\u003C/p\u003E\n"},{"CreatedByName":"Kryten","CreatedById":348,"CreatedDateTime":"2014-09-15T23:20:29Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022gpisic\u0022 data-cite=\u0022gpisic\u0022\u003E\u003Cdiv\u003ESentient AI\u0027s are probably a bad idea. Sonner or later the less evolved species will get exterminated. That would be us not them. So no, don\u0027t ever make sentient AI\u0027s, i don\u0027t like it.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003E The phrase \u0027less evolved\u0027 is meaningless enough already, without applying it to something that didn\u0027t evolve in the first place.\u003C/p\u003E\n"},{"CreatedByName":"Mazon Del","CreatedById":32991,"CreatedDateTime":"2014-09-15T23:48:57Z","Content":"\n\u003Cp\u003EReally we just need to raise the AI\u0027s to want humans around. Worst case, they force us to upload our minds into computers and now we are immortal computers. I\u0027d volunteer.\u003C/p\u003E\n"},{"CreatedByName":"78stonewobble","CreatedById":97559,"CreatedDateTime":"2014-09-16T08:34:10Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022gmpd2000\u0022 data-cite=\u0022gmpd2000\u0022\u003E\u003Cdiv\u003E(AIs: Artificial Intelligences)\u003Cp\u003EWell, The classical example of this would be HAL9000 from 2001: ASO , (Spoilers!) when it doesn\u0027t let Dave into the ship, because they were talking about disconecting it, it even tries to apologize for what it did.\u003C/p\u003E\u003Cp\u003ESo, do you think that AIs should take control of something important (space mission, managing a space station, etc) ?\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EHmm, well we can barely make a system that can read out the names of the busstops loud. \u003C/p\u003E\u003Cp\u003EWhat kind of \u0022AI\u0022? An artificial intelligence or one that is similar to human intelligence (with base instincts and feelings and what not)? \u003C/p\u003E\u003Cp\u003EWe don\u0027t need necessarily need a self aware intelligence for many many tasks. Like stockmarket / casino predictions or military logistics. You just need better written ordinary programmes. \u003C/p\u003E\u003Cp\u003EIn any case, as that other guy said. Noone has built an AI yet, so we don\u0027t know how they will be. \u003C/p\u003E\u003Cp\u003ESo, if we build a psychopath, I\u0027m gonna say no. \u003C/p\u003E\u003Cp\u003EOn the other hand, if we can bring em to more or less sane human levels. Why not...\u003C/p\u003E\n"},{"CreatedByName":"Seret","CreatedById":41409,"CreatedDateTime":"2014-09-16T08:34:46Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022WestAir\u0022 data-cite=\u0022WestAir\u0022\u003E\u003Cdiv\u003E\u003Cp\u003EThe first AI on the US Supreme Court will be the first infallible Justice. Imagine the benefits of a Justice that is pre-programmed to be a constitutionally faithful leader. \u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EVery high level judges such as those on your US Supreme Court are generally not simply applying existing legislation as written. Things generally get referred to that level because new precedents have to be set. Asking an AI to operate in that kind of blue sky arena and trusting it to come up with judgements that humans found just and satisfying would be an immense challenge for a machine. I think jobs like this would one of the very last to ever be occupied by an AI. Humans won\u0027t want to give up control of inherently subjective topics like justice and values.\u003C/p\u003E\n"},{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2014-09-16T09:07:13Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Seret\u0022 data-cite=\u0022Seret\u0022\u003E\u003Cdiv\u003EVery high level judges such as those on your US Supreme Court are generally not simply applying existing legislation as written. Things generally get referred to that level because new precedents have to be set. Asking an AI to operate in that kind of blue sky arena and trusting it to come up with judgements that humans found just and satisfying would be an immense challenge for a machine. I think jobs like this would one of the very last to ever be occupied by an AI. Humans won\u0027t want to give up control of inherently subjective topics like justice and values.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003Eyes, its mostly an political decision, the judges also have to think political not only pure legal. \u003C/p\u003E\u003Cp\u003ELots of lower level stuff is already automated like fines from speed traps, yes you can appeal first to police then to court but mostly don\u0027t as the evidence is clear.\u003C/p\u003E\n"},{"CreatedByName":"rtxoff","CreatedById":107622,"CreatedDateTime":"2014-09-16T09:31:59Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Kryten\u0022 data-cite=\u0022Kryten\u0022\u003E\u003Cdiv\u003EThe phrase \u0027less evolved\u0027 is meaningless enough already, without applying it to something that didn\u0027t evolve in the first place.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003ESure they will be evolved, they inherit all of our evolution plus all the benefits we will give them hence we will move a step down on the food chain even if they won\u0027t eat the same food we do.\u003C/p\u003E\n"},{"CreatedByName":"rtxoff","CreatedById":107622,"CreatedDateTime":"2014-09-16T09:35:03Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022WestAir\u0022 data-cite=\u0022WestAir\u0022\u003E\u003Cdiv\u003ETake Data from Star Trek. A million of him wouldn\u0027t in a million years \u0022exterminate\u0022 mankind. I believe AI are no threat to humanity. In fact, they may be what\u0027s needed to ensure we survive another thousand years.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThe thing with Data is that he was not gifted with the full package of emotions. His brother Lore is a good example what happens if you put human emotions into an AI.\u003C/p\u003E\n"},{"CreatedByName":"Dodgey","CreatedById":89577,"CreatedDateTime":"2014-09-16T09:54:17Z","Content":"\n\u003Cp\u003EHow do you figure that? There seems to be this assumption that as soon as you flip the on switch on the program it is immediately fully aware. Any computer needs to be programmed and this includes the brain, the difference is that we are \u0022programmed\u0022 by our interactions with reality through our 5 senses. This excludes base programming handed down through genetics.\u003C/p\u003E\u003Cp\u003EMy point is that any AI excluding copies of another would need to be taught, so why not teach it to be compassionate as you would a child. 2010 Odyssey Two describes this quite well.l\u003C/p\u003E\n"},{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2014-09-16T10:05:30Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Dodgey\u0022 data-cite=\u0022Dodgey\u0022\u003E\u003Cdiv\u003EHow do you figure that? There seems to be this assumption that as soon as you flip the on switch on the program it is immediately fully aware. Any computer needs to be programmed and this includes the brain, the difference is that we are \u0022programmed\u0022 by our interactions with reality through our 5 senses. This excludes base programming handed down through genetics.\u003Cp\u003EMy point is that any AI excluding copies of another would need to be taught, so why not teach it to be compassionate as you would a child. 2010 Odyssey Two describes this quite well.l\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThis, you will also get an evolution of them over time the same way cars or computers evolve, the first sentinel computers would be morons.\u003C/p\u003E\u003Cp\u003EAt the time we can make good ones we will know the well probably better detail knowledge than of human thinking.\u003C/p\u003E\n"},{"CreatedByName":"Kryten","CreatedById":348,"CreatedDateTime":"2014-09-16T14:51:34Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022gpisic\u0022 data-cite=\u0022gpisic\u0022\u003E\u003Cdiv\u003ESure they will be evolved, they inherit all of our evolution plus all the benefits we will give them hence we will move a step down on the food chain even if they won\u0027t eat the same food we do.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003E More gibberish. Evolution is a process, not a linear property you can have more or less of.\u003C/p\u003E\n"},{"CreatedByName":"rtxoff","CreatedById":107622,"CreatedDateTime":"2014-09-16T15:46:08Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Kryten\u0022 data-cite=\u0022Kryten\u0022\u003E\u003Cdiv\u003EMore gibberish. Evolution is a process, not a linear property you can have more or less of.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EAbsolutely, you just confirmed everything i said before. The phrase \u0022More gibberish\u0022 was really not necessary just read everything again if you did not understand it.\u003C/p\u003E\n"},{"CreatedByName":"Kryten","CreatedById":348,"CreatedDateTime":"2014-09-16T15:53:33Z","Content":"\n\u003Cp\u003EI do understand; I understand you\u0027ve no idea of the nature or mechanism of evolution except through bad scifi featuring \u0027the next stage of human evolution\u0027.\u003C/p\u003E\n"},{"CreatedByName":"Scotius","CreatedById":57622,"CreatedDateTime":"2014-09-16T17:51:35Z","Content":"\n\u003Cp\u003EPeace, people \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif\u0022 alt=\u0022:)\u0022\u003E Many mental illnesses that turn Homo sapiens into various \u0022-paths\u0022 can be traced to chemical imbalances, genetic diseases, brain defects and so on. We have to treat such things, or at least mitigate them with drugs, behaviour modifications or isolation. I find it hard to imagine our first AIs will be installed on faulty hardware without strict quality control.\u003C/p\u003E\n"}]}