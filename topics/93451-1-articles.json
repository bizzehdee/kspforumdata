{"TopicId":93451,"ForumId":55,"TopicTitle":"Why does DirectX use more memory than OpenGL?","CreatedByName":"DesTroy","CreatedById":116547,"CreatedDateTime":"2014-12-18T01:12:05Z","PageNum":1,"Articles":[{"CreatedByName":"DesTroy","CreatedById":116547,"CreatedDateTime":"2014-12-18T01:12:05Z","Content":"\n\u003Cp\u003EI\u0027m hoping this is the right area to post this. But I have a question that I have never seen any explanation posted for anywhere on the internet:\u003C/p\u003E\u003Cp\u003EWhy does (at least in KSP) DirectX use obscenely more memory (usually more than 2x) than OpenGL mode?\u003C/p\u003E\u003Cp\u003EWhen you have the correct hardware, there is no visual differences between the two whatsoever. There should be negligible or NO difference in memory usage whatsoever. (Especially on the texture memory side of things)\u003C/p\u003E\u003Cp\u003EThe only rational explanation I can think of immediately, is that due to an error by Microsoft, Unity, or Squad, (Or any combination of the 3) DirectX mode is loading the textures into memory twice.\u003C/p\u003E\u003Cp\u003EDoes anyone have an actual, detailed explanation?\u003C/p\u003E\n"},{"CreatedByName":"Pecan","CreatedById":96332,"CreatedDateTime":"2014-12-18T01:33:46Z","Content":"\n\u003Cp\u003EOpenGL works differently to DirectX. On my hardware, I \u003Cspan style=\u0022text-decoration:underline;\u0022\u003Elose\u003C/span\u003E memory using OpenGL.\u003C/p\u003E\u003Cp\u003ERational explanations can\u0027t explain computers - it must be quantum ^^.\u003C/p\u003E\u003Cp\u003EExpect many \u0027actual, detailed explanations\u0027 - ignore them all, except as it works on your particular machine.\u003C/p\u003E\u003Cp\u003E(Obviously, the technologies are doing much the same job and largely in the same ways, but you really can\u0027t compare them directly).\u003C/p\u003E\n"},{"CreatedByName":"Crimson Sunrise","CreatedById":132102,"CreatedDateTime":"2014-12-18T01:35:55Z","Content":"\n\u003Cp\u003EThat\u0027s in part due to the fact that the OpenGL is an open source library whose code is well known and can be adapted for optimization (mainly because it\u0027s free). DirectX being proprietary, holds other restrictions that keep certain optimizations from happening. You can only use the API the way it is and said API is restricted to the Windows OS (Linux and OSX games have to be ported to use OpenGL instead when you have a Linux or OSX version.)\u003C/p\u003E\n"},{"CreatedByName":"DesTroy","CreatedById":116547,"CreatedDateTime":"2014-12-18T08:02:18Z","Content":"\n\u003Cp\u003EThat doesn\u0027t explain why it is using that much RAM... We are talking about 1-2 Gb\u0027s.... This kind of amount must be due to textures...... since they both load the same texture files (And the filesize of the textures doesn\u0027t even total that much) it sure looks like someone made a boo boo and it\u0027s loading them twice.\u003C/p\u003E\n"},{"CreatedByName":"Daid","CreatedById":32171,"CreatedDateTime":"2014-12-18T08:27:54Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022DesTroy\u0022 data-cite=\u0022DesTroy\u0022\u003E\u003Cdiv\u003EThat doesn\u0027t explain why it is using that much RAM... We are talking about 1-2 Gb\u0027s.... This kind of amount must be due to textures...... since they both load the same texture files (And the filesize of the textures doesn\u0027t even total that much) it sure looks like someone made a boo boo and it\u0027s loading them twice.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003ECould be, that on your specific video card, DirectX textures are stored as raw, and OpenGL textures are stored as compressed textures in memory.\u003C/p\u003E\u003Cp\u003EOr that in your case, the OpenGL implementation does not do bump/specular mapping and thus does not need to load the textures for that, saving a lot of memory.\u003C/p\u003E\u003Cp\u003EOr, that the OpenGL implementation uses smaller texture sizes because your video card opengl driver does not support bigger textures. (Some of the textures in KSP are huge)\u003C/p\u003E\u003Cp\u003E(I\u0027m a software engineer, and I maintain an application that uses OpenGL, which is fun any annoying sometimes. Windows OpenGL drivers is a minefield)\u003C/p\u003E\n"},{"CreatedByName":"sal_vager","CreatedById":16426,"CreatedDateTime":"2014-12-18T11:14:31Z","Content":"\n\u003Cp\u003EMoved to development discussion.\u003C/p\u003E\u003Cp\u003EI don\u0027t know for sure, but I think it\u0027s just because the two systems just do things differently and use memory in different ways.\u003C/p\u003E\n"},{"CreatedByName":"ratchet freak","CreatedById":119895,"CreatedDateTime":"2014-12-18T11:42:49Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Crimson Sunrise\u0022 data-cite=\u0022Crimson Sunrise\u0022\u003E\u003Cdiv\u003EThat\u0027s in part due to the fact that the OpenGL is an open source library whose code is well known and can be adapted for optimization (mainly because it\u0027s free). DirectX being proprietary, holds other restrictions that keep certain optimizations from happening. You can only use the API the way it is and said API is restricted to the Windows OS (Linux and OSX games have to be ported to use OpenGL instead when you have a Linux or OSX version.)\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThis is false, OpenGL is NOT a library but a free (as in free beer) API. Graphics card vendors will make their own implementations in the drivers that go with the card. They can create and release extensions to it but the process is quite restrictive. There is an open source implementation called MESA aimed to linux-like architectures however the latest version (10.4) only supports openGL 3.3 rather than the newest OpenGL 4.5.\u003C/p\u003E\u003Cp\u003ESome drivers will keep the buffer memory in application memory (allocated by the dll you have to load when accessing OpenGL) as a cache or move it to a different process like the memory allocated to the driver or on the GPU memory or in swap-space. What will actually happen is entirely up to the implementation and the restrictions the OpenGL spec provides (like that you should always be able to read your own buffers).\u003C/p\u003E\n"},{"CreatedByName":"Crimson Sunrise","CreatedById":132102,"CreatedDateTime":"2014-12-18T14:14:16Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022ratchet freak\u0022 data-cite=\u0022ratchet freak\u0022\u003E\u003Cdiv\u003EThis is false, OpenGL is NOT a library but a free (as in free beer) API. Graphics card vendors will make their own implementations in the drivers that go with the card. They can create and release extensions to it but the process is quite restrictive. There is an open source implementation called MESA aimed to linux-like architectures however the latest version (10.4) only supports openGL 3.3 rather than the newest OpenGL 4.5.\u003Cp\u003ESome drivers will keep the buffer memory in application memory (allocated by the dll you have to load when accessing OpenGL) as a cache or move it to a different process like the memory allocated to the driver or on the GPU memory or in swap-space. What will actually happen is entirely up to the implementation and the restrictions the OpenGL spec provides (like that you should always be able to read your own buffers).\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EWhile I do know the difference between Open Source and Free Software, I don\u0027t really care which term is used, since the context is more important than the \u0027correct term\u0027.\u003C/p\u003E\n"}]}