{"TopicId":222628,"ForumId":44,"TopicTitle":"Overview of all AI, not just LLMs","CreatedByName":"darthgently","CreatedById":204885,"CreatedDateTime":"2024-01-05T17:39:49Z","PageNum":1,"Articles":[{"CreatedByName":"darthgently","CreatedById":204885,"CreatedDateTime":"2024-01-05T17:39:49Z","Content":"\n\u003Cp\u003E\nOf course the elephant in the room is the massive differential in energy requirements between silicon and wetware brains in a world woefully lacking the electrical infrastructure to cover the viral plan to electrify all transportation, all HVAC, all tools and appliances,\u00A0 and how alarmingly humongous the projected electrical budget for future silicon compute is also.\u00A0\u00A0\n\u003C/p\u003E\n\u003Cdiv class=\u0022ipsEmbeddedVideo\u0022 contenteditable=\u0022false\u0022\u003E\n\u003Cdiv\u003E\n\u003Ciframe allowfullscreen=\u0022\u0022 frameborder=\u00220\u0022 height=\u0022113\u0022 src=\u0022https://www.youtube-nocookie.com/embed/PZYmFtNhwIA?feature=oembed\u0022 title=\u0022What\u0027s After LLMs?\u0022 width=\u0022200\u0022\u003E\u003C/iframe\u003E\n\u003C/div\u003E\n\u003C/div\u003E\n\u003Cp\u003E\nThis could be a great filter for terrestrial life if we attempt all of this at all costs by gov fiat and/or corporate flexing (or a dangerous partnership between the two) without first having achieved post-scarcity via accessing resources beyond earth and without having first durably planted (modified?) terrestrial life elsewhere beyond earth\n\u003C/p\u003E\n"},{"CreatedByName":"Nuke","CreatedById":10883,"CreatedDateTime":"2024-01-05T17:44:17Z","Content":"\n\u003Cp\u003E\nthis guy has one of the best logos on youtube.\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"darthgently","CreatedById":204885,"CreatedDateTime":"2024-01-05T18:09:17Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224355917\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221704476657\u0022 data-ipsquote-userid=\u002210883\u0022 data-ipsquote-username=\u0022Nuke\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n19 minutes ago, Nuke said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nthis guy has one of the best logos on youtube.\u00A0\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nIt is trendy appearing, I\u0027ll grant that.\u00A0 If you are interested in the details of the compute industry with a focus on hardware, and \u0022cats on an island\u0022, techtechpotato is a great follow, regardless of logo.\u00A0 The \u0022cookie\u0022 in the logo is apparently a shiny, prismatic silicon wafer I\u0027d guess.\u00A0 Hopefully not a CDROM, lol\n\u003C/p\u003E\n"},{"CreatedByName":"Nuke","CreatedById":10883,"CreatedDateTime":"2024-01-05T18:41:00Z","Content":"\n\u003Cp\u003E\nyea i watch his channel.\n\u003C/p\u003E\n"},{"CreatedByName":"StrandedonEarth","CreatedById":89439,"CreatedDateTime":"2024-01-06T02:55:45Z","Content":"\n\u003Cp\u003E\nUnclear on the concept...\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Cimg alt=\u0022JEtfAqX.jpeg\u0022 class=\u0022ipsImage\u0022 data-ratio=\u0022115.73\u0022 height=\u0022971\u0022 width=\u0022839\u0022 src=\u0022https://i.imgur.com/JEtfAqX.jpeg\u0022\u003E\n\u003C/p\u003E\n"},{"CreatedByName":"kerbiloid","CreatedById":129408,"CreatedDateTime":"2024-01-06T04:44:32Z","Content":"\n\u003Cp\u003E\nThe guy at his left elbow has his abdominals on the back.\n\u003C/p\u003E\n"},{"CreatedByName":"darthgently","CreatedById":204885,"CreatedDateTime":"2024-01-07T14:49:09Z","Content":"\n\u003Cp\u003E\nFor context with regards to the projected costs of silicon compute, the human brain runs around 20 watts.\u00A0 The hypothetical\u00A0 wattage of human equivalent silicon compute is likely going to be many orders of magnitude beyond that.\u00A0 We should be focusing on real education of real people if we want to solve problems.\u00A0 Silicon compute is an expensive sidecar to the civilizational/societal process; useful, but very expensive.\u00A0 To be judiciously applied in specific use cases.\u00A0 We can\u0027t afford to replace people en masse with silicon if only from an energy standpoint.\u00A0 We don\u0027t have, nor can afford, the infrastructure for it.\u00A0\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"tomf","CreatedById":57809,"CreatedDateTime":"2024-01-07T17:46:39Z","Content":"\n\u003Cp\u003E\nTo be fair the natural intelligence does require a support system that requires more than just the 20 watts. For the average USAian it comes to just less than 10kW.\n\u003C/p\u003E\n"},{"CreatedByName":"darthgently","CreatedById":204885,"CreatedDateTime":"2024-01-07T18:43:37Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224356766\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221704649599\u0022 data-ipsquote-userid=\u002257809\u0022 data-ipsquote-username=\u0022tomf\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n57 minutes ago, tomf said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nTo be fair the natural intelligence does require a support system that requires more than just the 20 watts. For the average USAian it comes to just less than 10kW.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nYes, but that support is for far more than merely compute.\u00A0 It is what it requires to exist as an evolved intelligence on the only life supporting world we know of in a vast universe.\u00A0 Existence matters!\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222024-01-07T18:44:25Z\u0022 title=\u002201/07/2024 06:44  PM\u0022 data-short=\u0022Jan 7\u0022\u003EJanuary 7\u003C/time\u003E by darthgently\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"tater","CreatedById":119411,"CreatedDateTime":"2024-02-16T05:01:04Z","Content":"\n\u003Cdiv class=\u0022ipsEmbeddedVideo\u0022 contenteditable=\u0022false\u0022\u003E\n\u003Cdiv\u003E\n\u003Ciframe allowfullscreen=\u0022\u0022 frameborder=\u00220\u0022 height=\u0022113\u0022 src=\u0022https://www.youtube-nocookie.com/embed/2fAPgOCjToA?feature=oembed\u0022 title=\u0022OpenAI Sora: All Example Videos with Prompts | Upscaled 4K\u0022 width=\u0022200\u0022\u003E\u003C/iframe\u003E\n\u003C/div\u003E\n\u003C/div\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"tater","CreatedById":119411,"CreatedDateTime":"2024-02-16T14:17:02Z","Content":"\n\u003Cdiv class=\u0022ipsEmbeddedOther\u0022 contenteditable=\u0022false\u0022\u003E\n\u003Ciframe allowfullscreen=\u0022\u0022 data-controller=\u0022core.front.core.autosizeiframe\u0022 data-embedid=\u0022embed7076241660\u0022 src=\u0022https://forum.kerbalspaceprogram.com/index.php?app=core\u0026amp;module=system\u0026amp;controller=embed\u0026amp;url=https://twitter.com/thegarrettscott/status/1758198134134489375\u0022 style=\u0022height:106px;\u0022\u003E\u003C/iframe\u003E\n\u003C/div\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"kerbiloid","CreatedById":129408,"CreatedDateTime":"2024-02-16T14:23:52Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224356710\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221704638949\u0022 data-ipsquote-userid=\u0022204885\u0022 data-ipsquote-username=\u0022darthgently\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nOn 1/7/2024 at 5:49 PM, darthgently said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nFor context with regards to the projected costs of silicon compute, the human brain runs around 20 watts.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nIt\u0027s a human network adaptor LED.\n\u003C/p\u003E\n\u003Cp\u003E\nThe real data storage is in cloud.\n\u003C/p\u003E\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224356766\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221704649599\u0022 data-ipsquote-userid=\u002257809\u0022 data-ipsquote-username=\u0022tomf\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nOn 1/7/2024 at 8:46 PM, tomf said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nTo be fair the natural intelligence does require a support system that requires more than just the 20 watts. For the average USAian it comes to just less than 10kW.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nA modded case with bells and whistles for that adaptor.\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222024-02-16T14:25:06Z\u0022 title=\u002202/16/2024 02:25  PM\u0022 data-short=\u0022Feb 16\u0022\u003EFebruary 16\u003C/time\u003E by kerbiloid\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"tater","CreatedById":119411,"CreatedDateTime":"2024-02-16T19:24:29Z","Content":"\n\u003Cp\u003E\n\u003Ca href=\u0022https://openai.com/research/video-generation-models-as-world-simulators\u0022 rel=\u0022external nofollow\u0022\u003Ehttps://openai.com/research/video-generation-models-as-world-simulators\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nA few quotes:\n\u003C/p\u003E\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nQuote\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nOur results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nImportantly, Sora is a diffusion \u003Cem\u003Etransformer\u003C/em\u003E\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nWe find that video models exhibit a number of interesting emergent capabilities when trained at scale. These capabilities enable Sora to simulate some aspects of people, animals and environments from the physical world. These properties emerge without any explicit inductive biases for 3D, objects, etc.\u2014they are purely phenomena of scale.\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nWe believe the capabilities Sora has today demonstrate that continued scaling of video models is a promising path towards the development of capable simulators of the physical and digital world, and the objects, animals and people that live within them.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nThat last bit is important not for making videos, but for AGI. We all have an internalized real world model, which informs \u0022common sense.\u0022 This might be that for computers.\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222024-02-16T20:06:36Z\u0022 title=\u002202/16/2024 08:06  PM\u0022 data-short=\u0022Feb 16\u0022\u003EFebruary 16\u003C/time\u003E by tater\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"darthgently","CreatedById":204885,"CreatedDateTime":"2024-02-16T22:04:02Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366873\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708111469\u0022 data-ipsquote-userid=\u0022119411\u0022 data-ipsquote-username=\u0022tater\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n2 hours ago, tater said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\n\u003Ca href=\u0022https://openai.com/research/video-generation-models-as-world-simulators\u0022 rel=\u0022external nofollow\u0022\u003Ehttps://openai.com/research/video-generation-models-as-world-simulators\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nA few quotes:\n\u003C/p\u003E\n\u003Cp\u003E\nThat last bit is important not for making videos, but for AGI. We all have an internalized real world model, which informs \u0022common sense.\u0022 This might be that for computers.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nWould an AI for, say,\u00A0 self-driving, if only trained on data from vehicle POV cameras and inertial sensors and such, guess that the wider world was flat (ignoring hills and such) and not an oblate spheroid?\u00A0 \u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nOr would its gyros be sensitive enough to detect the curvature over a longer drive?\u00A0 \u00A0If yes, would it discount the curvature as unimportant and pragmatically embrace flat earthism?\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nI\u0027m wondering to what degree human flat earthers may just be going with the flow of their wetware neural nets in a natural way, but then backfill with bad symbolic \u0022logic\u0022 to support the more fundamental neural net conclusion.\u00A0 This may seem obvious, but I think it important to recognize that some silly conclusions may make some practical sense in a limited domain.\u00A0 And the danger of flat earth, or analogous in other domains, exists for AI.\u00A0 And we don\u0027t want AI to be like that.\u00A0 Do we?\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222024-02-16T22:05:24Z\u0022 title=\u002202/16/2024 10:05  PM\u0022 data-short=\u0022Feb 16\u0022\u003EFebruary 16\u003C/time\u003E by darthgently\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"PakledHostage","CreatedById":8059,"CreatedDateTime":"2024-02-17T01:52:01Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366901\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708121042\u0022 data-ipsquote-userid=\u0022204885\u0022 data-ipsquote-username=\u0022darthgently\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n3 hours ago, darthgently said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nWould an AI for, say,\u00A0 self-driving, if only trained on data from vehicle POV cameras and inertial sensors and such, guess that the wider world was flat (ignoring hills and such) and not an oblate spheroid?\u00A0 \u00A0\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nAnd would it conclude that red lights mean stop, green lights mean go, and yellow lights mean go really fast?\n\u003C/p\u003E\n"},{"CreatedByName":"mikegarrison","CreatedById":137807,"CreatedDateTime":"2024-02-17T02:26:20Z","Content":"\n\u003Cp\u003E\nIMO, these LLM that people have gotten all excited about seem to be excellent\u00A0Wernicke\u0027s aphasia simulators. They are really good at sounding fluent but conveying no real meaning.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Ca href=\u0022https://garymarcus.substack.com/p/statistics-versus-understanding-the\u0022 rel=\u0022external nofollow\u0022\u003Ehttps://garymarcus.substack.com/p/statistics-versus-understanding-the\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nIn that article, for instance, you see lots of pictures that AI generated when asked for an image of a person writing with their left hand. They all show right-handed people -- because the AI doesn\u0027t actually know what left and right is, and the images that they have been trained on overwhelmingly show people writing with their right hands.\n\u003C/p\u003E\n"},{"CreatedByName":"darthgently","CreatedById":204885,"CreatedDateTime":"2024-02-17T02:40:22Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366930\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708136780\u0022 data-ipsquote-userid=\u0022137807\u0022 data-ipsquote-username=\u0022mikegarrison\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n7 minutes ago, mikegarrison said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nIMO, these LLM that people have gotten all excited about seem to be excellent\u00A0Wernicke\u0027s aphasia simulators. They are really good at sounding fluent but conveying no real meaning.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Ca href=\u0022https://garymarcus.substack.com/p/statistics-versus-understanding-the\u0022 rel=\u0022external nofollow\u0022\u003Ehttps://garymarcus.substack.com/p/statistics-versus-understanding-the\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nIn that article, for instance, you see lots of pictures that AI generated when asked for an image of a person writing with their left hand. They all show right-handed people -- because the AI doesn\u0027t actually know what left and right is, and the images that they have been trained on overwhelmingly show people writing with their right hands.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nAgreed.\u00A0 It is just automated knee jerk mostly.\u00A0 \u00A0 I read something the other day about efforts to layer over a more old school symbolic logical AI approach on top of the neutral approach which seemed promising.\u00A0 If I can dig up the link I\u0027ll post\n\u003C/p\u003E\n"},{"CreatedByName":"JoeSchmuckatelli","CreatedById":154477,"CreatedDateTime":"2024-02-17T02:58:25Z","Content":"\n\u003Cp\u003E\nWon\u0027t lie - I\u0027m impressed by some of this.\n\u003C/p\u003E\n\u003Cp\u003E\nMind you - the folks already welcoming our AI orverlordes are premateuaur.\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n(spelling intentional, for those who get it)\n\u003C/p\u003E\n"},{"CreatedByName":"tater","CreatedById":119411,"CreatedDateTime":"2024-02-17T04:31:30Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366930\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708136780\u0022 data-ipsquote-userid=\u0022137807\u0022 data-ipsquote-username=\u0022mikegarrison\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n1 hour ago, mikegarrison said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nIMO, these LLM that people have gotten all excited about seem to be excellent\u00A0Wernicke\u0027s aphasia simulators. They are really good at sounding fluent but conveying no real meaning.\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Ca href=\u0022https://garymarcus.substack.com/p/statistics-versus-understanding-the\u0022 rel=\u0022external nofollow\u0022\u003Ehttps://garymarcus.substack.com/p/statistics-versus-understanding-the\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nIn that article, for instance, you see lots of pictures that AI generated when asked for an image of a person writing with their left hand. They all show right-handed people -- because the AI doesn\u0027t actually know what left and right is, and the images that they have been trained on overwhelmingly show people writing with their right hands.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nHard to believe a Feb 2024 article used GPT-3, not GPT-4. The latter is far more capable. Also, the limited tokens really matters. With more tokens you can take the model\u2014pretrained\u2014and \u003Cem\u003Eteach\u003C/em\u003E it. It gives a wrong answer, and you not just correct it, but show it HOW to correct it\u2014like a kid asking math homework questions. You ask the kid to show their work, then maybe you ask if they checked the signs\u2014then they notice they added not subtracted moving a variable from one to the other side of the expression. You don\u0027t tell them, you lead them. Models do this now with multi-shot questioning, and do far better.\n\u003C/p\u003E\n\u003Cp\u003E\nYes, it is finding the next word, just sounding fluent\u2014but they are none the less also more than that. They have demonstrated emergent capabilities. The theory of mind examples in that long paper (microsoft people? I linked it in another thread) are telling. That was not \u0022finding the next word\u0022 via statistics, it correctly explains what and WHY the different characters in the scenario think what it says they think.\n\u003C/p\u003E\n\u003Cp\u003E\nAt a certain level faking intelligence IS intelligence. As has happened throughout the quest for AI, the goalposts will shift\u2014often rightfully. Back in the day chess was said to require intelligence. Humans fell, the bar was moved. Go is much harder than chess, surely it requires intelligence... nah, not enough. Chatbots could beat a Turing test right now (depending on the interlocutor), nah, not enough, bar moved.\n\u003C/p\u003E\n\u003Cp\u003E\nMaybe coming up with novel math or scientific ideas will be enough? I have no idea, but I think it\u0027s far closer than it had been.\n\u003C/p\u003E\n"},{"CreatedByName":"mikegarrison","CreatedById":137807,"CreatedDateTime":"2024-02-17T06:18:29Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366939\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708144290\u0022 data-ipsquote-userid=\u0022119411\u0022 data-ipsquote-username=\u0022tater\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n1 hour ago, tater said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nHard to believe a Feb 2024 article used GPT-3, not GPT-4. The latter is far more capable. Also, the limited tokens really matters. With more tokens you can take the model\u2014pretrained\u2014and \u003Cem\u003Eteach\u003C/em\u003E it. It gives a wrong answer, and you not just correct it, but show it HOW to correct it\u2014like a kid asking math homework questions. You ask the kid to show their work, then maybe you ask if they checked the signs\u2014then they notice they added not subtracted moving a variable from one to the other side of the expression. You don\u0027t tell them, you lead them. Models do this now with multi-shot questioning, and do far better.\n\u003C/p\u003E\n\u003Cp\u003E\nYes, it is finding the next word, just sounding fluent\u2014but they are none the less also more than that. They have demonstrated emergent capabilities. The theory of mind examples in that long paper (microsoft people? I linked it in another thread) are telling. That was not \u0022finding the next word\u0022 via statistics, it correctly explains what and WHY the different characters in the scenario think what it says they think.\n\u003C/p\u003E\n\u003Cp\u003E\nAt a certain level faking intelligence IS intelligence. As has happened throughout the quest for AI, the goalposts will shift\u2014often rightfully. Back in the day chess was said to require intelligence. Humans fell, the bar was moved. Go is much harder than chess, surely it requires intelligence... nah, not enough. Chatbots could beat a Turing test right now (depending on the interlocutor), nah, not enough, bar moved.\n\u003C/p\u003E\n\u003Cp\u003E\nMaybe coming up with novel math or scientific ideas will be enough? I have no idea, but I think it\u0027s far closer than it had been.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nThe point is that the whole method is fundamentally flawed. Not only is faking intelligence not intelligence, but it\u0027s not even close to intelligence. It\u0027s like if you studied an entire dictionary and learned exactly how every word is related to every other word, but still had no clue that any of them actually refer to a real world outside the dictionary.\n\u003C/p\u003E\n\u003Cp\u003E\nThey don\u0027t exhibit \u0022emergent capabilities\u0022. We *see* emergent capabilities in them, just like we see patterns in tea leaves and shapes in clouds and the face of Jesus on a tortilla. We interpret their babbling as meaningful, but the \u0022emergent capabilities\u0022 being demonstrated are all on our side of the fence.\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222024-02-17T06:21:49Z\u0022 title=\u002202/17/2024 06:21  AM\u0022 data-short=\u0022Feb 17\u0022\u003EFebruary 17\u003C/time\u003E by mikegarrison\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"KSK","CreatedById":61025,"CreatedDateTime":"2024-02-17T08:03:10Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366939\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708144290\u0022 data-ipsquote-userid=\u0022119411\u0022 data-ipsquote-username=\u0022tater\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n3 hours ago, tater said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nMaybe coming up with novel math or scientific ideas will be enough? I have no idea, but I think it\u0027s far closer than it had been.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nThey\u0027ve got a way to go\u003Ca href=\u0022https://arstechnica.com/science/2024/02/scientists-aghast-at-bizarre-ai-rat-with-huge-genitals-in-peer-reviewed-article/\u0022 rel=\u0022external nofollow\u0022\u003E yet\u003C/a\u003E though. Forget the title of the article - IMO that particular picture is sort of OK in an exaggerated for clarity way.\u00A0 The rest of the diagrams though - and their captions - are just typical LLM mashups. Superficially convincing in that they look sort of like the real thing, but actually meaningless.\n\u003C/p\u003E\n"},{"CreatedByName":"tater","CreatedById":119411,"CreatedDateTime":"2024-02-17T08:04:04Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366953\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708150709\u0022 data-ipsquote-userid=\u0022137807\u0022 data-ipsquote-username=\u0022mikegarrison\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n1 hour ago, mikegarrison said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nThe point is that the whole method is fundamentally flawed. Not only is faking intelligence not intelligence, but it\u0027s not even close to intelligence. It\u0027s like if you studied an entire dictionary and learned exactly how every word is related to every other word, but still had no clue that any of them actually refer to a real world outside the dictionary.\n\u003C/p\u003E\n\u003Cp\u003E\nThey don\u0027t exhibit \u0022emergent capabilities\u0022. We *see* emergent capabilities in them, just like we see patterns in tea leaves and shapes in clouds and the face of Jesus on a tortilla. We interpret their babbling as meaningful, but the \u0022emergent capabilities\u0022 being demonstrated are all on our side of the fence.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nI disagree. If you can string words together, you can string words together. Intelligence != consciousness. That\u0027s the point of a Turing test. The machine can know or \u0022understand\u0022 \u003Cem\u003Enothing\u003C/em\u003E, but if you can\u0027t tell it from a human, blinded, what difference does it make? If you can ask it questions, and it can answer as well as any human\u2014how is it different from the standpoint of intelligence?\n\u003C/p\u003E\n\u003Cp\u003E\nThe theory of mind questions were in fact emergent, and unexpected. Fed scenarios using garbage words as the subject (so said words existed in no training data), the scenario about the one guy losing his FISBIT (or whatever the word was) was described accurately by GPT-4, as well as possible internal motivations of the humans in the scenario, and what they might be thinking to themselves. The model above (video from text), and the related paper says:\n\u003C/p\u003E\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\nQuote\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nWe find that video models exhibit a number of interesting emergent capabilities when trained at scale. These capabilities enable Sora to simulate some aspects of people, animals and environments from the physical world. These properties emerge without any explicit inductive biases for 3D, objects, etc.\u2014they are purely phenomena of scale.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nThis is not dissimilar from the \u0022nothing but nets\u0022 Tesla FSD 12 trained entirely on driving data from other teslas. It was never told what a stop sign is, yet it stops at them. It figured out to recognize and slow for speed bumps. These are also emergent behaviors as they are not innate properties of the system (though perhaps less profound than describing state of mind in a human).\n\u003C/p\u003E\n\u003Cp\u003E\nA lot of this depends on the definition of intelligence, honestly. If that includes \u0022consciousness\u0022 (ill-defined even for humans) then yeah, that\u0027s going to be hard to get to, or even demonstrate. If it is \u0022the ability to acquire and apply knowledge and skills.\u0022 then I think \u0022faking it\u0022 is not meaningfully different than being it. How does a pathologist read a biopsy slide? He\u0027s trained on images of different pathology, and looks for patterns that match what he recognizes as abnormal, and categorizes them. AI systems can already do this\u2014and when they tested it, they found that the AI system had discovered a new tumor marker pattern (the data had been subsequently verified, and had some examples where they knew cancer, but it was not thought to be visible).\n\u003C/p\u003E\n"},{"CreatedByName":"KSK","CreatedById":61025,"CreatedDateTime":"2024-02-17T08:09:51Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366958\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708157044\u0022 data-ipsquote-userid=\u0022119411\u0022 data-ipsquote-username=\u0022tater\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n4 minutes ago, tater said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nA lot of this depends on the definition of intelligence, honestly. If that includes \u0022consciousness\u0022 (ill-defined even for humans) then yeah, that\u0027s going to be hard to get to, or even demonstrate. If it is \u0022the ability to acquire and apply knowledge and skills.\u0022 then I think \u0022faking it\u0022 is not meaningfully different than being it. How does a pathologist read a biopsy slide? He\u0027s trained on images of different pathology, and looks for patterns that match what he recognizes as abnormal, and categorizes them. AI systems can already do this\u2014and when they tested it, they found that the AI system had discovered a new tumor marker pattern (the data had been subsequently verified, and had some examples where they knew cancer, but it was not thought to be visible).\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nWouldn\u0027t it be more correct to say that the AI had discovered a new correlation between a set of images? I doubt it had any concept of what a tumour marker was, what a biopsy slide was, or the implications of discovering one on the other.\n\u003C/p\u003E\n"},{"CreatedByName":"tater","CreatedById":119411,"CreatedDateTime":"2024-02-17T08:10:33Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366957\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708156990\u0022 data-ipsquote-userid=\u002261025\u0022 data-ipsquote-username=\u0022KSK\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n8 hours ago, KSK said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nThey\u0027ve got a way to go\u003Ca href=\u0022https://arstechnica.com/science/2024/02/scientists-aghast-at-bizarre-ai-rat-with-huge-genitals-in-peer-reviewed-article/\u0022 rel=\u0022external nofollow\u0022\u003E yet\u003C/a\u003E though. Forget the title of the article - IMO that particular picture is sort of OK in an exaggerated for clarity way.\u00A0 The rest of the diagrams though - and their captions - are just typical LLM mashups. Superficially convincing in that they look sort of like the real thing, but actually meaningless.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nI don\u0027t disagree, but the rate of improvement is nonetheless striking. I think that building \u0022common sense\u0022 in the form of a world-model is probably required for systems to have meaningful general intelligence in the future. We have that from existing on the world, and seeing certain real world cause an effect since being toddlers. Push the spoon, and it falls off the high chair tray, then the grownups pick it up... fun! Do it again! Hence me thinking that embodiment might be required. That said, the ability to build internally consistent videos, with common sense physics within is a sort of world-model, so it\u0027s a start.\n\u003C/p\u003E\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366959\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708157391\u0022 data-ipsquote-userid=\u002261025\u0022 data-ipsquote-username=\u0022KSK\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n8 hours ago, KSK said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nWouldn\u0027t it be more correct to say that the AI had discovered a new correlation between a set of images? I doubt it had any concept of what a tumour marker was, what a biopsy slide was, or the implications of discovering one on the other.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nFair enough. If a model in a year comes up with something novel analyzing some dataset, and can describe it... then what, we say, it\u0027s just an LLM writing plausible English to describe some data it observed, it doesn\u0027t \u0022know\u0022 anything. Maybe some people will never recognize it as more than a statistical model.\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222024-02-17T16:25:20Z\u0022 title=\u002202/17/2024 04:25  PM\u0022 data-short=\u0022Feb 17\u0022\u003EFebruary 17\u003C/time\u003E by tater\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"KSK","CreatedById":61025,"CreatedDateTime":"2024-02-17T08:33:18Z","Content":"\n\u003Cblockquote class=\u0022ipsQuote\u0022 data-ipsquote=\u0022\u0022 data-ipsquote-contentapp=\u0022forums\u0022 data-ipsquote-contentclass=\u0022forums_Topic\u0022 data-ipsquote-contentcommentid=\u00224366960\u0022 data-ipsquote-contentid=\u0022222628\u0022 data-ipsquote-contenttype=\u0022forums\u0022 data-ipsquote-timestamp=\u00221708157433\u0022 data-ipsquote-userid=\u0022119411\u0022 data-ipsquote-username=\u0022tater\u0022\u003E\n\u003Cdiv class=\u0022ipsQuote_citation\u0022\u003E\n23 minutes ago, tater said:\n\u003C/div\u003E\n\u003Cdiv class=\u0022ipsQuote_contents\u0022\u003E\n\u003Cp\u003E\nFair enough. If a model in a year comes up with something novel analyzing some dataset, and can describe it... then what, we say, it\u0027s just an LLM writing plausibel English to describe some data it observed, it doesn\u0027t \u0022know\u0022 anything. Maybe some people will never recognize it as more than a statistical model.\n\u003C/p\u003E\n\u003C/div\u003E\n\u003C/blockquote\u003E\n\u003Cp\u003E\nProbably. As you said, the goalposts are always moving.\n\u003C/p\u003E\n\u003Cp\u003E\nIf somebody came up with a model that moved beyond mere description and basically wrote an internally consistent first draft paper without being led through the process by its metaphorical hand - then I think at that point I\u0027d agree that the question of whether the model was actually intelligent, or just faking it, was irrelevant.\n\u003C/p\u003E\n\u003Cp\u003E\nBy first draft paper, I\u0027m meaning something that sets the background for the new dataset in terms of what\u0027s been observed before, describes the new analysis, and then presents some sort of meaningful conclusion from that analysis. Is it consistent with previous results? Does it invalidate previous results. Does it have any wider repercussions? Does it suggest any new avenues of research?\n\u003C/p\u003E\n\u003Cp\u003E\nIt\u0027s probably unrealistic to expect anything quite as pithy or insightful as Crick \u0026amp; Watson\u0027s \u0022It has not escaped our notice that the specific pairing we have postulated immediately suggests a possible copying mechanism for the genetic material\u0022 but that\u0027s the kind of thing I\u0027m getting at.\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222024-02-17T08:34:35Z\u0022 title=\u002202/17/2024 08:34  AM\u0022 data-short=\u0022Feb 17\u0022\u003EFebruary 17\u003C/time\u003E by KSK\u003C/strong\u003E\n\u003C/span\u003E\n"}]}