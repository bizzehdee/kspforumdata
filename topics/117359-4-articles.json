{"TopicId":117359,"ForumId":44,"TopicTitle":"Von Neumann probes","CreatedByName":"Souper","CreatedById":86003,"CreatedDateTime":"2015-08-01T00:20:45Z","PageNum":4,"Articles":[{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2015-08-06T15:03:56Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Jouni\u0022 data-cite=\u0022Jouni\u0022\u003E\u003Cdiv\u003ELet\u0027s assume that we build a von Neumann probe like that. It\u0027s probably huge, and carries a lot of equipment that no longer exists on Earth. We launch it towards a promising solar system...\u003Cp\u003E...and hope that it finds an exact duplicate of the Earth. Otherwise it\u0027s in trouble, because it may not find all the raw materials it needs, or have the right equipment for processing them. Now it needs to improvise and build completely new machines for tasks nobody had even thought about before. It\u0027s just a single probe, so it may not be able to figure out everything before it runs out of some critical resource, or before making a critical mistake.\u003C/p\u003E\u003Cp\u003EMaybe it\u0027s better to launch many probes to the same destination. That way, the mission isn\u0027t doomed, if one individual isn\u0027t creative enough or makes a bad choice. Unfortunately, even that may not be enough. The probes may come up with a solution, but they may be unable to build the machines the solution involves quickly enough.\u003C/p\u003E\u003Cp\u003EPerhaps the real solution is to seed a self-sustaining ecosystem at the destination, giving the probes enough time to adapt to the conditions and to figure out new ways to do things. But how do we do that, if we don\u0027t even know what the destination is like before the launch? The obvious solution is to stay in contact with the source, and launch resupply missions once the destination has been properly explored. At this point, the whole thing starts feeling more like colonization than von Neumann machines.\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EYou would not land on an planet you would be better off going for asteroids. The probe must be smart enough to identify suitable ones and mine them for needed materials. \u003C/p\u003E\u003Cp\u003EThe probe don\u0027t need to be much smarter than this, yes it need to be able to replace broken parts with new who is made, it the redundancy breaks down it will not be able to repair itself.\u003C/p\u003E\u003Cp\u003EHowever its first task will be to scale up production and add redundancy.\u003C/p\u003E\u003Cp\u003ENote that an human colony will face the exact same problem unless they find an parallel earth where they can live of the land or at least grow plants, only then can they afford to loose advanced technology. If not they would have to keep the life support system running, yes humans are smarter and better at repairing but the complexity problem kicks in just as much here.\u003C/p\u003E\n"},{"CreatedByName":"Jouni","CreatedById":97346,"CreatedDateTime":"2015-08-06T15:04:06Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022ZetaX\u0022 data-cite=\u0022ZetaX\u0022\u003E\u003Cdiv\u003ENo, that system of reactions must not be self-sustaining. They are simply there already. It might use them until none are left (then they probably die).\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EOk, let\u0027s drop the \u0022self-sustaining\u0022 part. It doesn\u0027t change anything. We have a complex system of chemical reactions set up by some unknown process. The system is complex enough and large enough that it could bootstrap a proto-life ecosystem under suitable conditions.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003EAgain: your setting is pointless as you in the end are counting everything as an ecosystem, thus devoiding your argument from any meaning. If we actually build such probes, you could still say that \u0022it is just the universe sustaining a complex ecosystem\u0022.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EPlease reread my first message on page 7. I tried to explain there what I really meant.\u003C/p\u003E\n"},{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2015-08-06T15:10:47Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Jouni\u0022 data-cite=\u0022Jouni\u0022\u003E\u003Cdiv\u003EBecause the cell doesn\u0027t duplicate itself in an ocean. It duplicates itself in a complex self-sustaining system of chemical reactions. (Note that the term \u0027ecosystem\u0027 is often used for non-biological systems with similar characteristics as biological ecosystems.)\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EYou however can have an extremely primitive ecosystem, just single celled plants with photosynthesis should do in theory. Growth would probably be restricted of lack of co2 however new is released by volcanoes and. Advanced organisms need an more advanced ecosystem but that is another issue.\u003C/p\u003E\n"},{"CreatedByName":"Jouni","CreatedById":97346,"CreatedDateTime":"2015-08-06T15:21:50Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022KSK\u0022 data-cite=\u0022KSK\u0022\u003E\u003Cdiv\u003EYes I am but that doesn\u0027t make any difference to my argument. Start with a complex machine that is a) composed of simpler sub-machines, \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_cool.png\u0022 alt=\u0022B)\u0022\u003E capable of building slightly more complex sub-machines than it, itself is made from and c) capable of assembling those more complex sub-machines into a new machine. Watch that complex machine build a more complex machine.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EDo you also assume that the machine is able to build new copies of every sub-machine it consists of? In that case, your argument is tautological and doesn\u0027t tell anything about the reality.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003EIncorrect. Go and read up on computable vs non computable problems. It is entirely possible to have a process that you completely understand and yet the only way to predict what the process will do is to run it and see what happens.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EI\u0027m quite familiar with computability. My favorite result there is Rice\u0027s Theorem. It essentially says that even if you\u0027re given the source code of a computer program and the opportunity to run it as many times as you want, it\u0027s logically impossible to say anything about what the program does. As with all statements involving non-computability, you must wrap the statement in a thick layer of quantifiers to say anything relevant to the real world.\u003C/p\u003E\u003Cp\u003EMy point was that in order to differentiate between understanding and storytelling, we must be able to make predictions or produce other tangible results. Some things are just logically impossible to understand, while others are practically impossible due to their complexity.\u003C/p\u003E\n"},{"CreatedByName":"Camacha","CreatedById":59088,"CreatedDateTime":"2015-08-06T15:41:13Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Jouni\u0022 data-cite=\u0022Jouni\u0022\u003E\u003Cdiv\u003EEverything just keeps getting more and more complex all the time.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EYou keep on repeating that over and over, but that does not make it true. I have a reasonable insight into what makes a machine and what goes into producing something and stating that producing ever more complex parts/machines requires ever larger and more complex production machines simply is not true, and that these things would become ever more separated as complexity increases also is not true. It has been the case for a while and in certain areas, but both modern production and developments in different areas show us it is not a rule that is absolute.\u003C/p\u003E\u003Cp\u003EThat is not even taking the human component in machines, which arguably is an incredibly complex and high maintenance tool, into account.\u003C/p\u003E\n"},{"CreatedByName":"KSK","CreatedById":61025,"CreatedDateTime":"2015-08-06T16:31:08Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Jouni\u0022 data-cite=\u0022Jouni\u0022\u003E\u003Cdiv\u003EDo you also assume that the machine is able to build new copies of every sub-machine it consists of? In that case, your argument is tautological and doesn\u0027t tell anything about the reality.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EOf course but I fail to see the tautology. Quite the opposite given that this is an essential, in fact a defining feature, of a von Neumann machine.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003E\u003Cp\u003EI\u0027m quite familiar with computability. My favorite result there is Rice\u0027s Theorem. It essentially says that even if you\u0027re given the source code of a computer program and the opportunity to run it as many times as you want, it\u0027s logically impossible to say anything about what the program does. As with all statements involving non-computability, you must wrap the statement in a thick layer of quantifiers to say anything relevant to the real world.\u003C/p\u003E\u003Cp\u003EMy point was that in order to differentiate between understanding and storytelling, we must be able to make predictions or produce other tangible results. Some things are just logically impossible to understand, while others are practically impossible due to their complexity.\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EIn that case, let me refer you to the three body problem (since we\u0027re on the KSP forum). We can understand everything about the relevant orbital dynamics but cannot use them to make tangible predictions since the system is inherently chaotic. So it\u0027s logically possible to understand the system but we cannot use that understanding to predict its behaviour.\u003C/p\u003E\n"},{"CreatedByName":"Jouni","CreatedById":97346,"CreatedDateTime":"2015-08-06T16:42:39Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Camacha\u0022 data-cite=\u0022Camacha\u0022\u003E\u003Cdiv\u003EYou keep on repeating that over and over, but that does not make it true. I have a reasonable insight into what makes a machine and what goes into producing something and stating that producing ever more complex parts/machines requires ever larger and more complex production machines simply is not true, and that these things would become ever more separated as complexity increases also is not true. It has been the case for a while and in certain areas, but both modern production and developments in different areas show us it is not a rule that is absolute.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003ELook at the entire system, not just the machine producing the final product. What intermediate products are used, and how are they produced? How are the machines used for making the intermediate/final products built? Trace all this recursively, until you reach primary production. It\u0027s always possible to make one part of the system less complex, but the price is increased complexity in other parts of the system.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022KSK\u0022 data-cite=\u0022KSK\u0022\u003E\u003Cdiv\u003EOf course but I fail to see the tautology. Quite the opposite given that this is an essential, in fact a defining feature, of a von Neumann machine.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThe debate is about whether von Neumann machines are possible. If you assume that they\u0027re possible, your argument looks like a tautology.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003EIn that case, let me refer you to the three body problem (since we\u0027re on the KSP forum). We can understand everything about the relevant orbital dynamics but cannot use them to make tangible predictions since the system is inherently chaotic. So it\u0027s logically possible to understand the system but we cannot use that understanding to predict its behaviour.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThe last time I checked, weather forecasts were quite reliable.\u003C/p\u003E\n"},{"CreatedByName":"Camacha","CreatedById":59088,"CreatedDateTime":"2015-08-06T17:07:50Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Jouni\u0022 data-cite=\u0022Jouni\u0022\u003E\u003Cdiv\u003ELook at the entire system, not just the machine producing the final product. What intermediate products are used, and how are they produced? How are the machines used for making the intermediate/final products built? Trace all this recursively, until you reach primary production. It\u0027s always possible to make one part of the system less complex, but the price is increased complexity in other parts of the system.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EProve it. Simply repeating your idea over and over tells us nothing. Like I said, I happen to know a little about about production and I just do not see it.\u003C/p\u003E\n"},{"CreatedByName":"Technical Ben","CreatedById":10512,"CreatedDateTime":"2015-08-06T18:03:04Z","Content":"\n\u003Cp\u003EIf I have a RepRap and it\u0027s just a matter of progressive iteration, could I not turn it in to an Apple Ipad producer with relative ease? If my RepRap does not have this ability, what additional features do I need to get to that? At what point do I go from \u0022can only make things out of plastic\u0022 to \u0022can make everything from glass to metalwork to transistors to silicone chips\u0022?\u003C/p\u003E\u003Cp\u003EIf it requires not additional complexity for a construction system or manufacturing process to progress, then any RepRap/constructor can be programmed to iterate into a universal constructor.\u003C/p\u003E\u003Cp\u003EI don\u0027t see that happening, so it seems there \u003Cem\u003Eis\u003C/em\u003E a limiting factor to manufacturing processes.\u003C/p\u003E\u003Cp\u003EVon Neumann machines/UCs might be possible, but in no way are they assumed to be possible for us to currently construct.\u003C/p\u003E\n"},{"CreatedByName":"Jouni","CreatedById":97346,"CreatedDateTime":"2015-08-06T18:03:07Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Camacha\u0022 data-cite=\u0022Camacha\u0022\u003E\u003Cdiv\u003EProve it. Simply repeating your idea over and over tells us nothing. Like I said, I happen to know a little about about production and I just do not see it.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThe world is now more complex than it was 10 years ago, when it was more complex than 20 years ago, and so on. Pretty much everything produced today involves bigger and more complex supply chains than World War II. Computers are used for almost everything, and the production of some of their components involves huge facilities with large one-of-a-kind machines.\u003C/p\u003E\u003Cp\u003EIf you want more specific answers, ask more specific questions.\u003C/p\u003E\n"},{"CreatedByName":"ZetaX","CreatedById":60692,"CreatedDateTime":"2015-08-06T18:06:40Z","Content":"\n\u003Cp\u003EThere is a difference between there simply being those long chains and them being strictly necessary. They are simply efficient (from a market point of view), but they are not necessary.\u003C/p\u003E\n"},{"CreatedByName":"Camacha","CreatedById":59088,"CreatedDateTime":"2015-08-06T18:53:01Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Jouni\u0022 data-cite=\u0022Jouni\u0022\u003E\u003Cdiv\u003EThe world is now more complex than it was 10 years ago, when it was more complex than 20 years ago, and so on. Pretty much everything produced today involves bigger and more complex supply chains than World War II. Computers are used for almost everything, and the production of some of their components involves huge facilities with large one-of-a-kind machines.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThat is not proof. We need proof of your statements, not some casual and non-causal observation. Look at your own statements, and back them up with proven facts, research papers and other sources.\u003C/p\u003E\n"},{"CreatedByName":"ZetaX","CreatedById":60692,"CreatedDateTime":"2015-08-06T19:14:41Z","Content":"\n\u003Cp\u003EMay I suggest that Jouni states a formal definition of complexity, including how one might measure it\u00C3\u201A\u00C2\u00BF Then we can discuss if a) it is adequate, \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_cool.png\u0022 alt=\u0022B)\u0022\u003E whether it in- or decreases.\u003C/p\u003E\n"},{"CreatedByName":"KSK","CreatedById":61025,"CreatedDateTime":"2015-08-06T20:33:43Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Jouni\u0022 data-cite=\u0022Jouni\u0022\u003E\u003Cdiv\u003E The debate is about whether von Neumann machines are possible. If you assume that they\u0027re possible, your argument looks like a tautology.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EAhh, I see. Thank you. \u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003EThe last time I checked, weather forecasts were quite reliable.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EOnly up to a point, as I think you well know. And that has nothing at all to do with my argument which was a rebuttal of your assertion that \u0022in order to differentiate between understanding and storytelling, we must be able to make predictions or produce other tangible results. Some things are just logically impossible to understand, while others are practically impossible due to their complexity.\u0022\u003C/p\u003E\u003Cp\u003EWhich is just flat out wrong. We can understand everything about a system and yet be unable to make useful predictions about it. In fact it is our deep understanding of that system that leads us to appreciate its unpredictability.\u003C/p\u003E\n"},{"CreatedByName":"Jouni","CreatedById":97346,"CreatedDateTime":"2015-08-06T22:55:16Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Camacha\u0022 data-cite=\u0022Camacha\u0022\u003E\u003Cdiv\u003EThat is not proof. We need proof of your statements, not some casual and non-causal observation. Look at your own statements, and back them up with proven facts, research papers and other sources.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EPlease be more specific. What are the exact statements you\u0027re interested in, what is your understanding of the issues, and why do you think so?\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022ZetaX\u0022 data-cite=\u0022ZetaX\u0022\u003E\u003Cdiv\u003EMay I suggest that Jouni states a formal definition of complexity, including how one might measure it\u00C3\u201A\u00C2\u00BF Then we can discuss if a) it is adequate, \u003Cimg src=\u0022//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_cool.png\u0022 alt=\u0022B)\u0022\u003E whether it in- or decreases.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EWe could use some standard definitions from algorithmic information theory. For example, let\u0027s choose an universal model of computation. The complexity of an object is the length of the shortest program that describes a class of objects, among which the object in question has maximal conditional Kolmogorov complexity. (Or something like that. It\u0027s been a while since I last touched algorithmic information theory.) This kind of complexity is obviously uncomputable (like with any reasonable definition of complexity), but the minimum description length approach provides a principled way for approximating it.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022KSK\u0022 data-cite=\u0022KSK\u0022\u003E\u003Cdiv\u003EWhich is just flat out wrong. We can understand everything about a system and yet be unable to make useful predictions about it. In fact it is our deep understanding of that system that leads us to appreciate its unpredictability.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThat kind of understanding is superficial, not deep. If there are no practical consequences, the understanding is no different from stories about the Flying Spaghetti Monster.\u003C/p\u003E\n"},{"CreatedByName":"_Augustus_","CreatedById":115084,"CreatedDateTime":"2015-08-06T23:01:34Z","Content":"\n\u003Cp\u003EAren\u0027t humans technically Von Neumann probes?\u003C/p\u003E\n"},{"CreatedByName":"Bill Phil","CreatedById":127797,"CreatedDateTime":"2015-08-07T00:06:00Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022_Augustus_\u0022 data-cite=\u0022_Augustus_\u0022\u003E\u003Cdiv\u003EAren\u0027t humans technically Von Neumann probes?\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003ENo. We create similar copies, but they\u0027re quite different. We\u0027re also not probes..,\u003C/p\u003E\n"},{"CreatedByName":"_Augustus_","CreatedById":115084,"CreatedDateTime":"2015-08-07T00:19:35Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Bill Phil\u0022 data-cite=\u0022Bill Phil\u0022\u003E\u003Cdiv\u003ENo. We create similar copies, but they\u0027re quite different. We\u0027re also not probes..,\u003C/div\u003E\u003C/blockquote\u003E Give two humans one of these:\u003Cp\u003E\u003Cimg src=\u0022http://i.kinja-img.com/gawker-media/image/upload/s--WE1nQdla--/c_fit,fl_progressive,q_80,w_320/18mhv1zr9whipjpg.jpg\u0022 alt=\u002218mhv1zr9whipjpg.jpg\u0022\u003E\u003C/p\u003E\u003Cp\u003EAnd enlarge the interior space a little\u003C/p\u003E\u003Cp\u003EAnd have a pureed food tube, a water faucet and drink pouch...\u003C/p\u003E\u003Cp\u003EAnd ta-da! You have a Von Neumann probe.\u003C/p\u003E\n"},{"CreatedByName":"SomeGuy12","CreatedById":103022,"CreatedDateTime":"2015-08-07T00:29:57Z","Content":"\n\u003Cp\u003EE-coli has 28,000 mechanical parts. It is very complex, and it contains logic circuitry similar to a computer, sensors, movement systems, and so forth. It needs as substrate trace minerals and sugar to self replicate, as well as an aqueous environment. That is it. This is a strong existence proof that a true von neumann probe is feasible, eventually. \u003C/p\u003E\u003Cp\u003EWhat would such a probe actually look like? Well, like e-coli, it would need an internal system that can string together simple \u0022feedstock\u0022 molecules into larger molecules that can perform tasks. It would also need the internal systems to make new feedstock. Every robot part in the probe would need to ultimately made of things that can be made from these larger molecules made from the feedstock molecules. \u003C/p\u003E\u003Cp\u003EProposed design : the robot parts would be cubical metal subunits, on the order of the size of modern living cells. There would be between 10 and 100 specialized types of subunits that each perform a basic task. The obvious subunit is a cube that just has little attachment pieces on all sides that cause it to lock to adjacent subunits. Then there might be a kind that is like the first basic subunit, but one face of the cube has a sliding rail where things can slide up and down. This type goes in a joint. Then, another kind might have a gear on the side and an internal motor, and be capable of driving pieces. And so on.\u003C/p\u003E\u003Cp\u003EThe subunits would have to be made of a series of a small pieces that got made from the feedstock. Many many pieces would be shared in common between the subunits. They would be made using convergent assembly on a nanoscale manufacturing line. \u003C/p\u003E\u003Cp\u003EThe probe would need to eat - it would eat rocks and digest them by converting the rocks to plasma then directing the plasma using magnetic separation devices.\u003C/p\u003E\u003Cp\u003EOr it might dissolve the rocks in acid and water and use a system much more similar to modern living cells.\u003C/p\u003E\u003Cp\u003EIt would be able to eat itself - to cannibalize broken parts and then remanufacture them. This means it would need multiple parallel redundant copies of every critical part in the probe, so it can eat a broken part while other parts take up the load. \u003C/p\u003E\u003Cp\u003EUnlike an e-coli, it might weigh hundreds of kilograms. A device that operates in a vacuum and can eat rocks raw without needing help would necessarily be a lot bigger than an e-coli that just floats around in fluid until it bumps into food.\u003C/p\u003E\u003Cp\u003ESuch a probe doesn\u0027t have to be dumb. Once it reaches a destination star, it would eat rocks and build itself a bigger computer to think with. It would load highly compressed software, possibly using procedurally defined software that self modifies when it unpacks itself back into a sentient system.\u003C/p\u003E\u003Cp\u003EIt would then build a laser receiver device. The beings who launched it would send out a constant binary stream that would contain more advanced software libraries and possible even encoded sentient beings as map files of their internal neural networks. Humans could travel this way - the safe way to travel interstellar distances, by sending a binary copy of your mind state across the light years. Then you just wait for the reply that will contain your mind-state when you got done exploring...\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222015-08-07T03:52:47Z\u0022 title=\u002208/07/2015 03:52  AM\u0022 data-short=\u00228 yr\u0022\u003EAugust 7, 2015\u003C/time\u003E by Vanamonde\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"AndrewBCrisp","CreatedById":57119,"CreatedDateTime":"2015-08-07T02:06:14Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022SomeGuy12\u0022 data-cite=\u0022SomeGuy12\u0022\u003E\u003Cdiv\u003EUnlike an e-coli, it might weigh hundreds of kilograms. A device that operates in a vacuum and can eat rocks raw without needing help would necessarily be a lot bigger than an e-coli that just floats around in fluid until it bumps into food.\u003Cp\u003ESuch a probe doesn\u0027t have to be dumb. Once it reaches a destination star, it would eat rocks and build itself a bigger computer to think with. It would load highly compressed software, possibly using procedurally defined software that self modifies when it unpacks itself back into a sentient system.\u003C/p\u003E\u003Cp\u003EIt would then build a laser receiver device. The beings who launched it would send out a constant binary stream that would contain more advanced software libraries and possible even encoded sentient beings as map files of their internal neural networks. Humans could travel this way - the safe way to travel interstellar distances, by sending a binary copy of your mind state across the light years. Then you just wait for the reply that will contain your mind-state when you got done exploring...\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EI\u0027d like to focus on this item here. As SomeGuy12 mentions, the existence of bacteria proves that Von Neumann machines are possible. But here, we now move from the discussion of \u0022is this possible?\u0022 to \u0022is this responsible\u0022. Or - referencing the \u003Ca href=\u0022http://www.centauri-dreams.org/?p=27362\u0022 rel=\u0022external nofollow\u0022\u003Earticle\u003C/a\u003E I linked to earlier - do we want replicators or explorers? Which would we rather come into contact with?\u003C/p\u003E\u003Cp\u003EA Von Neumann Probe - I\u0027m just going to refer to them as VNP, as it\u0027s easier to type - will certainly need resources if it is to replicate, but replication may not be the best action for it once it reaches a target star. After all, the star\u0027s planets may be inhabited, and even if we take the precaution of hard-wiring \u0022don\u0027t eat the natives\u0022 into the original VNP before launch, the natives may see things differently once the VNP starts chomping rocks and spitting out more copies of itself with out so much as a \u0022by your leave?\u0022. We can certainly imagine the response our world\u0027s leaders might give if, say, tomorrow astronomers report they\u0027ve detected an alien probe busily replicating in our asteroid belt. \u003C/p\u003E\u003Cp\u003ESo if exploration and contact are the point of sending out VNPs, we need them to be smart enough to not only recognize if a system is inhabited, but also to make contact and to \u003Cem\u003Eask permission\u003C/em\u003E to replicate. If permission is given, or if there\u0027s nobody to get permission from, but there are planets where civilization could develop, the VNP must also be smart enough to \u003Cem\u003Elimit its numbers\u003C/em\u003E. It would not do to spare a civilization but gobble up all of the off-planet resources that civilization may one day need. \u003C/p\u003E\u003Cp\u003EThis will certainly increase the complexity of any VNP sent out, but fortunately we can scale up. As Cooper\u0027s article states, we will likely work with VNPs first as miners in our system, and can gradually expand their capabilities to interstellar explorer-grade as we go along. But if there\u0027s an alien VNP patiently waiting in our system, our miner VNPs will need to be smart enough to recognize them and hold off, rather than attempt to eat our first alien visitor. Recognizing an artifact as a \u0022do not eat\u0022 priority should be a lot easier than recognizing a civilization, and can serve as the ethical foundations our future explorer probes will need if they are to replicate responsibly.\u003C/p\u003E\n"},{"CreatedByName":"SomeGuy12","CreatedById":103022,"CreatedDateTime":"2015-08-07T07:51:29Z","Content":"\n\u003Cp\u003EThe mechanism I described, the first thing the probe munches on is an asteroid no larger than the one that was recently landed on. Once it\u0027s done enough munching, it would unpack itself back into a sentient system. Data integrity checks and redundant information would make the probability of mutations less than one time in the lifespan of the universe - it would not evolve like living creatures do.\u003C/p\u003E\n"},{"CreatedByName":"Jouni","CreatedById":97346,"CreatedDateTime":"2015-08-07T08:26:53Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Jouni\u0022 data-cite=\u0022Jouni\u0022\u003E\u003Cdiv\u003EWe could use some standard definitions from algorithmic information theory. For example, let\u0027s choose an universal model of computation. The complexity of an object is the length of the shortest program that describes a class of objects, among which the object in question has maximal conditional Kolmogorov complexity. (Or something like that. It\u0027s been a while since I last touched algorithmic information theory.) This kind of complexity is obviously uncomputable (like with any reasonable definition of complexity), but the minimum description length approach provides a principled way for approximating it.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EMaybe I\u0027ll expand upon this a bit.\u003C/p\u003E\u003Cp\u003EThe Kolmogorov complexity H(x) of object x is its algorithmic enthropy. It\u0027s defined as the length of the shortest program producing the object (or a full description of it). Like other enthropy measures, the Kolmogorov complexity is quite useless as a measure of useful information. After all, random noise has maximal enthropy.\u003C/p\u003E\u003Cp\u003EMy definition above essentially splits the Kolmogorov complexity into two parts: a description I(x) of a class of objects that should be functionally equivalent, and random noise N(x) that defines the individual object x within the class. Under some assumptions, we have H(x) \u00C3\u00A2\u00E2\u20AC\u00B0\u00CB\u2020 I(x) \u002B N(x).\u003C/p\u003E\u003Cp\u003ELet\u0027s assume that x is a machine, y is the raw materials it uses, z is the object it produces, and r is the set of random conditions during the production. Because x, y, and r completely describe z, we have H(z) \u0026lt;\u00C3\u00A2\u00E2\u20AC\u00B0\u00CB\u2020 H(x) \u002B H(y) \u002B H\u00AE.\u003C/p\u003E\u003Cp\u003ENow let\u0027s assume that machine x is reliable. This means that most representatives of the same class of machines should be able to produce a representative of the same class of objects from most representatives of the same class of raw materials under most random conditions. Essentially, random noise N(\u00C3\u201A\u00C2\u00B7) and random events r should be mostly irrelevant in the production. Now we have I(z) \u0026lt;\u00C3\u00A2\u00E2\u20AC\u00B0\u00CB\u2020 I(x) \u002B I(y).\u003C/p\u003E\u003Cp\u003EThe next thing to note is that machine x already contains a description of the raw material it needs; I(y) is included in I(x). Otherwise the machine can\u0027t know when it should start the production. Now we have I(z) \u0026lt;\u00C3\u00A2\u00E2\u20AC\u00B0\u00CB\u2020 I(x); a reliable autonomous machine can\u0027t produce objects more complex than itself.\u003C/p\u003E\u003Cp\u003EThe final step to I(z) \u0026lt; I(x) is more fuzzy. Production without information loss feels like an information-theoretic version of perpetual motion. In principle, there\u0027s nothing against it, but it\u0027s just extremely unlikely. The reasons against von Neumann-style self-replication are therefore statistical, not logical.\u003C/p\u003E\n"},{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2015-08-07T08:44:15Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022AndrewBCrisp\u0022 data-cite=\u0022AndrewBCrisp\u0022\u003E\u003Cdiv\u003EI\u0027d like to focus on this item here. As SomeGuy12 mentions, the existence of bacteria proves that Von Neumann machines are possible. But here, we now move from the discussion of \u0022is this possible?\u0022 to \u0022is this responsible\u0022. Or - referencing the \u003Ca href=\u0022http://www.centauri-dreams.org/?p=27362\u0022 rel=\u0022external nofollow\u0022\u003Earticle\u003C/a\u003E I linked to earlier - do we want replicators or explorers? Which would we rather come into contact with?\u003Cp\u003EA Von Neumann Probe - I\u0027m just going to refer to them as VNP, as it\u0027s easier to type - will certainly need resources if it is to replicate, but replication may not be the best action for it once it reaches a target star. After all, the star\u0027s planets may be inhabited, and even if we take the precaution of hard-wiring \u0022don\u0027t eat the natives\u0022 into the original VNP before launch, the natives may see things differently once the VNP starts chomping rocks and spitting out more copies of itself with out so much as a \u0022by your leave?\u0022. We can certainly imagine the response our world\u0027s leaders might give if, say, tomorrow astronomers report they\u0027ve detected an alien probe busily replicating in our asteroid belt. \u003C/p\u003E\u003Cp\u003ESo if exploration and contact are the point of sending out VNPs, we need them to be smart enough to not only recognize if a system is inhabited, but also to make contact and to \u003Cem\u003Eask permission\u003C/em\u003E to replicate. If permission is given, or if there\u0027s nobody to get permission from, but there are planets where civilization could develop, the VNP must also be smart enough to \u003Cem\u003Elimit its numbers\u003C/em\u003E. It would not do to spare a civilization but gobble up all of the off-planet resources that civilization may one day need. \u003C/p\u003E\u003Cp\u003EThis will certainly increase the complexity of any VNP sent out, but fortunately we can scale up. As Cooper\u0027s article states, we will likely work with VNPs first as miners in our system, and can gradually expand their capabilities to interstellar explorer-grade as we go along. But if there\u0027s an alien VNP patiently waiting in our system, our miner VNPs will need to be smart enough to recognize them and hold off, rather than attempt to eat our first alien visitor. Recognizing an artifact as a \u0022do not eat\u0022 priority should be a lot easier than recognizing a civilization, and can serve as the ethical foundations our future explorer probes will need if they are to replicate responsibly.\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EAn VNP with an error would stop working as in unable to repair itself or make other parts. Its very unlikely that it would say start producing more and more mining robots who mine or similar cancer like replication problems. its some ways to make this even more safe, if you compress and encrypt the relevant files any bit fail will result in scrambled data, you then use error correction and multiple copies to avoid corruption. Now design system so it regularly has to read the files from disc. \u003C/p\u003E\u003Cp\u003EThe VNP would not have much to do with planets other than land probes on it for exploring. If you see any sign of an advanced civilization, radio, primarily but also light and it would report back and go into some sort of ambassador role. An pre industrial civilization would be hard to detect but would also not notice anything except perhaps an lander or two. \u003C/p\u003E\u003Cp\u003EI imagine the VNP would have two purposes, primarily would be exploration they would move outward exploring solar systems, report back in the chain make copies of itself for more exploration. It would not send VNP to systems who have them, might send an backup probe to an system with ship underway but nothing more.\u003C/p\u003E\u003Cp\u003EAfter the expansion part it would maintain the VNP communication network and report back. it might also get new orders or plans from the operators. \u003C/p\u003E\u003Cp\u003EAn second stage might be to prepare a planet for colonization.\u003C/p\u003E\n"},{"CreatedByName":"SomeGuy12","CreatedById":103022,"CreatedDateTime":"2015-08-07T09:06:32Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022Jouni\u0022 data-cite=\u0022Jouni\u0022\u003E\u003Cdiv\u003E\u003Cp\u003EThe final step to I(z) \u0026lt; I(x) is more fuzzy. Production without information loss feels like an information-theoretic version of perpetual motion. In principle, there\u0027s nothing against it, but it\u0027s just extremely unlikely. The reasons against von Neumann-style self-replication are therefore statistical, not logical.\u003C/p\u003E\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EYour theory is flat out wrong. Because we already have proof of existence of such devices, and can trivially draw out a sketch for more sophisticated devices. Let\u0027s find your errors.\u003C/p\u003E\u003Cp\u003EOh. That didn\u0027t take long. \u003C/p\u003E\u003Cp\u003E1. When the machine copies itself, it first burns a bunch of energy reducing the entropy of the input feedstock to a very low level. (plasma separation, element specific filters, etc). \u003C/p\u003E\u003Cp\u003E2. The machine\u0027s components are not a solitary piece of equipment. They are a \u003Cem\u003Epopulation\u003C/em\u003E of individual pieces. Life on earth clearly demonstrates that such a population can ratchet forward life on earth has done such a thing, from simple machines to the current complexity. The probability of a given machine producing a more complex version of itself is statistically highly unlikely...but it is possible. \u003C/p\u003E\u003Cp\u003E3. In my proposal, the machine isn\u0027t just the piece you sent to another star. You send a constant stream of data from a vastly more complex host machine at the starting star. That data stream contains the information needed to make the more complex versions of the base machine you sent. \u003C/p\u003E\u003Cp\u003E4. In my proposal, another way to do this is procedural compression. Basically, an CRC/md5ed bit of code inside the base machine says things like \u0022go to X, perform this mathematical operation on X, execute the new code present at X...\u0022. You tested this code back at the host star, and developed a piece of code that will unpack into something that is capable of meeting the design constraints. Essentially it\u0027s almost like setting up a bacterium to evolve itself into a much more complex creature by rewriting it\u0027s own genome. The probability of something like this existing by chance is unlikely, but you\u0027d build it by working backwards.\u003C/p\u003E\u003Cp\u003E5. You can reduce the errors to near zero.\u003C/p\u003E\u003Cp\u003EThinking about it, I\u0027m giving engineering reasons. The theoretical reason your idea is wrong is that energy and information are related quantities, and you appear to be able to trade energy for information complexity.\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222015-08-07T09:15:49Z\u0022 title=\u002208/07/2015 09:15  AM\u0022 data-short=\u00228 yr\u0022\u003EAugust 7, 2015\u003C/time\u003E by SomeGuy12\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"Jouni","CreatedById":97346,"CreatedDateTime":"2015-08-07T09:43:22Z","Content":"\n\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022 data-ipsquote-username=\u0022SomeGuy12\u0022 data-cite=\u0022SomeGuy12\u0022\u003E\u003Cdiv\u003EYour theory is flat out wrong. Because we already have proof of existence of such devices, and can trivially draw out a sketch for more sophisticated devices. Let\u0027s find your errors.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EIt\u0027s not my theory, it\u0027s just mathematics. If you\u0027re not familiar with algorithmic information theory, I suggest you to read a book or two about it. Algorithmic information theory is generally offered as a graduate-level computer science/mathematics class, so the web pages of your favorite university should have book suggestions.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003E1. When the machine copies itself, it first burns a bunch of energy reducing the entropy of the input feedstock to a very low level. (plasma separation, element specific filters, etc).\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EI fail to see how this is relevant to the discussion.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003E2. The machine\u0027s components are not a solitary piece of equipment. They are a \u003Cem\u003Epopulation\u003C/em\u003E of individual pieces. Life on earth clearly demonstrates that such a population can ratchet forward life on earth has done such a thing, from simple machines to the current complexity. The probability of a given machine producing a more complex version of itself is statistically highly unlikely...but it is possible.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EThis makes no difference. H(x) is a complete description of the entire population, while I(x) is a complete description of all of its relevant functionality. Life generates useful information from entropy, but because the process is random, it can\u0027t know in advance what it\u0027s going to get. Because we\u0027re talking about machines that should be able to produce something pre-defined, that kind of information is useless.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003E3. In my proposal, the machine isn\u0027t just the piece you sent to another star. You send a constant stream of data from a vastly more complex host machine at the starting star. That data stream contains the information needed to make the more complex versions of the base machine you sent.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EIn this case, we\u0027re not talking about von Neumann machines.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003E4. In my proposal, another way to do this is procedural compression.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EKolmogorov complexity already incorporates all compression methods anyone is ever going to invent. After all, it\u0027s the shortest algorithmic description of an object.\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003E5. You can reduce the errors to near zero.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EAre you saying that perpetual motion is possible?\u003C/p\u003E\u003Cblockquote data-ipsquote=\u0022\u0022 class=\u0022ipsQuote\u0022\u003E\u003Cdiv\u003EThinking about it, I\u0027m giving engineering reasons. The theoretical reason your idea is wrong is that energy and information are related quantities, and you appear to be able to trade energy for information complexity.\u003C/div\u003E\u003C/blockquote\u003E\u003Cp\u003EWhat are you trying to say? I didn\u0027t mention energy at all, because it\u0027s irrelevant to algorithmic complexity.\u003C/p\u003E\n"}]}