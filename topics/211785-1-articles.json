{"TopicId":211785,"ForumId":44,"TopicTitle":"I want to create torrents of my entire NASA/Astronomy/Spaceflight Mission data/image/video collection consisting of over 57.12 terabytes. Would you be interested if i did?","CreatedByName":"Astra Infinitum","CreatedById":221662,"CreatedDateTime":"2023-01-30T08:42:31Z","PageNum":1,"Articles":[{"CreatedByName":"Astra Infinitum","CreatedById":221662,"CreatedDateTime":"2023-01-30T08:42:31Z","Content":"\n\u003Cp\u003E\nI have over 57 Terabytes of data (and constantly growing) I\u0027ve hoarded over the years from NASA and other Astronomy, Astrophysics, Spaceflight, etc. resources. I\u0027ve acquired most of it from thousands and thousands.... and thousands of places across the internet over the last 15-20 years. I\u0027ve ben asked countless times to compile it and put it online somehow for people to acces and download it. I have thousands and thousands of PDF documents, images, notes, test results, and more starting from the Mercury program all the way through Artemis I and present day 2023. I have Documents and Manuals on nearly every Rocket, capsule, module, flight test, mission, mission briefing, science data from missions from Mercury to Gemini to Apollo To Shuttle to ISS, until present day 2023. I have engineering drawings of rockets, spacecrafts,\u00A0 capsules, satellites, and more from Redstone to SLS. I have the entire Apollo image collection in high resolution .tif images from every roll of hasselblad film on every Apollo mission. Shoot I literally have over 400gb of just Apollo Lunar Sample collection images, reports, research, and data alone. Almost everything from everywhere is in extreme high resolution. I have extreme high resolution images of every photo taken by Hubble, Cassini, Juno, and more in .tif\u00A0 and other formats as well. I have every single thing from Apollo- every document ever made nearly, i kid you not like everything from the first project to do with the Apollo missions down the the last document from Apollo missions to the audio files and\u00A0 typed transcripts of everything from astronauts to mission control from every mission, digitized film camera images, and just everything you can think of including all the Rockets, capsules, LM, Lunar rover, manuals, drawings, Flight plans, guidance system manuals, I can literally go on and on and on and on and on and on and on and on. I have bits and pieces of astronaut photos and videos from dozens and dozens of space shuttle missions.\n\u003C/p\u003E\n\u003Cp\u003E\nI have scanned PDFs of hand written notes from Mercury, Gemini, and Apollo astronauts as well as NASA engineers\n\u003C/p\u003E\n\u003Cp\u003E\nI have hoards of raw data and high res images (from spacecraft that had imaging cameras/instrumentation) from 50\u002B space craft and missions/surveys/ect like Hubble, Kepler, TESS, K2, WASP,\u00A0 \u00A0Cassini (also every Cassini image), Juno, New Horizons, Gaia, Digitized Sky Survey, and more.\n\u003C/p\u003E\n\u003Cp\u003E\nA large amount of all the data from MAST which has all the image and data from Hubble, Webb, TESS, Nancy Grace Roman, the ones i also had just named above and more.\u00A0I also a trove of the special apps and software, code, scripts, special file viewers , and more that you need to work with or view alot of the data from alot of these missions.\n\u003C/p\u003E\n\u003Cp\u003E\nA large amount of the data and images and catalogs from Simbad and VizieR and anything you can view in/through Aladin sky atlas.\n\u003C/p\u003E\n\u003Cp\u003E\nEvery image and video file from NASA SDO - Solar Dynamics Observatory for about 2-3 years, currently.\n\u003C/p\u003E\n\u003Cp\u003E\nI have endless high res images, planetary maps, surface maps, and data from every planet from USGS and other sources\n\u003C/p\u003E\n\u003Cp\u003E\nAll data from NASA exoplanet archive up to 12-2022\n\u003C/p\u003E\n\u003Cp\u003E\nI also a trove of the special apps and software, code, scripts, special file viewers , and more that you need to work with or view alot of the data from alot of these missions.\u003Cbr\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nI leave it at that bc i could never stop explaining everything ive compiled.\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nBut i\u0027ve said all that to say this: I\u0027ve been asked by many people over the years to put it online somehow so people can access and download all of it. I\u0027ve recently been trying to first organize everything a little better because its so all over the place. But what i think i will do is once everything is very neatly organized i would like to split into many different categories and in groups/files that i will make into torrents. I would like for no torrent file to include more than 50gb, that way people can choose what they want to download and not be forced to have to download 100s of gb or TBs of data only to get a few things in there that turns out to be a fraction of the entire torrent. Ive never actually created a torrent so I gotta go learn how to do that first but that should be quite easy.\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nAnyone else have any ideas on ways to compile everything to put online for people to download safely? Any ideas besides breaking it all down into torrents? I own a handful of domains and have access to storage servers\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nAnd last question: is all this something that would greatly interest any/all/some users on this forum? My guess would be yes but i wanted to ask anyway.\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\n\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nAlso feel free to offer to help. Idk how we can go about it yet but il figure something out bc its gonna take awhile to do all this.\n\u003C/p\u003E\n"},{"CreatedByName":"Shpaget","CreatedById":45577,"CreatedDateTime":"2023-01-30T17:13:11Z","Content":"\n\u003Cp\u003E\nWow.\n\u003C/p\u003E\n\u003Cp\u003E\nDo you have it indexed? Such a huge amount of data is of little use if it\u0027s impossible to navigate.\n\u003C/p\u003E\n"},{"CreatedByName":"Nuke","CreatedById":10883,"CreatedDateTime":"2023-01-31T02:42:02Z","Content":"\n\u003Cp\u003E\ntorrents really only work if you can find regular seeders with big storage. id be hard pressed to find 10tb of storage in my entire house. i got 8tb on my main rig and nas alone and a lot of 512 gig drives in all my other machines. and most of that space is allocated to operating systems, software, and data not to mention a good half is backup. you might find some data hoarders with more storage.\u00A0\n\u003C/p\u003E\n\u003Cp\u003E\nyou might be better off uploading the video to youtube, monetize it (at least ask for donations) and use the proceeds to fund cloud storage for the non-video data. science has always had this problem of finding long term archival storage for their data. we really need a new rom standard that has some serious density behind it. there was that 5d holographic storage thing in the news around back, but i doubt that\u0027s something you can just buy a drive for.\u00A0 tape works but you have to periodically check for degradation.\u00A0\n\u003C/p\u003E\n\u003Cspan class=\u0022ipsType_reset ipsType_medium ipsType_light\u0022 data-excludequote=\u0022\u0022\u003E\n\u003Cstrong\u003EEdited \u003Ctime datetime=\u00222023-01-31T02:43:15Z\u0022 title=\u002201/31/2023 02:43  AM\u0022 data-short=\u00221 yr\u0022\u003EJanuary 31, 2023\u003C/time\u003E by Nuke\u003C/strong\u003E\n\u003C/span\u003E\n"},{"CreatedByName":"Gargamel","CreatedById":64714,"CreatedDateTime":"2023-01-31T02:54:07Z","Content":"\n\u003Cp\u003E\nThere\u2019s a few places that can easily handle that much data. \u00A0 \u00A0NSA, Google, Amazon, NASA\u2026. One of them might have an interest in archiving research data. \u00A0 \u00A0 Try reaching out to their publications relations people and see if they could put you in contact with somebody inside the agency who might be interested in helping out. \u00A0\n\u003C/p\u003E\n"},{"CreatedByName":"AckSed","CreatedById":224249,"CreatedDateTime":"2023-02-02T15:25:35Z","Content":"\n\u003Cp\u003E\nWow. That\u0027s a small-scale data centre\u0027s worth.\n\u003C/p\u003E\n\u003Cp\u003E\nAsk the Internet Archive?\n\u003C/p\u003E\n\u003Cp\u003E\n\u003Ca href=\u0022https://archive.org/about/contact.php\u0022 rel=\u0022external nofollow\u0022\u003Ehttps://archive.org/about/contact.php\u003C/a\u003E\n\u003C/p\u003E\n\u003Cp\u003E\nFor example, they helped with (partial) digitisation of the\u00A0\u003Ca href=\u0022https://archive.org/details/prelinger?tab=about\u0022 rel=\u0022external nofollow\u0022\u003EPrelinger Archives\u003C/a\u003E, a 60,000-strong collection of film ephemera.\n\u003C/p\u003E\n\u003Cp\u003E\nAnd of course I\u0027m interested. I just don\u0027t have the storage space!\n\u003C/p\u003E\n"}]}