{"TopicId":107556,"ForumId":44,"TopicTitle":"Robot takeover","CreatedByName":"Ethanadams","CreatedById":136913,"CreatedDateTime":"2015-05-05T00:29:59Z","PageNum":5,"Articles":[{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2016-06-10T23:14:43Z","Content":"\u003E \n\u003E \n\u003E 6 hours ago, Rakaydos said:\n\u003E \n\u003E \n\u003E AI will have Emotions... they will, however, not all be human emotions.\n\u003E \n\u003E \n\u003E \n\u003E \n\u003E Emotions being shortcuts, bypassing the gordian knot of logic and decision paralisis. Rage/Fear? Kill or flee. Happyness? reward cycle.\n\u003E \n\u003E \n\u003E \n\u003E \n\u003E An AI wont have a human concept of love, because that\u0027s related to human pairbonding, human reprodution, and thus continued human life. An AI would have something similar to a worker ant\u0027s need to be useful, because it makes the AI more likely to be the basis for furthur AIs- computer reproduction.\n\u003E \n\nThis, watching you cat play with an mouse is an sort of this."},{"CreatedByName":"magnemoe","CreatedById":57801,"CreatedDateTime":"2016-06-10T23:27:08Z","Content":"\u003E \n\u003E \n\u003E 2 hours ago, RainDreamer said:\n\u003E \n\u003E \n\u003E Relevant comic from [Questionable Content](http://questionablecontent.net):\n\u003E \n\u003E \n\u003E \n\u003E \n\u003E ![3239.png](http://questionablecontent.net/comics/3239.png)\n\u003E \n\nAnother comic to follow, this is pure evil ![:)](//kerbal-forum-uploads.s3.us-west-2.amazonaws.com/emoticons/default_k_smiley.gif \u0022:)\u0022)  \n\nMore serious, nature does not follow human rules not even the most basic ones.   \n\nThey follow totally different rules. Some who are pure nightmare fuel for us.   \n\nBest example, some frogs live in Sahara, they get lots of rains but with years between, to create enough new frogs from the rapid evaporating pounds they need to grow fast.  \n\nSolution is two types of tadpoles, the common one who eat plankton and the predator one who eat other tadpoles.   \n\nThis ensure that enough predator tadpoles survive to become frogs.    \n\nYes its lots of less extreme ones like chicks kicking the weaker ones out."},{"CreatedByName":"SinBad","CreatedById":158888,"CreatedDateTime":"2016-06-11T05:04:37Z","Content":"I would like to point to the chinese room arguement here, but with a twist. Most folks take it as an arguement against the possability of strong ai. but i see it as supporting the possibility. If a program behaves as if it is conscious, does it matter if it actualy is? If it behaves as if it has human like emotions, does it matter if it doesnt feel them?\n\nIf a program is so good at pretending to have a human like mind that most people interacting with it feel like its intelligent and consious, does it matter that inside the room is just a cpu executing sequential bits of code?\n\nFor that matter, proove that your mind isnt a chinese room made of chemical reactions. Point to your consciousness."},{"CreatedByName":"vger","CreatedById":67603,"CreatedDateTime":"2016-06-11T17:10:13Z","Content":"A crucial example of why free-thinking robots probably shouldn\u0027t happen. It\u0027d be like a child with the strength of ten men. Think about some of the things that happened in \u0022Frankenstein,\u0022 and then consider that people can be manipulative jerks. Allowing AI to be susceptible to such manipulation is a very VERY bad idea.\n\n[http://www.telegraph.co.uk/technology/2016/03/24/microsofts-teen-girl-ai-turns-into-a-hitler-loving-sex-robot-wit/](http://www.telegraph.co.uk/technology/2016/03/24/microsofts-teen-girl-ai-turns-into-a-hitler-loving-sex-robot-wit/)\n\nSeems like the only way to prevent this sort of thing from happening is by violating the free-will of the AI. Hard-coded morals, \u0022Asimov\u0027s laws of robotics,\u0022 etc.\n\n**Edited \u003Ctime datetime=\u00222016-06-11T17:15:29Z\u0022 title=\u002206/11/2016 05:15  PM\u0022 data-short=\u00228 yr\u0022\u003EJune 11, 2016\u003C/time\u003E by vger**"},{"CreatedByName":"kerbiloid","CreatedById":129408,"CreatedDateTime":"2016-06-24T05:14:32Z","Content":"Humans win!\n\n\u003Ciframe allowfullscreen=\u0022true\u0022 frameborder=\u00220\u0022 height=\u0022270\u0022 src=\u0022https://www.youtube.com/embed/tf7IEVTDjng?feature=oembed\u0026vq=highres\u0022 width=\u0022480\u0022\u003E\u003C/iframe\u003E\n\n(From 1:25)"},{"CreatedByName":"RainDreamer","CreatedById":129077,"CreatedDateTime":"2016-06-24T06:42:25Z","Content":"\u003E \n\u003E \n\u003E On 12/06/2016 at 0:10 AM, vger said:\n\u003E \n\u003E \n\u003E Seems like the only way to prevent this sort of thing from happening is by violating the free-will of the AI. Hard-coded morals, \u0022Asimov\u0027s laws of robotics,\u0022 etc.\n\u003E \n\nWhat I wonder is...how can we define something as nebulous as human morality to become laws? Will the robot understand something like emotional harm?"},{"CreatedByName":"Vanamonde","CreatedById":27914,"CreatedDateTime":"2016-06-24T21:40:33Z","Content":"Why did they give this thing a \u0022hand\u0022 that looks like a goat skull? It\u0027s creepy."}]}