{"TopicId":107755,"ForumId":55,"TopicTitle":"Using Genetic Algorithms for development.","CreatedByName":"Whirligig Girl","CreatedById":36077,"CreatedDateTime":"2015-05-05T22:55:42Z","PageNum":1,"Articles":[{"CreatedByName":"Whirligig Girl","CreatedById":36077,"CreatedDateTime":"2015-05-05T22:55:42Z","Content":"I was thinking about how the new aero compares to FAR, and how rockets and planes don\u0027t wobble in the new atmosphere as they did in old FAR. This brought me to the train of thought of how they fine-tuned the whole thing. Then I had an idea. A lot of these things are based on subjective opinions on balance, and may not turn out quite right. So what if instead, you had a genetic algorithm (natural selection, but for designing things instead of being life) to tune things. For instance, a variation on a code or a cfg is run through a series of stress tests, and the best one (in the case of aero, perhaps it could be the SAS configuration that produces the least wobble) gets to bring its \u0022genes\u0022 on to the next generation of code or cfgs or whathaveyou.\n\nThis is so abstract, this might fit in better in the Space Lounge than the development forum.\n\nAnd now I\u0027m wondering about the idea of using a genetic algorithm to control a rocket in kOS or something.\n\n**Edited \u003Ctime datetime=\u00222015-05-05T22:59:50Z\u0022 title=\u002205/05/2015 10:59  PM\u0022 data-short=\u00229 yr\u0022\u003EMay 5, 2015\u003C/time\u003E by GregroxMun**"},{"CreatedByName":"J.Random","CreatedById":63332,"CreatedDateTime":"2015-05-05T23:17:01Z","Content":"Well, afaik the hard thing about genetic algorithms is that you have to, you know, actually teach the neural network. So, in case of the whole aerodynamic model, I guess you\u0027d have to have reference designs (and a lot of them) and know precisely how they should work at different speed/AoA, so you could evaluate the success rate of the network. And creating a \u0022how good does it fly\u0022 metric would be a problem."},{"CreatedByName":"Whirligig Girl","CreatedById":36077,"CreatedDateTime":"2015-05-05T23:18:59Z","Content":"\u003E \n\u003E Well, afaik the hard thing about genetic algorithms is that you have to, you know, actually teach the neural network. So, in case of the whole aerodynamic model, I guess you\u0027d have to have reference designs (and a lot of them) and know precisely how they should work at different speed/AoA, so you could evaluate the success rate of the network. And creating a \u0022how good does it fly\u0022 metric would be a problem.\n\nI never said I had an idea of how exactly to use it, I just gave a basic example. It\u0027d be up to Squad to figure anything else out."},{"CreatedByName":"youkofoxy","CreatedById":111097,"CreatedDateTime":"2015-05-06T02:26:59Z","Content":"Google\n\nDid you mean: A system for selection of algorithms per popularity."},{"CreatedByName":"arkie87","CreatedById":103434,"CreatedDateTime":"2015-05-06T02:52:43Z","Content":"\u003E \n\u003E I was thinking about how the new aero compares to FAR, and how rockets and planes don\u0027t wobble in the new atmosphere as they did in old FAR. This brought me to the train of thought of how they fine-tuned the whole thing. Then I had an idea. A lot of these things are based on subjective opinions on balance, and may not turn out quite right. So what if instead, you had a genetic algorithm (natural selection, but for designing things instead of being life) to tune things. For instance, a variation on a code or a cfg is run through a series of stress tests, and the best one (in the case of aero, perhaps it could be the SAS configuration that produces the least wobble) gets to bring its \u0022genes\u0022 on to the next generation of code or cfgs or whathaveyou.\n\u003E This is so abstract, this might fit in better in the Space Lounge than the development forum.\n\u003E \n\u003E And now I\u0027m wondering about the idea of using a genetic algorithm to control a rocket in kOS or something.\n\nWhat are your design variables (i.e. what are you optimizing) and what is your objective function (what are you optimizing FOR)? \n\nAre you optimizing aerodynamic physics (what) so that planes fly as easily as possible (for)? If that\u0027s the case, then i\u0027d say just revert back to pre 1.0 aero...\n\nAre you optimizing aerodynamics physics so that good designs fly well and bad designs fly bad? \n\nIt\u0027s definately possible, if you define what your design variables, design constraints, and objective function are. You just need a code that randomly assembles planes tries to fly them, and then evaluates each one.\n\nOr are you trying to optimize autopiloting/control? I recommend looking [here](https://en.wikipedia.org/wiki/PID_controller). If you look at the pseudocode at the bottom, this can EASILY be implemented in kOS."},{"CreatedByName":"Fel","CreatedById":57121,"CreatedDateTime":"2015-05-06T02:58:49Z","Content":"\u003E \n\u003E I never said I had an idea of how exactly to use it, I just gave a basic example. It\u0027d be up to Squad to figure anything else out.\n\nThen what is the point of mentioning it? It\u0027s a very incomplete idea and I have a feeling using something akin to a phoropter, or binary search, would prove better. \u0022Which is better, one, two, or no difference\u0022\n\n(Of course, we\u0027re dealing with a ton of variables; which means you\u0027ll use a \u0022mastermind\u0022 algorithm, or rather that you keep changing multiple variables but, due to the way they\u0027re changed, determine the outcome in fewer turns than doing each separately.\n\n**Edited \u003Ctime datetime=\u00222015-05-06T03:01:17Z\u0022 title=\u002205/06/2015 03:01  AM\u0022 data-short=\u00229 yr\u0022\u003EMay 6, 2015\u003C/time\u003E by Fel**"},{"CreatedByName":"Bill Phil","CreatedById":127797,"CreatedDateTime":"2015-05-06T03:24:18Z","Content":"Basically, run a test of each generation? Taking the best values, and adding in mutations?\n\nLike:\n\n1.) Test a whole bunch of code\n\n2.) Take the best instances\n\n3.) Add a mutation to each one\n\n4.) Repeat\n\nSomething like that?"},{"CreatedByName":"katateochi","CreatedById":35181,"CreatedDateTime":"2015-05-06T11:37:03Z","Content":"I think this would be a rather complex problem to solve with a GA. Evaluation of a fitness function is going to be time consuming as you\u0027ll have to run real time trials in KSP. GA\u0027s are also lazy little \\*\\*\\*\\* and won\u0027t necessarily find the optimal solution in a complex search space. \n\nI think you\u0027d be better of with some form of back-propagation algorithm which could adjust a setting in real time as you flew a craft. You\u0027d need to characterize what the \u0022error\u0022 was (ie the amount of wobble) and then have the algorithm adjust settings to attempt to reduce that error. \n\nIt\u0027s an interesting idea, but kinda tricky. \n\nBut re your evolved autopilot idea. I\u0027ve been wondering about that too and also about evolving a rocket. But both those suffer from having very time consuming fitness functions (a whole launch per evaluation). So I\u0027ve shelved those ideas for now."},{"CreatedByName":"Whirligig Girl","CreatedById":36077,"CreatedDateTime":"2015-05-06T11:38:55Z","Content":"\u003E \n\u003E Basically, run a test of each generation? Taking the best values, and adding in mutations?\n\u003E Like:\n\u003E \n\u003E 1.) Test a whole bunch of code\n\u003E \n\u003E 2.) Take the best instances\n\u003E \n\u003E 3.) Add a mutation to each one\n\u003E \n\u003E 4.) Repeat\n\u003E \n\u003E Something like that?\n\nYes, pretty much exactly that."},{"CreatedByName":"katateochi","CreatedById":35181,"CreatedDateTime":"2015-05-06T12:27:38Z","Content":"\u003E \n\u003E Basically, run a test of each generation? Taking the best values, and adding in mutations?\n\u003E Like:\n\u003E \n\u003E 1.) Test a whole bunch of code\n\u003E \n\u003E 2.) Take the best instances\n\u003E \n\u003E 3.) Add a mutation to each one\n\u003E \n\u003E 4.) Repeat\n\u003E \n\u003E Something like that?\n\n\u003E \n\u003E Yes, pretty much exactly that.\n\nYou don\u0027t want to take the best instances, that would be what\u0027s called Elitist selection and it is generally doomed. You also don\u0027t want to add a mutation to each one, mutations are the vector for adding totally novel genes to a population but for the most part they are very detrimental to a population. You want to have a very very low mutation rate. \n\n1) define population of (say 30) random genomes\n\n2) \u0022recombination\u0022 - select two genomes at random and combine them to form a new genome (can be the typical 50/50 split of genomes from each, a recombination rate of 0.5, but doesn\u0027t have to be)\n\n3) \u0022mutation\u0022 - on very rare occasions, say about 0.02% of the time, add a mutation to a gene in the new genome. \n\n4) \u0022contest\u0022 - select 3rd random genome from population and evaluate it\u0027s performance and the performance of the new genome. If new genome wins then it replaces that member in the population, otherwise throw it away\n\n5) return to step 2\n\nBreeding can happen between any population members, even really poorly scoring ones, that is essential for maintaining genetic diversity (elitist selection looses diversity very quickly so it\u0027s highly prone to getting stuck in a genetic blind alley). \n\nOnly need to run 2 fitness evaluations per \u0022generation\u0022 (which helps speed things up).\n\nRecombination is what drives a population towards genetic convergence (fixes characteristics in a population), mutation adds noise and acts against that. There is no rule about optimal rates for either, it depends on a number of things, length of genome, complexity of search space etc. If recombination rates are too high then the population will very quickly become clones of each other and all diversity is lost, if mutation rates are too high good traits will get lost (and mathematically you end up being no more effective than a random search algorithm). \n\nAnyway, sorry for going all GA nerd on you, just thought you\u0027d be interested!"},{"CreatedByName":"Bill Phil","CreatedById":127797,"CreatedDateTime":"2015-05-06T12:58:11Z","Content":"You want the best instances. That\u0027s how natural selection works, the best for a given environment is the most evolutionarily successful. Like with the finches in the Galapagos, the ones with the beaks that were unsuited died off, and the ones with better beaks for the new environment, a variation within the original population, were better suited.\n\nAdding a mutation to each one would add variance, which is basically making all instances not the same. This is key to evolution. \n\nRecombination of genes actually promotes mutations in the form of variance."},{"CreatedByName":"John FX","CreatedById":59415,"CreatedDateTime":"2015-05-06T13:28:46Z","Content":"Rather than evolve a system which I must admit sounds very cool, couldn\u0027t you just have a variable amount of control authority and reduce degrees of flap deflection/SAS Torque the closer you are to (for example) prograde with a fudge factor for rotational speed and acceleration?\n\nMeaning if you are pointing prograde and not drifting there is no control authority but if you are drifting then you have \u0027some\u0027 based on (acceleration combined with drift speed, if accelerating away increase authority until you stop accelerating away then add a bit more to start heading back to the desired direction), the further away from prograde and the faster you are moving away from it or even accelerating away, the more control authority you have.\n\nThe most control authority would be when you are a long way from prograde and drifting away (with acceleration) from it on the navball.\n\nJust my thoughts, I\u0027m a lazy programmer...\n\nSurely this is the way they already do it?\n\n**Edited \u003Ctime datetime=\u00222015-05-06T13:31:41Z\u0022 title=\u002205/06/2015 01:31  PM\u0022 data-short=\u00229 yr\u0022\u003EMay 6, 2015\u003C/time\u003E by John FX**"},{"CreatedByName":"Fel","CreatedById":57121,"CreatedDateTime":"2015-05-08T01:40:30Z","Content":"\u003E \n\u003E You want the best instances. That\u0027s how natural selection works, the best for a given environment is the most evolutionarily successful. Like with the finches in the Galapagos, the ones with the beaks that were unsuited died off, and the ones with better beaks for the new environment, a variation within the original population, were better suited.\n\nThat isn\u0027t how evolution works.\n\nEvolution is simply \u0022X creature is more successful at creating viable offspring over a period of time than Y creature.\u0022 There is no \u0022best for the given environment\u0022 simply procreation. So, let\u0027s say a particular species of bird targeted other species of birds and wiped them out, all it means is that species of bird that is killing other birds becomes the \u0022best survivor\u0022 in the environment and earns the right to bear the next generation of offspring. Does it mean that the birds that were killed off were inferior, or did not have traits that the genocidal birds would benefit from? No. All it means is that the birds were killed off due to the actions of other birds.\n\nkatateochi is very right here; mutations aren\u0027t how evolution works, GENES are. People have \u0022some number I\u0027m not going to bother looking up\u0022 genes that aren\u0027t even active! Occasionally we get two people to mate that have the same gene, and it just happens to work for their offspring and we get what you call \u0022a mutation.\u0022\n\nMutations have another name, one you\u0027re probably more familiar with. Cancer. Of course, only occasionally do we get mutations where we need them, also called testicular cancer or ovarian cancer. OCCASIONALLY we get a defect that isn\u0027t malignant and we get something different that doesn\u0027t cause problems (doesn\u0027t need to be beneficial by itself, just needs to create a new gene that doesn\u0027t affect fertility.)\n\nThese algorithms aren\u0027t something you run and 30 seconds later you get a solution; they\u0027re very very big, very time consuming, and your population sizes generally get fairly large. You don\u0027t want too much initial variance because that will only make it longer before you get to a solution, and you don\u0027t want to just \u0022prune\u0022 your populations because you\u0027ll be destroying genes that may prove valuable when combined in a particular manner. **And the \u0022genes\u0022 aren\u0027t going to be the values you want** the genes only affect the evolutionary model, which is NOT a straight forward \u0022just push it into aero and test\u0022, those values can be calculated from the genes, but the genes cannot be calculated from those values."}]}